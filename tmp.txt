nohup: ignoring input
2021-10-31 23:25:57.258977: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2021-10-31 23:25:57.263341: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299990000 Hz
2021-10-31 23:25:57.263522: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x560160dbc7a0 executing computations on platform Host. Devices:
2021-10-31 23:25:57.263536: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:157: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  warnings.warn("The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.")
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:165: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  warnings.warn("The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.")
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/pettingzoo/utils/wrappers/base.py:59: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  warnings.warn("The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.")
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/pettingzoo/utils/wrappers/base.py:51: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  warnings.warn("The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.")
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:61: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  warnings.warn("The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.")
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/pettingzoo/utils/conversions.py:69: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  warnings.warn("The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.")
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/pettingzoo/utils/wrappers/base_parallel.py:48: UserWarning: The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead.
  "The `observation_spaces` dictionary is deprecated. Use the `observation_space` function instead."
/home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/pettingzoo/utils/wrappers/base_parallel.py:60: UserWarning: The `action_spaces` dictionary is deprecated. Use the `action_space` function instead.
  "The `action_spaces` dictionary is deprecated. Use the `action_space` function instead."
WARNING:tensorflow:From /home/seth/anaconda3/envs/RL/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
env is  Mario_Bros
adversary agents number is 0
Using good policy TD3 and adv policy TD3
Starting iterations...
steps: 1000, episodes: 1, mean episode reward: 0.0, 2.8702432504542315, time: 32.498
steps: 1823, episodes: 2, mean episode reward: 0.0, 4.314165872883147, time: 33.083
steps: 2714, episodes: 3, mean episode reward: 0.0, 4.290630522567845, time: 29.803
steps: 3714, episodes: 4, mean episode reward: 0.0, 3.2910740676403245, time: 41.482
steps: 4677, episodes: 5, mean episode reward: 0.0, 3.682811430453023, time: 37.125
steps: 5677, episodes: 6, mean episode reward: 800.0, 803.8735460118459, time: 39.472
steps: 6531, episodes: 7, mean episode reward: 0.0, 3.756297102793554, time: 37.221
steps: 7531, episodes: 8, mean episode reward: 0.0, 3.217085870555877, time: 43.924
steps: 8531, episodes: 9, mean episode reward: 4000.0, 4004.888573551654, time: 39.964
steps: 9531, episodes: 10, mean episode reward: 0.0, 4.67682496966559, time: 11.622
steps: 10531, episodes: 11, mean episode reward: 0.0, 5.403692518726693, time: 11.258
steps: 11531, episodes: 12, mean episode reward: 1600.0, 1602.8958146661619, time: 11.442
steps: 12531, episodes: 13, mean episode reward: 4800.0, 4803.066532463932, time: 10.919
steps: 13531, episodes: 14, mean episode reward: 800.0, 805.4889246938629, time: 11.122
steps: 14312, episodes: 15, mean episode reward: 0.0, 3.5579164583957414, time: 9.171
steps: 15312, episodes: 16, mean episode reward: 0.0, 5.588882782131281, time: 11.272
steps: 16312, episodes: 17, mean episode reward: 800.0, 803.244063154401, time: 11.592
steps: 17312, episodes: 18, mean episode reward: 3200.0, 3203.931919409451, time: 11.607
steps: 17645, episodes: 19, mean episode reward: 0.0, 1.932803849042068, time: 4.87
steps: 18645, episodes: 20, mean episode reward: 0.0, 5.6797157393055455, time: 11.885
steps: 19233, episodes: 21, mean episode reward: 3200.0, 3202.44928707487, time: 7.14
steps: 20233, episodes: 22, mean episode reward: 0.0, 3.7893451568338703, time: 12.113
steps: 20917, episodes: 23, mean episode reward: 0.0, 3.082234383101307, time: 8.359
steps: 21754, episodes: 24, mean episode reward: 2400.0, 2404.3073823002105, time: 10.219
StopIteration()
steps: 22754, episodes: 25, mean episode reward: 1600.0, 1604.6388682115075, time: 12.29
steps: 23491, episodes: 26, mean episode reward: 0.0, 4.4165712185332815, time: 9.506
steps: 24491, episodes: 27, mean episode reward: 0.0, 5.403511869504569, time: 12.478
steps: 25300, episodes: 28, mean episode reward: 0.0, 4.090253367322638, time: 10.612
steps: 26250, episodes: 29, mean episode reward: 0.0, 4.501473463608725, time: 12.009
steps: 27250, episodes: 30, mean episode reward: 0.0, 2.5299441508781264, time: 12.928
steps: 28182, episodes: 31, mean episode reward: 2400.0, 2402.9449815553853, time: 12.343
steps: 28621, episodes: 32, mean episode reward: 0.0, 2.5458148959959686, time: 6.133
steps: 29621, episodes: 33, mean episode reward: 0.0, 4.935365400602725, time: 13.529
steps: 30621, episodes: 34, mean episode reward: 1600.0, 1603.8956138255521, time: 17.698
steps: 31370, episodes: 35, mean episode reward: 0.0, 2.3759671283485493, time: 20.759
steps: 32370, episodes: 36, mean episode reward: 2400.0, 2403.4712011970446, time: 48.302
steps: 33370, episodes: 37, mean episode reward: 0.0, 5.912142837293438, time: 14.369
steps: 34370, episodes: 38, mean episode reward: 1600.0, 1602.7871911426512, time: 14.588
steps: 35370, episodes: 39, mean episode reward: 2400.0, 2404.5842533579425, time: 14.461
steps: 36370, episodes: 40, mean episode reward: 0.0, 3.781657377012065, time: 14.81
steps: 37370, episodes: 41, mean episode reward: 0.0, 4.9774410841790235, time: 14.54
steps: 38370, episodes: 42, mean episode reward: 0.0, 5.9432710400636894, time: 14.806
steps: 39370, episodes: 43, mean episode reward: 0.0, 4.5795576715441015, time: 15.46
steps: 40236, episodes: 44, mean episode reward: 1600.0, 1605.6727007335933, time: 12.995
steps: 40932, episodes: 45, mean episode reward: 0.0, 3.6194166089304556, time: 10.451
StopIteration()
steps: 41932, episodes: 46, mean episode reward: 0.0, 3.705424418287429, time: 15.868
steps: 42932, episodes: 47, mean episode reward: 0.0, 5.289541088612375, time: 15.693
steps: 43736, episodes: 48, mean episode reward: 0.0, 3.6928011364277946, time: 12.795
steps: 44300, episodes: 49, mean episode reward: 0.0, 2.880911164243774, time: 8.833
steps: 45104, episodes: 50, mean episode reward: 1600.0, 1605.0581265733754, time: 12.788
StopIteration()
steps: 46104, episodes: 51, mean episode reward: 1600.0, 1604.180071337179, time: 16.862
steps: 46948, episodes: 52, mean episode reward: 0.0, 3.9423604091585505, time: 13.783
steps: 47948, episodes: 53, mean episode reward: 0.0, 5.635196990691323, time: 16.791
StopIteration()
steps: 48948, episodes: 54, mean episode reward: 0.0, 5.460489732434681, time: 17.152
steps: 49938, episodes: 55, mean episode reward: 0.0, 5.171659110983029, time: 17.104
steps: 50938, episodes: 56, mean episode reward: 1600.0, 1604.8736995235538, time: 17.637
steps: 51938, episodes: 57, mean episode reward: 0.0, 4.798118878745317, time: 17.771
steps: 52557, episodes: 58, mean episode reward: 800.0, 803.2188068072551, time: 10.675
steps: 53557, episodes: 59, mean episode reward: 800.0, 802.7772508765627, time: 18.448
steps: 54379, episodes: 60, mean episode reward: 0.0, 4.448524637307838, time: 14.755
steps: 55379, episodes: 61, mean episode reward: 1600.0, 1604.8087550090531, time: 18.856
steps: 56379, episodes: 62, mean episode reward: 0.0, 5.3268715603344905, time: 19.06
steps: 57307, episodes: 63, mean episode reward: 0.0, 4.888841108858035, time: 17.766
steps: 58070, episodes: 64, mean episode reward: 0.0, 4.222226470220759, time: 14.591
steps: 59070, episodes: 65, mean episode reward: 0.0, 4.7261314122899645, time: 19.538
steps: 60070, episodes: 66, mean episode reward: 0.0, 4.606250577486982, time: 19.9
steps: 60539, episodes: 67, mean episode reward: 0.0, 2.7197887510386547, time: 9.763
StopIteration()
steps: 61539, episodes: 68, mean episode reward: 1600.0, 1605.1758640424755, time: 20.337
steps: 62539, episodes: 69, mean episode reward: 3200.0, 3205.2366532984493, time: 18.025
steps: 63539, episodes: 70, mean episode reward: 0.0, 5.284352283953176, time: 18.218
StopIteration()
steps: 64539, episodes: 71, mean episode reward: 0.0, 3.919589772356293, time: 18.639
StopIteration()
steps: 65539, episodes: 72, mean episode reward: 800.0, 804.2544211196418, time: 19.78
steps: 66439, episodes: 73, mean episode reward: 1600.0, 1603.966199779294, time: 17.024
steps: 67344, episodes: 74, mean episode reward: 1600.0, 1605.4867311201892, time: 17.323
steps: 68344, episodes: 75, mean episode reward: 3200.0, 3202.726591219282, time: 19.864
StopIteration()
steps: 69344, episodes: 76, mean episode reward: 0.0, 3.9520218556622146, time: 20.048
steps: 70223, episodes: 77, mean episode reward: 0.0, 4.172996664967857, time: 17.528
steps: 71223, episodes: 78, mean episode reward: 2400.0, 2405.1173101197346, time: 20.744
steps: 72052, episodes: 79, mean episode reward: 1600.0, 1604.3591831380525, time: 16.68
steps: 72997, episodes: 80, mean episode reward: 0.0, 3.7207903378125984, time: 19.686
steps: 73997, episodes: 81, mean episode reward: 0.0, 5.280347443911384, time: 21.543
steps: 74958, episodes: 82, mean episode reward: 3200.0, 3203.9234264340203, time: 20.846
steps: 75958, episodes: 83, mean episode reward: 0.0, 5.268647227061301, time: 22.195
steps: 76634, episodes: 84, mean episode reward: 2400.0, 2403.1664379051385, time: 14.306
steps: 77464, episodes: 85, mean episode reward: 0.0, 4.2833937733671705, time: 18.307
steps: 78464, episodes: 86, mean episode reward: 0.0, 4.454173235386596, time: 22.925
steps: 79464, episodes: 87, mean episode reward: 1600.0, 1605.339248748171, time: 23.283
StopIteration()
steps: 80464, episodes: 88, mean episode reward: 0.0, 3.85836972392802, time: 23.449
steps: 81464, episodes: 89, mean episode reward: 800.0, 803.4726961072623, time: 23.83
StopIteration()
steps: 82464, episodes: 90, mean episode reward: 1600.0, 1604.562834483344, time: 24.06
steps: 83217, episodes: 91, mean episode reward: 0.0, 3.3811053571276886, time: 17.759
steps: 84217, episodes: 92, mean episode reward: 0.0, 5.519805513776722, time: 24.832
steps: 85217, episodes: 93, mean episode reward: 0.0, 5.558962693607554, time: 25.084
steps: 86217, episodes: 94, mean episode reward: 1600.0, 1603.7384384737604, time: 25.513
steps: 87217, episodes: 95, mean episode reward: 0.0, 4.580663726916972, time: 25.604
steps: 88217, episodes: 96, mean episode reward: 0.0, 4.4792184099777534, time: 26.118
steps: 89217, episodes: 97, mean episode reward: 0.0, 5.17994444136203, time: 26.435
steps: 90217, episodes: 98, mean episode reward: 1600.0, 1604.7750863380738, time: 26.772
steps: 90997, episodes: 99, mean episode reward: 800.0, 803.9767400109021, time: 20.42
steps: 91997, episodes: 100, mean episode reward: 4000.0, 4003.6813980020784, time: 27.487
steps: 92901, episodes: 101, mean episode reward: 1600.0, 1603.9840324859429, time: 24.898
steps: 93901, episodes: 102, mean episode reward: 0.0, 3.090938231483957, time: 28.004
steps: 94665, episodes: 103, mean episode reward: 2400.0, 2404.6207553891986, time: 20.77
steps: 95665, episodes: 104, mean episode reward: 1600.0, 1604.3801390697804, time: 28.511
steps: 96665, episodes: 105, mean episode reward: 0.0, 5.615432815975192, time: 28.889
steps: 97665, episodes: 106, mean episode reward: 0.0, 4.145654499245326, time: 29.391
StopIteration()
steps: 98665, episodes: 107, mean episode reward: 1600.0, 1603.770898891777, time: 29.808
steps: 99665, episodes: 108, mean episode reward: 800.0, 805.4592747433064, time: 29.991
steps: 100665, episodes: 109, mean episode reward: 0.0, 4.716144566096542, time: 30.253
steps: 101665, episodes: 110, mean episode reward: 1600.0, 1605.3202290887543, time: 30.334
steps: 102585, episodes: 111, mean episode reward: 0.0, 4.182973284324164, time: 27.617
steps: 103585, episodes: 112, mean episode reward: 2400.0, 2403.980718455939, time: 30.22
steps: 104585, episodes: 113, mean episode reward: 0.0, 4.1362215642922955, time: 30.434
steps: 105585, episodes: 114, mean episode reward: 0.0, 3.8990932784445302, time: 30.319
steps: 106527, episodes: 115, mean episode reward: 3200.0, 3204.2888271325146, time: 28.375
steps: 107527, episodes: 116, mean episode reward: 1600.0, 1605.5229709792306, time: 30.287
steps: 108527, episodes: 117, mean episode reward: 0.0, 5.262017748388056, time: 30.276
steps: 109527, episodes: 118, mean episode reward: 0.0, 4.495045185874692, time: 30.303
steps: 110386, episodes: 119, mean episode reward: 1600.0, 1603.5972407934269, time: 25.416
steps: 111260, episodes: 120, mean episode reward: 0.0, 4.633271715002445, time: 25.959
steps: 112260, episodes: 121, mean episode reward: 0.0, 3.8771787978017995, time: 31.595
steps: 113260, episodes: 122, mean episode reward: 2400.0, 2403.1460622585073, time: 30.825
steps: 114260, episodes: 123, mean episode reward: 3200.0, 3204.3713071967163, time: 30.242
steps: 115260, episodes: 124, mean episode reward: 2400.0, 2404.501207365324, time: 30.297
steps: 115959, episodes: 125, mean episode reward: 1600.0, 1603.5137595108063, time: 20.242
steps: 116959, episodes: 126, mean episode reward: 3200.0, 3204.478866728999, time: 30.39
steps: 117959, episodes: 127, mean episode reward: 0.0, 5.459847463368282, time: 30.341
StopIteration()
steps: 118959, episodes: 128, mean episode reward: 0.0, 3.233818785343926, time: 30.468
steps: 119959, episodes: 129, mean episode reward: 0.0, 4.1401801305672254, time: 30.322
StopIteration()
steps: 120959, episodes: 130, mean episode reward: 1600.0, 1604.128672951033, time: 30.342
steps: 121959, episodes: 131, mean episode reward: 0.0, 4.9395789381740975, time: 30.187
StopIteration()
steps: 122959, episodes: 132, mean episode reward: 0.0, 5.589187113166213, time: 30.317
steps: 123959, episodes: 133, mean episode reward: 0.0, 5.113233035301208, time: 30.238
steps: 124714, episodes: 134, mean episode reward: 0.0, 2.7401173931806113, time: 22.075
steps: 125714, episodes: 135, mean episode reward: 2400.0, 2403.8847873460672, time: 30.297
steps: 126714, episodes: 136, mean episode reward: 0.0, 4.853952592998804, time: 30.169
steps: 127714, episodes: 137, mean episode reward: 3200.0, 3203.415908895169, time: 30.277
steps: 128714, episodes: 138, mean episode reward: 1600.0, 1604.2516140009507, time: 30.187
steps: 129396, episodes: 139, mean episode reward: 1600.0, 1602.3368257770962, time: 19.584
steps: 130396, episodes: 140, mean episode reward: 2400.0, 2404.0785959538807, time: 30.223
steps: 131396, episodes: 141, mean episode reward: 1600.0, 1604.9540343631054, time: 30.156
StopIteration()
steps: 132396, episodes: 142, mean episode reward: 0.0, 3.977918287136777, time: 30.205
steps: 133396, episodes: 143, mean episode reward: 0.0, 4.396788402443984, time: 30.265
steps: 134300, episodes: 144, mean episode reward: 1600.0, 1603.9676346564972, time: 27.009
steps: 135300, episodes: 145, mean episode reward: 0.0, 4.084001574067182, time: 30.206
steps: 136300, episodes: 146, mean episode reward: 0.0, 5.255329138334033, time: 30.115
StopIteration()
steps: 137300, episodes: 147, mean episode reward: 2400.0, 2405.185121462482, time: 30.21
steps: 138239, episodes: 148, mean episode reward: 3200.0, 3203.4180093148207, time: 28.048
steps: 139239, episodes: 149, mean episode reward: 3200.0, 3204.493302234618, time: 30.21
steps: 139919, episodes: 150, mean episode reward: 0.0, 3.306601660319536, time: 19.464
steps: 140919, episodes: 151, mean episode reward: 0.0, 3.943762986004179, time: 30.118
steps: 141693, episodes: 152, mean episode reward: 0.0, 2.420124348926483, time: 22.611
StopIteration()
steps: 142693, episodes: 153, mean episode reward: 0.0, 3.9393297870111152, time: 30.064
steps: 143693, episodes: 154, mean episode reward: 0.0, 4.087293744276421, time: 30.068
steps: 144693, episodes: 155, mean episode reward: 0.0, 5.430990929321052, time: 30.209
steps: 145693, episodes: 156, mean episode reward: 0.0, 4.8630587791343025, time: 30.112
steps: 146214, episodes: 157, mean episode reward: 0.0, 2.4860513947900853, time: 14.66
StopIteration()
steps: 147214, episodes: 158, mean episode reward: 0.0, 4.3494646652577, time: 30.169
steps: 148214, episodes: 159, mean episode reward: 0.0, 5.17459587198652, time: 30.171
steps: 149022, episodes: 160, mean episode reward: 0.0, 2.9690262973975226, time: 23.679
StopIteration()
steps: 150022, episodes: 161, mean episode reward: 0.0, 4.059907675824567, time: 30.102
StopIteration()
steps: 151022, episodes: 162, mean episode reward: 3200.0, 3204.10507051113, time: 30.112
steps: 152022, episodes: 163, mean episode reward: 0.0, 5.414487422688069, time: 30.213
steps: 153022, episodes: 164, mean episode reward: 1600.0, 1604.9145625984024, time: 30.193
steps: 153761, episodes: 165, mean episode reward: 2400.0, 2402.851468657794, time: 21.405
steps: 154761, episodes: 166, mean episode reward: 1600.0, 1603.9649196282953, time: 30.084
steps: 155271, episodes: 167, mean episode reward: 0.0, 2.681019468349976, time: 14.299
steps: 156187, episodes: 168, mean episode reward: 0.0, 4.778733821461817, time: 27.164
steps: 157187, episodes: 169, mean episode reward: 1600.0, 1604.9059028579304, time: 30.07
steps: 158187, episodes: 170, mean episode reward: 0.0, 4.8115902037292, time: 29.955
steps: 159187, episodes: 171, mean episode reward: 0.0, 4.900594901128475, time: 29.941
steps: 160187, episodes: 172, mean episode reward: 0.0, 4.763019906792429, time: 29.983
steps: 161172, episodes: 173, mean episode reward: 800.0, 803.2469260017004, time: 29.583
steps: 161878, episodes: 174, mean episode reward: 0.0, 3.4846969790806317, time: 20.329
steps: 162878, episodes: 175, mean episode reward: 0.0, 5.08814029976417, time: 29.998
steps: 163878, episodes: 176, mean episode reward: 1600.0, 1604.9751363295118, time: 30.076
steps: 164878, episodes: 177, mean episode reward: 1600.0, 1604.5601499255185, time: 30.18
steps: 165878, episodes: 178, mean episode reward: 0.0, 4.6942393549005885, time: 30.0
steps: 166878, episodes: 179, mean episode reward: 1600.0, 1604.7367931727174, time: 30.081
StopIteration()
steps: 167878, episodes: 180, mean episode reward: 0.0, 4.5737622563452796, time: 30.036
steps: 168878, episodes: 181, mean episode reward: 0.0, 5.0880587196203395, time: 29.886
steps: 169878, episodes: 182, mean episode reward: 0.0, 4.340729029841348, time: 30.094
steps: 170771, episodes: 183, mean episode reward: 0.0, 4.598887817311784, time: 26.478
steps: 171601, episodes: 184, mean episode reward: 0.0, 4.676376134439471, time: 24.311
steps: 172601, episodes: 185, mean episode reward: 0.0, 2.939793930848519, time: 29.875
steps: 173601, episodes: 186, mean episode reward: 0.0, 5.398271499604424, time: 29.962
steps: 174601, episodes: 187, mean episode reward: 4000.0, 4004.8185758508907, time: 29.889
steps: 175601, episodes: 188, mean episode reward: 1600.0, 1604.4211207709359, time: 29.91
steps: 176434, episodes: 189, mean episode reward: 800.0, 804.0368228755607, time: 24.288
StopIteration()
steps: 177434, episodes: 190, mean episode reward: 4000.0, 4004.209479939702, time: 29.943
steps: 178434, episodes: 191, mean episode reward: 0.0, 4.165328211380251, time: 29.925
steps: 179049, episodes: 192, mean episode reward: 0.0, 2.9905715078060355, time: 17.402
steps: 179667, episodes: 193, mean episode reward: 0.0, 3.277976915180066, time: 17.548
steps: 180667, episodes: 194, mean episode reward: 0.0, 4.845466143073841, time: 30.028
steps: 181667, episodes: 195, mean episode reward: 1600.0, 1605.2677032666022, time: 29.962
steps: 182667, episodes: 196, mean episode reward: 1600.0, 1603.551297574525, time: 29.931
steps: 183667, episodes: 197, mean episode reward: 1600.0, 1604.586087560741, time: 29.924
steps: 184667, episodes: 198, mean episode reward: 800.0, 805.1797705900071, time: 29.95
steps: 185126, episodes: 199, mean episode reward: 1600.0, 1602.4459521785398, time: 12.827
steps: 186126, episodes: 200, mean episode reward: 800.0, 805.1772204067969, time: 29.917
steps: 187126, episodes: 201, mean episode reward: 0.0, 4.1780174434733635, time: 30.043
steps: 188126, episodes: 202, mean episode reward: 1600.0, 1605.0794072121228, time: 29.908
steps: 189126, episodes: 203, mean episode reward: 0.0, 3.041946223795264, time: 29.87
steps: 190126, episodes: 204, mean episode reward: 0.0, 4.390147578498797, time: 29.942
steps: 190448, episodes: 205, mean episode reward: 0.0, 2.0613951415741396, time: 8.78
steps: 191318, episodes: 206, mean episode reward: 0.0, 3.526106558453629, time: 25.64
StopIteration()
steps: 192318, episodes: 207, mean episode reward: 3200.0, 3204.580116212692, time: 29.853
steps: 193318, episodes: 208, mean episode reward: 0.0, 4.130236145155212, time: 29.926
steps: 194318, episodes: 209, mean episode reward: 0.0, 4.14934632708737, time: 29.851
StopIteration()
steps: 195318, episodes: 210, mean episode reward: 800.0, 804.2537381311217, time: 29.937
steps: 196318, episodes: 211, mean episode reward: 1600.0, 1604.93077579469, time: 29.913
steps: 197318, episodes: 212, mean episode reward: 0.0, 2.912054647632013, time: 29.98
steps: 198318, episodes: 213, mean episode reward: 3200.0, 3204.852648410422, time: 29.896
StopIteration()
steps: 199318, episodes: 214, mean episode reward: 1600.0, 1603.492947514625, time: 29.895
steps: 200318, episodes: 215, mean episode reward: 0.0, 5.263202296436328, time: 29.707
steps: 201318, episodes: 216, mean episode reward: 1600.0, 1604.1985020749134, time: 29.891
steps: 202222, episodes: 217, mean episode reward: 3200.0, 3203.5922668918556, time: 26.544
StopIteration()
steps: 203222, episodes: 218, mean episode reward: 2400.0, 2403.8628816301243, time: 29.823
steps: 204222, episodes: 219, mean episode reward: 0.0, 3.294382932083693, time: 29.754
steps: 205222, episodes: 220, mean episode reward: 0.0, 2.8546646936570563, time: 29.683
steps: 206182, episodes: 221, mean episode reward: 3200.0, 3203.975408510783, time: 28.261
StopIteration()
steps: 207182, episodes: 222, mean episode reward: 0.0, 5.058261019816301, time: 29.7
StopIteration()
steps: 208182, episodes: 223, mean episode reward: 0.0, 3.266166114666837, time: 29.801
steps: 208733, episodes: 224, mean episode reward: 0.0, 2.5129157755908875, time: 15.439
steps: 209733, episodes: 225, mean episode reward: 3200.0, 3205.5455449521514, time: 29.6
steps: 210733, episodes: 226, mean episode reward: 800.0, 804.2150303072893, time: 29.499
steps: 211733, episodes: 227, mean episode reward: 1600.0, 1603.371278043207, time: 29.719
steps: 212733, episodes: 228, mean episode reward: 0.0, 5.453205274987241, time: 29.722
StopIteration()
steps: 213733, episodes: 229, mean episode reward: 0.0, 3.891259413645902, time: 29.742
steps: 214733, episodes: 230, mean episode reward: 2400.0, 2403.8346018854763, time: 29.726
steps: 215733, episodes: 231, mean episode reward: 1600.0, 1604.154728595296, time: 29.738
steps: 216611, episodes: 232, mean episode reward: 0.0, 2.917300097037951, time: 25.703
steps: 217130, episodes: 233, mean episode reward: 0.0, 2.3723186675348638, time: 14.527
steps: 217819, episodes: 234, mean episode reward: 0.0, 3.499125563111235, time: 19.624
steps: 218819, episodes: 235, mean episode reward: 0.0, 4.980590187858053, time: 29.756
steps: 219819, episodes: 236, mean episode reward: 1600.0, 1604.9066811416244, time: 29.661
steps: 220819, episodes: 237, mean episode reward: 0.0, 4.761007594071598, time: 29.598
steps: 221140, episodes: 238, mean episode reward: 800.0, 801.9077864761272, time: 8.693
steps: 221809, episodes: 239, mean episode reward: 0.0, 3.033646661888534, time: 19.032
steps: 222809, episodes: 240, mean episode reward: 1600.0, 1603.3412442300196, time: 29.781
StopIteration()
steps: 223809, episodes: 241, mean episode reward: 2400.0, 2403.55910301844, time: 29.805
steps: 224809, episodes: 242, mean episode reward: 0.0, 5.546702497648632, time: 29.834
steps: 225423, episodes: 243, mean episode reward: 1600.0, 1603.0848891707217, time: 17.171
steps: 226423, episodes: 244, mean episode reward: 1600.0, 1604.5894684698856, time: 29.759
StopIteration()
steps: 227423, episodes: 245, mean episode reward: 0.0, 4.5432412033411, time: 29.852
steps: 228405, episodes: 246, mean episode reward: 1600.0, 1604.2028508924423, time: 29.204
StopIteration()
steps: 229405, episodes: 247, mean episode reward: 3200.0, 3203.4872453195812, time: 29.657
steps: 230216, episodes: 248, mean episode reward: 0.0, 2.6960683438534736, time: 23.442
StopIteration()
steps: 231216, episodes: 249, mean episode reward: 0.0, 3.789453105124679, time: 29.669
steps: 232133, episodes: 250, mean episode reward: 3200.0, 3203.9928070422393, time: 26.921
steps: 233133, episodes: 251, mean episode reward: 3200.0, 3204.8269636886953, time: 29.626
StopIteration()
steps: 234133, episodes: 252, mean episode reward: 0.0, 4.950222648355637, time: 29.686
steps: 235133, episodes: 253, mean episode reward: 0.0, 4.348663022106706, time: 29.694
steps: 235767, episodes: 254, mean episode reward: 1600.0, 1602.921530552123, time: 17.752
steps: 236767, episodes: 255, mean episode reward: 4800.0, 4804.0151149389, time: 29.803
steps: 237767, episodes: 256, mean episode reward: 1600.0, 1604.2611926185136, time: 29.595
steps: 238280, episodes: 257, mean episode reward: 3200.0, 3202.200710414754, time: 14.168
steps: 239280, episodes: 258, mean episode reward: 3200.0, 3203.6905721455073, time: 29.717
steps: 240280, episodes: 259, mean episode reward: 3200.0, 3203.5395522064764, time: 29.661
steps: 241280, episodes: 260, mean episode reward: 800.0, 803.1293646181609, time: 29.724
steps: 242280, episodes: 261, mean episode reward: 3200.0, 3204.684921466133, time: 29.754
steps: 243280, episodes: 262, mean episode reward: 1600.0, 1603.4085611573764, time: 29.773
steps: 244022, episodes: 263, mean episode reward: 0.0, 2.951781220171388, time: 21.246
steps: 244566, episodes: 264, mean episode reward: 800.0, 802.8912364057978, time: 15.082
steps: 245566, episodes: 265, mean episode reward: 0.0, 5.860218542564991, time: 29.721
steps: 246020, episodes: 266, mean episode reward: 0.0, 2.566043691132799, time: 12.567
steps: 247020, episodes: 267, mean episode reward: 2400.0, 2404.2884218131667, time: 29.768
steps: 248020, episodes: 268, mean episode reward: 1600.0, 1604.3953437940102, time: 29.749
steps: 248891, episodes: 269, mean episode reward: 2400.0, 2402.9705839348153, time: 25.441
steps: 249891, episodes: 270, mean episode reward: 0.0, 5.503618665161643, time: 29.726
steps: 250869, episodes: 271, mean episode reward: 0.0, 4.452878768737922, time: 29.035
steps: 251869, episodes: 272, mean episode reward: 1600.0, 1603.145673418628, time: 29.708
steps: 252679, episodes: 273, mean episode reward: 0.0, 3.8256856029917157, time: 23.315
StopIteration()
steps: 253679, episodes: 274, mean episode reward: 0.0, 4.124119931080883, time: 29.801
steps: 254162, episodes: 275, mean episode reward: 1600.0, 1602.0868522188925, time: 13.367
steps: 255162, episodes: 276, mean episode reward: 1600.0, 1604.4099205017926, time: 29.717
steps: 256162, episodes: 277, mean episode reward: 1600.0, 1603.4776043662212, time: 29.73
steps: 257057, episodes: 278, mean episode reward: 3200.0, 3204.2878174192742, time: 26.243
steps: 257857, episodes: 279, mean episode reward: 0.0, 3.15630165587338, time: 23.058
steps: 258624, episodes: 280, mean episode reward: 1600.0, 1604.3461666474109, time: 22.034
steps: 259215, episodes: 281, mean episode reward: 0.0, 2.8521787088493857, time: 16.652
steps: 260215, episodes: 282, mean episode reward: 0.0, 5.17653218247911, time: 29.657
steps: 261215, episodes: 283, mean episode reward: 3200.0, 3204.604444379199, time: 29.733
steps: 262215, episodes: 284, mean episode reward: 0.0, 5.954475929641075, time: 29.544
StopIteration()
steps: 263215, episodes: 285, mean episode reward: 0.0, 4.869215372018938, time: 29.734
StopIteration()
steps: 264215, episodes: 286, mean episode reward: 1600.0, 1604.374450608405, time: 29.653
steps: 265035, episodes: 287, mean episode reward: 1600.0, 1603.3794484891025, time: 23.793
steps: 265984, episodes: 288, mean episode reward: 1600.0, 1604.7896778009028, time: 27.912
steps: 266984, episodes: 289, mean episode reward: 1600.0, 1606.1170208284323, time: 29.649
steps: 267984, episodes: 290, mean episode reward: 800.0, 804.6747625319659, time: 29.732
steps: 268984, episodes: 291, mean episode reward: 0.0, 4.749366048098379, time: 29.826
steps: 269984, episodes: 292, mean episode reward: 1600.0, 1604.1509251861514, time: 29.711
steps: 270984, episodes: 293, mean episode reward: 4800.0, 4804.07462308934, time: 29.743
steps: 271984, episodes: 294, mean episode reward: 0.0, 5.126980325707767, time: 29.682
steps: 272921, episodes: 295, mean episode reward: 3200.0, 3205.2741186910152, time: 27.585
steps: 273921, episodes: 296, mean episode reward: 4000.0, 4003.8914603376415, time: 29.624
StopIteration()
steps: 274921, episodes: 297, mean episode reward: 1600.0, 1603.7216862471882, time: 29.672
steps: 275921, episodes: 298, mean episode reward: 4000.0, 4005.7616954062946, time: 29.675
steps: 276921, episodes: 299, mean episode reward: 3200.0, 3204.558798975013, time: 29.697
steps: 277921, episodes: 300, mean episode reward: 0.0, 5.824209912212686, time: 29.6
steps: 278921, episodes: 301, mean episode reward: 1600.0, 1604.4722642761412, time: 29.757
steps: 279921, episodes: 302, mean episode reward: 1600.0, 1604.7716329076547, time: 29.77
steps: 280921, episodes: 303, mean episode reward: 0.0, 4.270300854341616, time: 29.749
steps: 281921, episodes: 304, mean episode reward: 0.0, 4.845180214936948, time: 29.651
steps: 282921, episodes: 305, mean episode reward: 800.0, 805.044520090346, time: 29.815
StopIteration()
steps: 283921, episodes: 306, mean episode reward: 0.0, 5.295658769001899, time: 29.626
steps: 284921, episodes: 307, mean episode reward: 4000.0, 4004.4157144774636, time: 29.831
steps: 285921, episodes: 308, mean episode reward: 3200.0, 3204.2248643092835, time: 29.8
StopIteration()
steps: 286921, episodes: 309, mean episode reward: 4000.0, 4004.009797534468, time: 29.681
steps: 287891, episodes: 310, mean episode reward: 0.0, 4.612202006894038, time: 28.616
steps: 288891, episodes: 311, mean episode reward: 0.0, 3.5640454919791082, time: 29.781
steps: 289891, episodes: 312, mean episode reward: 0.0, 5.477371328186843, time: 29.742
steps: 290891, episodes: 313, mean episode reward: 0.0, 5.983322132428311, time: 29.597
steps: 291891, episodes: 314, mean episode reward: 3200.0, 3204.3484208262353, time: 29.625
steps: 292615, episodes: 315, mean episode reward: 0.0, 2.612100713733301, time: 20.666
steps: 293615, episodes: 316, mean episode reward: 0.0, 4.386961974382845, time: 29.573
steps: 294615, episodes: 317, mean episode reward: 2400.0, 2404.249737759146, time: 29.677
steps: 295426, episodes: 318, mean episode reward: 2400.0, 2403.8856713500973, time: 23.417
steps: 296265, episodes: 319, mean episode reward: 1600.0, 1603.074270844017, time: 24.335
steps: 297265, episodes: 320, mean episode reward: 0.0, 5.9116374909262115, time: 29.754
steps: 298215, episodes: 321, mean episode reward: 0.0, 4.986186746416475, time: 28.067
steps: 299215, episodes: 322, mean episode reward: 0.0, 5.600089432642771, time: 29.735
steps: 299930, episodes: 323, mean episode reward: 1600.0, 1602.9595094671643, time: 20.463
steps: 300753, episodes: 324, mean episode reward: 0.0, 2.416225102585937, time: 23.927
steps: 301597, episodes: 325, mean episode reward: 1600.0, 1603.9676302861833, time: 24.427
steps: 302597, episodes: 326, mean episode reward: 800.0, 804.1510628344055, time: 29.793
steps: 303597, episodes: 327, mean episode reward: 0.0, 4.528619279072276, time: 29.814
steps: 304597, episodes: 328, mean episode reward: 0.0, 3.344091889702905, time: 29.733
StopIteration()
steps: 305597, episodes: 329, mean episode reward: 0.0, 4.56499660164107, time: 29.717
steps: 306597, episodes: 330, mean episode reward: 0.0, 5.348997096296172, time: 29.754
steps: 307597, episodes: 331, mean episode reward: 2400.0, 2403.9281668360586, time: 29.856
steps: 308597, episodes: 332, mean episode reward: 800.0, 804.370095832633, time: 29.741
StopIteration()
steps: 309597, episodes: 333, mean episode reward: 0.0, 5.701134910657186, time: 29.777
steps: 310597, episodes: 334, mean episode reward: 800.0, 804.182107964398, time: 29.715
steps: 311597, episodes: 335, mean episode reward: 1600.0, 1605.0302810849873, time: 29.782
steps: 312274, episodes: 336, mean episode reward: 1600.0, 1604.4244956230868, time: 19.118
steps: 313105, episodes: 337, mean episode reward: 800.0, 804.0894060888631, time: 24.145
steps: 314105, episodes: 338, mean episode reward: 800.0, 803.893610189671, time: 29.637
steps: 315105, episodes: 339, mean episode reward: 2400.0, 2403.8942697517114, time: 29.663
steps: 315931, episodes: 340, mean episode reward: 1600.0, 1603.6505455889865, time: 23.983
steps: 316931, episodes: 341, mean episode reward: 0.0, 4.970500118655299, time: 29.612
steps: 317931, episodes: 342, mean episode reward: 0.0, 3.3137734188126795, time: 29.729
steps: 318560, episodes: 343, mean episode reward: 0.0, 3.802129684340308, time: 17.578
steps: 319560, episodes: 344, mean episode reward: 0.0, 4.570743862224922, time: 29.646
StopIteration()
steps: 320560, episodes: 345, mean episode reward: 1600.0, 1603.1717715672262, time: 29.759
steps: 321560, episodes: 346, mean episode reward: 0.0, 5.911877054938819, time: 29.691
steps: 322560, episodes: 347, mean episode reward: 0.0, 3.9199247885542956, time: 29.726
steps: 323560, episodes: 348, mean episode reward: 800.0, 804.2247814132545, time: 29.665
steps: 324396, episodes: 349, mean episode reward: 1600.0, 1603.7295575724027, time: 24.215
steps: 325396, episodes: 350, mean episode reward: 0.0, 5.215676904063213, time: 29.791
steps: 326396, episodes: 351, mean episode reward: 1600.0, 1604.4376991209647, time: 29.649
steps: 327396, episodes: 352, mean episode reward: 1600.0, 1603.602724646423, time: 29.755
steps: 328396, episodes: 353, mean episode reward: 800.0, 804.2628200982347, time: 29.785
steps: 329396, episodes: 354, mean episode reward: 1600.0, 1605.0216051460156, time: 29.873
steps: 330322, episodes: 355, mean episode reward: 0.0, 4.429395933540734, time: 27.46
steps: 331322, episodes: 356, mean episode reward: 1600.0, 1605.0312832633647, time: 29.735
steps: 332093, episodes: 357, mean episode reward: 1600.0, 1604.3579938738592, time: 22.241
steps: 333025, episodes: 358, mean episode reward: 0.0, 4.093309380192495, time: 27.648
steps: 334025, episodes: 359, mean episode reward: 0.0, 4.966281446087346, time: 29.739
steps: 334908, episodes: 360, mean episode reward: 0.0, 3.26370296111215, time: 26.011
steps: 335908, episodes: 361, mean episode reward: 0.0, 4.97683046189958, time: 29.827
StopIteration()
steps: 336908, episodes: 362, mean episode reward: 0.0, 4.845712866516253, time: 29.925
steps: 337652, episodes: 363, mean episode reward: 0.0, 3.6490570218129235, time: 21.308
steps: 338652, episodes: 364, mean episode reward: 1600.0, 1605.261475248354, time: 29.781
steps: 339652, episodes: 365, mean episode reward: 0.0, 4.493301478011599, time: 29.959
StopIteration()
steps: 340652, episodes: 366, mean episode reward: 0.0, 4.216163189686415, time: 29.955
steps: 341652, episodes: 367, mean episode reward: 0.0, 4.207611143302225, time: 29.933
StopIteration()
steps: 342652, episodes: 368, mean episode reward: 0.0, 4.731468948820445, time: 29.91
steps: 343652, episodes: 369, mean episode reward: 0.0, 5.323759294262323, time: 29.832
steps: 344652, episodes: 370, mean episode reward: 3200.0, 3204.6802647728264, time: 29.844
steps: 345562, episodes: 371, mean episode reward: 1600.0, 1603.8315873599663, time: 26.921
StopIteration()
steps: 346562, episodes: 372, mean episode reward: 0.0, 4.64838234537461, time: 30.18
steps: 347562, episodes: 373, mean episode reward: 1600.0, 1603.7849155836684, time: 29.926
StopIteration()
steps: 348562, episodes: 374, mean episode reward: 4000.0, 4004.8228658744656, time: 29.811
steps: 349562, episodes: 375, mean episode reward: 0.0, 4.387811406507597, time: 29.888
steps: 350334, episodes: 376, mean episode reward: 1600.0, 1604.2483930177195, time: 22.335
steps: 351334, episodes: 377, mean episode reward: 0.0, 5.1725335910401355, time: 29.697
steps: 352191, episodes: 378, mean episode reward: 1600.0, 1604.317587703896, time: 25.017
steps: 353139, episodes: 379, mean episode reward: 0.0, 3.7837646098096913, time: 28.162
steps: 354078, episodes: 380, mean episode reward: 1600.0, 1603.9283268156673, time: 27.78
steps: 355078, episodes: 381, mean episode reward: 800.0, 805.4506964035243, time: 29.796
StopIteration()
steps: 356078, episodes: 382, mean episode reward: 2400.0, 2404.0886158888734, time: 29.721
StopIteration()
steps: 357078, episodes: 383, mean episode reward: 0.0, 4.167201802664101, time: 29.728
steps: 358078, episodes: 384, mean episode reward: 0.0, 5.422626821318093, time: 29.772
steps: 358782, episodes: 385, mean episode reward: 1600.0, 1603.4983793778467, time: 20.003
steps: 359782, episodes: 386, mean episode reward: 0.0, 4.591839445563217, time: 29.716
steps: 360205, episodes: 387, mean episode reward: 0.0, 2.569123098637389, time: 11.729
steps: 361205, episodes: 388, mean episode reward: 1600.0, 1603.9351879222158, time: 29.776
steps: 362205, episodes: 389, mean episode reward: 0.0, 5.11235310281595, time: 29.76
steps: 362929, episodes: 390, mean episode reward: 0.0, 3.8069564888633733, time: 20.682
steps: 363623, episodes: 391, mean episode reward: 0.0, 3.5408610901616497, time: 19.938
steps: 364516, episodes: 392, mean episode reward: 1600.0, 1603.868051373108, time: 26.331
steps: 365516, episodes: 393, mean episode reward: 1600.0, 1604.9642523473208, time: 29.638
steps: 366382, episodes: 394, mean episode reward: 0.0, 4.950918483949525, time: 25.285
steps: 367382, episodes: 395, mean episode reward: 3200.0, 3204.718579555527, time: 29.782
steps: 368382, episodes: 396, mean episode reward: 0.0, 4.092050583305519, time: 29.912
StopIteration()
steps: 369382, episodes: 397, mean episode reward: 1600.0, 1605.0819103666886, time: 29.764
steps: 370382, episodes: 398, mean episode reward: 0.0, 5.430299685092312, time: 29.794
steps: 370856, episodes: 399, mean episode reward: 0.0, 2.1374940918104763, time: 13.083
steps: 371856, episodes: 400, mean episode reward: 0.0, 4.831204789393199, time: 29.767
steps: 372856, episodes: 401, mean episode reward: 0.0, 4.257516356443212, time: 29.822
steps: 373683, episodes: 402, mean episode reward: 2400.0, 2403.844542318948, time: 24.1
steps: 374683, episodes: 403, mean episode reward: 0.0, 3.995453765448147, time: 29.877
steps: 375683, episodes: 404, mean episode reward: 1600.0, 1603.6189256311488, time: 29.829
steps: 376594, episodes: 405, mean episode reward: 3200.0, 3203.7066706157348, time: 26.934
StopIteration()
steps: 377594, episodes: 406, mean episode reward: 0.0, 5.007201222868201, time: 29.904
steps: 378480, episodes: 407, mean episode reward: 0.0, 4.340503925434909, time: 26.159
steps: 379480, episodes: 408, mean episode reward: 0.0, 5.5327373176406915, time: 29.824
steps: 380480, episodes: 409, mean episode reward: 800.0, 804.3679669311126, time: 29.627
steps: 381258, episodes: 410, mean episode reward: 0.0, 3.37430721586682, time: 22.525
steps: 382258, episodes: 411, mean episode reward: 0.0, 4.792863846238136, time: 29.832
StopIteration()
steps: 383258, episodes: 412, mean episode reward: 3200.0, 3204.4537604634124, time: 29.739
StopIteration()
steps: 384258, episodes: 413, mean episode reward: 0.0, 4.455507394746092, time: 29.913
steps: 385258, episodes: 414, mean episode reward: 0.0, 5.510727195188837, time: 29.836
steps: 386132, episodes: 415, mean episode reward: 800.0, 803.306710267974, time: 25.617
steps: 387132, episodes: 416, mean episode reward: 0.0, 3.5405072372515214, time: 29.791
steps: 388025, episodes: 417, mean episode reward: 4800.0, 4803.9863660367355, time: 26.182
steps: 389025, episodes: 418, mean episode reward: 3200.0, 3203.7070224553627, time: 29.686
steps: 389859, episodes: 419, mean episode reward: 0.0, 2.70587920291527, time: 24.24
steps: 390514, episodes: 420, mean episode reward: 0.0, 3.535369303285278, time: 18.537
steps: 391514, episodes: 421, mean episode reward: 3200.0, 3204.418141011469, time: 29.699
steps: 392105, episodes: 422, mean episode reward: 0.0, 2.782325252868441, time: 16.575
steps: 393105, episodes: 423, mean episode reward: 3200.0, 3205.13000930939, time: 29.724
steps: 393977, episodes: 424, mean episode reward: 0.0, 5.0575542077459055, time: 25.484
steps: 394977, episodes: 425, mean episode reward: 1600.0, 1603.8016726640637, time: 29.67
steps: 395977, episodes: 426, mean episode reward: 0.0, 3.9878786996609716, time: 29.79
steps: 396977, episodes: 427, mean episode reward: 0.0, 5.289519784617941, time: 29.786
steps: 397977, episodes: 428, mean episode reward: 3200.0, 3203.7111415120735, time: 29.736
steps: 398977, episodes: 429, mean episode reward: 0.0, 5.3220495744110075, time: 29.773
steps: 399908, episodes: 430, mean episode reward: 0.0, 3.4454718264410205, time: 27.465
steps: 400780, episodes: 431, mean episode reward: 800.0, 804.6472302915566, time: 25.368
StopIteration()
steps: 401780, episodes: 432, mean episode reward: 800.0, 804.4030015215724, time: 29.81
steps: 402268, episodes: 433, mean episode reward: 0.0, 1.9938075366390564, time: 13.54
steps: 403268, episodes: 434, mean episode reward: 1600.0, 1603.6047808298113, time: 29.787
steps: 404268, episodes: 435, mean episode reward: 1600.0, 1604.5699428682003, time: 29.659
StopIteration()
steps: 405268, episodes: 436, mean episode reward: 1600.0, 1603.8878081609496, time: 29.71
StopIteration()
steps: 406268, episodes: 437, mean episode reward: 800.0, 804.0001267390344, time: 29.705
steps: 406989, episodes: 438, mean episode reward: 0.0, 3.5603118023775586, time: 20.492
steps: 407989, episodes: 439, mean episode reward: 0.0, 4.63007570447748, time: 29.797
steps: 408989, episodes: 440, mean episode reward: 1600.0, 1604.1303730403909, time: 29.65
StopIteration()
steps: 409989, episodes: 441, mean episode reward: 0.0, 4.497219908369446, time: 29.726
steps: 410930, episodes: 442, mean episode reward: 0.0, 3.3792832354968394, time: 27.71
steps: 411845, episodes: 443, mean episode reward: 0.0, 3.631054069145386, time: 26.949
steps: 412555, episodes: 444, mean episode reward: 0.0, 3.0752669370849075, time: 20.134
steps: 413461, episodes: 445, mean episode reward: 1600.0, 1603.3618406971218, time: 26.561
steps: 414461, episodes: 446, mean episode reward: 3200.0, 3204.7707940493833, time: 29.746
steps: 415461, episodes: 447, mean episode reward: 1600.0, 1603.0975317950224, time: 29.65
steps: 416461, episodes: 448, mean episode reward: 1600.0, 1604.146431162652, time: 29.638
steps: 417461, episodes: 449, mean episode reward: 800.0, 804.0955392512197, time: 29.638
steps: 418461, episodes: 450, mean episode reward: 1600.0, 1604.580451127737, time: 29.602
steps: 419461, episodes: 451, mean episode reward: 0.0, 4.853900115282616, time: 29.634
steps: 420235, episodes: 452, mean episode reward: 1600.0, 1603.2472919526845, time: 22.28
steps: 421235, episodes: 453, mean episode reward: 0.0, 5.136161695848143, time: 29.674
steps: 421997, episodes: 454, mean episode reward: 0.0, 3.07345372422109, time: 21.85
steps: 422997, episodes: 455, mean episode reward: 0.0, 4.860871923274997, time: 29.786
StopIteration()
steps: 423997, episodes: 456, mean episode reward: 1600.0, 1604.4849437472672, time: 29.623
steps: 424997, episodes: 457, mean episode reward: 2400.0, 2404.2017646498043, time: 29.74
steps: 425997, episodes: 458, mean episode reward: 4000.0, 4004.1205554102307, time: 29.661
StopIteration()
steps: 426997, episodes: 459, mean episode reward: 0.0, 5.178096246205523, time: 29.684
steps: 427997, episodes: 460, mean episode reward: 1600.0, 1605.0475345742934, time: 29.667
StopIteration()
steps: 428997, episodes: 461, mean episode reward: 2400.0, 2404.671902013524, time: 29.716
steps: 429353, episodes: 462, mean episode reward: 0.0, 1.4615773944053108, time: 9.724
steps: 429920, episodes: 463, mean episode reward: 0.0, 2.1113260770788203, time: 15.893
steps: 430920, episodes: 464, mean episode reward: 0.0, 4.053495440041127, time: 29.844
steps: 431231, episodes: 465, mean episode reward: 0.0, 1.5514948855436752, time: 8.395
steps: 432086, episodes: 466, mean episode reward: 0.0, 4.226439723328345, time: 24.772
StopIteration()
steps: 433086, episodes: 467, mean episode reward: 1600.0, 1603.9689461986352, time: 29.627
steps: 434086, episodes: 468, mean episode reward: 0.0, 4.511223166833206, time: 29.645
StopIteration()
steps: 435086, episodes: 469, mean episode reward: 0.0, 3.559139395612177, time: 29.667
steps: 436086, episodes: 470, mean episode reward: 3200.0, 3204.7309884035976, time: 29.52
steps: 437037, episodes: 471, mean episode reward: 1600.0, 1604.9549201207599, time: 27.993
StopIteration()
steps: 438037, episodes: 472, mean episode reward: 0.0, 4.304255912461971, time: 29.453
steps: 438833, episodes: 473, mean episode reward: 0.0, 3.3301356232411368, time: 22.77
steps: 439833, episodes: 474, mean episode reward: 0.0, 5.528377093992719, time: 29.57
steps: 440833, episodes: 475, mean episode reward: 0.0, 5.091815787334213, time: 29.553
steps: 441707, episodes: 476, mean episode reward: 2400.0, 2403.906544112381, time: 25.329
steps: 442707, episodes: 477, mean episode reward: 1600.0, 1604.1531207458338, time: 29.561
steps: 443575, episodes: 478, mean episode reward: 0.0, 4.3746117460077105, time: 25.197
steps: 444575, episodes: 479, mean episode reward: 3200.0, 3204.240520830184, time: 29.594
steps: 445575, episodes: 480, mean episode reward: 4000.0, 4004.6431765261786, time: 29.624
steps: 446575, episodes: 481, mean episode reward: 0.0, 5.265443086700803, time: 29.514
steps: 447575, episodes: 482, mean episode reward: 1600.0, 1605.221481863059, time: 29.662
steps: 448575, episodes: 483, mean episode reward: 1600.0, 1604.799006353518, time: 29.66
steps: 449575, episodes: 484, mean episode reward: 800.0, 804.9959865123808, time: 29.706
steps: 450575, episodes: 485, mean episode reward: 0.0, 5.004851978426016, time: 29.564
steps: 451575, episodes: 486, mean episode reward: 0.0, 4.517021628778191, time: 29.666
steps: 452398, episodes: 487, mean episode reward: 1600.0, 1603.449998466609, time: 23.848
steps: 453229, episodes: 488, mean episode reward: 0.0, 3.129703904154916, time: 24.068
steps: 454229, episodes: 489, mean episode reward: 0.0, 4.656281905947629, time: 29.63
steps: 455067, episodes: 490, mean episode reward: 0.0, 3.1470925181494813, time: 24.21
steps: 455732, episodes: 491, mean episode reward: 4000.0, 4002.8718287759098, time: 18.695
steps: 456732, episodes: 492, mean episode reward: 800.0, 804.2099480631827, time: 29.515
steps: 457732, episodes: 493, mean episode reward: 1600.0, 1604.8007536925977, time: 29.745
steps: 458732, episodes: 494, mean episode reward: 800.0, 804.4711213316642, time: 29.647
steps: 459732, episodes: 495, mean episode reward: 0.0, 5.21288541338214, time: 29.628
steps: 460562, episodes: 496, mean episode reward: 1600.0, 1603.1679567472727, time: 24.065
steps: 461562, episodes: 497, mean episode reward: 1600.0, 1604.8162869541347, time: 29.589
steps: 462314, episodes: 498, mean episode reward: 0.0, 3.313142709908387, time: 21.595
steps: 463314, episodes: 499, mean episode reward: 1600.0, 1605.278745043731, time: 29.565
steps: 464314, episodes: 500, mean episode reward: 1600.0, 1605.5340506243335, time: 29.559
steps: 464966, episodes: 501, mean episode reward: 0.0, 3.434794344443418, time: 18.155
steps: 465966, episodes: 502, mean episode reward: 800.0, 805.0590358841782, time: 29.561
steps: 466866, episodes: 503, mean episode reward: 0.0, 4.36734553291264, time: 26.212
steps: 467866, episodes: 504, mean episode reward: 1600.0, 1604.7129504545737, time: 29.692
steps: 468866, episodes: 505, mean episode reward: 0.0, 4.164369881451179, time: 29.61
steps: 469866, episodes: 506, mean episode reward: 1600.0, 1604.8431967690387, time: 29.787
steps: 470759, episodes: 507, mean episode reward: 1600.0, 1604.947976148567, time: 26.132
steps: 471759, episodes: 508, mean episode reward: 0.0, 3.814702977026831, time: 29.586
steps: 472759, episodes: 509, mean episode reward: 1600.0, 1605.034903657653, time: 29.645
steps: 473653, episodes: 510, mean episode reward: 0.0, 4.669658483958931, time: 26.122
StopIteration()
steps: 474653, episodes: 511, mean episode reward: 800.0, 804.8716874144567, time: 29.598
steps: 475653, episodes: 512, mean episode reward: 0.0, 4.494924426888437, time: 29.635
steps: 476653, episodes: 513, mean episode reward: 1600.0, 1604.416789178481, time: 29.613
steps: 477494, episodes: 514, mean episode reward: 0.0, 4.157625865708034, time: 24.436
steps: 478494, episodes: 515, mean episode reward: 0.0, 4.331944261836866, time: 29.64
StopIteration()
steps: 479494, episodes: 516, mean episode reward: 1600.0, 1605.3236952548755, time: 29.605
steps: 480482, episodes: 517, mean episode reward: 1600.0, 1603.2926304734358, time: 29.334
steps: 481482, episodes: 518, mean episode reward: 0.0, 4.47604620579075, time: 29.77
steps: 482482, episodes: 519, mean episode reward: 0.0, 5.306513498529209, time: 29.808
StopIteration()
steps: 483482, episodes: 520, mean episode reward: 0.0, 4.535280751805223, time: 29.852
steps: 484202, episodes: 521, mean episode reward: 1600.0, 1603.7532990288626, time: 20.56
steps: 485162, episodes: 522, mean episode reward: 0.0, 5.336548929740975, time: 28.264
steps: 486162, episodes: 523, mean episode reward: 0.0, 5.236917222445381, time: 29.851
steps: 487162, episodes: 524, mean episode reward: 3200.0, 3204.078019760129, time: 29.678
steps: 488162, episodes: 525, mean episode reward: 2400.0, 2404.5621960885246, time: 29.802
steps: 489162, episodes: 526, mean episode reward: 0.0, 5.556054498355061, time: 29.667
steps: 490162, episodes: 527, mean episode reward: 0.0, 4.417241764462146, time: 29.719
steps: 491162, episodes: 528, mean episode reward: 1600.0, 1604.4549468557361, time: 29.736
StopIteration()
steps: 492162, episodes: 529, mean episode reward: 1600.0, 1604.6271974543256, time: 29.683
steps: 493162, episodes: 530, mean episode reward: 2400.0, 2404.368337905529, time: 29.798
steps: 494162, episodes: 531, mean episode reward: 3200.0, 3204.601321479353, time: 29.719
steps: 495162, episodes: 532, mean episode reward: 1600.0, 1604.0334462452818, time: 29.76
steps: 495876, episodes: 533, mean episode reward: 0.0, 4.028203539365687, time: 20.387
steps: 496876, episodes: 534, mean episode reward: 0.0, 4.891594690927397, time: 29.797
steps: 497876, episodes: 535, mean episode reward: 0.0, 4.905110516893483, time: 29.754
steps: 498876, episodes: 536, mean episode reward: 0.0, 5.209298190974732, time: 29.717
steps: 499410, episodes: 537, mean episode reward: 0.0, 2.8020557593977067, time: 14.906
steps: 500410, episodes: 538, mean episode reward: 0.0, 4.853938261944245, time: 29.759
StopIteration()
steps: 501410, episodes: 539, mean episode reward: 2400.0, 2404.815616625197, time: 29.732
steps: 502410, episodes: 540, mean episode reward: 1600.0, 1604.981336061698, time: 29.765
StopIteration()
steps: 503410, episodes: 541, mean episode reward: 800.0, 804.6564281835555, time: 29.709
StopIteration()
steps: 504410, episodes: 542, mean episode reward: 800.0, 804.3442288030342, time: 29.812
steps: 505410, episodes: 543, mean episode reward: 3200.0, 3204.2207830376738, time: 29.683
steps: 506410, episodes: 544, mean episode reward: 2400.0, 2404.4959847870446, time: 29.732
steps: 507299, episodes: 545, mean episode reward: 800.0, 804.1825057717175, time: 26.011
steps: 508299, episodes: 546, mean episode reward: 0.0, 5.090006529320622, time: 29.776
steps: 509299, episodes: 547, mean episode reward: 0.0, 4.667228422287185, time: 29.739
StopIteration()
steps: 510299, episodes: 548, mean episode reward: 0.0, 4.734198923437142, time: 29.837
steps: 511135, episodes: 549, mean episode reward: 0.0, 3.800882709228259, time: 24.396
StopIteration()
steps: 512135, episodes: 550, mean episode reward: 0.0, 4.450311752067069, time: 29.802
steps: 513135, episodes: 551, mean episode reward: 1600.0, 1604.452689419553, time: 29.85
steps: 514135, episodes: 552, mean episode reward: 1600.0, 1604.517167717109, time: 29.773
steps: 515010, episodes: 553, mean episode reward: 0.0, 4.162688001096549, time: 25.758
steps: 515734, episodes: 554, mean episode reward: 0.0, 3.6471822391004296, time: 20.64
steps: 516475, episodes: 555, mean episode reward: 1600.0, 1603.203639708111, time: 21.265
steps: 517361, episodes: 556, mean episode reward: 1600.0, 1604.018612242424, time: 26.101
steps: 518361, episodes: 557, mean episode reward: 1600.0, 1604.54739704681, time: 29.77
steps: 519361, episodes: 558, mean episode reward: 1600.0, 1604.4947526342833, time: 29.802
steps: 520361, episodes: 559, mean episode reward: 4800.0, 4803.28579367633, time: 29.882
steps: 521012, episodes: 560, mean episode reward: 0.0, 2.349608141549185, time: 18.463
steps: 522012, episodes: 561, mean episode reward: 0.0, 3.306794054698712, time: 29.819
steps: 523012, episodes: 562, mean episode reward: 0.0, 3.579345173314853, time: 29.855
steps: 524012, episodes: 563, mean episode reward: 1600.0, 1603.6956323800623, time: 29.805
steps: 525012, episodes: 564, mean episode reward: 0.0, 3.937968100766252, time: 29.824
steps: 526012, episodes: 565, mean episode reward: 1600.0, 1603.8997451502046, time: 29.952
steps: 527012, episodes: 566, mean episode reward: 0.0, 3.4310558790152506, time: 29.788
StopIteration()
steps: 528012, episodes: 567, mean episode reward: 0.0, 4.221800481400084, time: 29.856
steps: 528851, episodes: 568, mean episode reward: 0.0, 4.104952657294254, time: 24.394
steps: 529539, episodes: 569, mean episode reward: 4800.0, 4802.266308792908, time: 19.574
steps: 530515, episodes: 570, mean episode reward: 0.0, 2.9117232773058817, time: 29.304
steps: 531273, episodes: 571, mean episode reward: 0.0, 2.40427398743769, time: 21.82
steps: 532107, episodes: 572, mean episode reward: 0.0, 3.8582280859391482, time: 24.367
steps: 532804, episodes: 573, mean episode reward: 0.0, 2.8748174351703977, time: 19.892
steps: 533804, episodes: 574, mean episode reward: 1600.0, 1604.4476901670141, time: 29.723
steps: 534804, episodes: 575, mean episode reward: 0.0, 4.931133534943565, time: 29.741
steps: 535804, episodes: 576, mean episode reward: 1600.0, 1603.140033877036, time: 29.852
steps: 536804, episodes: 577, mean episode reward: 0.0, 3.3103316829615284, time: 29.789
steps: 537804, episodes: 578, mean episode reward: 0.0, 4.107650832778868, time: 29.775
steps: 538804, episodes: 579, mean episode reward: 0.0, 5.020797681010331, time: 29.836
steps: 539804, episodes: 580, mean episode reward: 1600.0, 1604.0187562539727, time: 29.776
StopIteration()
steps: 540804, episodes: 581, mean episode reward: 800.0, 802.9802238936578, time: 29.817
steps: 541804, episodes: 582, mean episode reward: 0.0, 3.0885831692447714, time: 29.825
steps: 542804, episodes: 583, mean episode reward: 800.0, 802.926585312599, time: 29.834
steps: 543804, episodes: 584, mean episode reward: 0.0, 4.953372337379083, time: 29.757
steps: 544804, episodes: 585, mean episode reward: 0.0, 4.19686344802735, time: 29.722
StopIteration()
steps: 545804, episodes: 586, mean episode reward: 0.0, 5.033625460885896, time: 29.582
steps: 546804, episodes: 587, mean episode reward: 1600.0, 1604.3360770084914, time: 29.754
steps: 547324, episodes: 588, mean episode reward: 0.0, 2.392019838816443, time: 14.407
steps: 548324, episodes: 589, mean episode reward: 0.0, 5.226427113066207, time: 29.742
StopIteration()
steps: 549324, episodes: 590, mean episode reward: 1600.0, 1604.031625793119, time: 29.631
steps: 550324, episodes: 591, mean episode reward: 1600.0, 1604.8782208529476, time: 29.711
steps: 551324, episodes: 592, mean episode reward: 1600.0, 1604.4242396430134, time: 29.845
steps: 552324, episodes: 593, mean episode reward: 3200.0, 3204.5596748643443, time: 29.704
steps: 553324, episodes: 594, mean episode reward: 3200.0, 3205.1359604787776, time: 29.731
steps: 554031, episodes: 595, mean episode reward: 0.0, 4.114155638985092, time: 20.185
steps: 555031, episodes: 596, mean episode reward: 1600.0, 1602.9613646045973, time: 29.799
steps: 556031, episodes: 597, mean episode reward: 0.0, 4.108482201604372, time: 29.733
steps: 557031, episodes: 598, mean episode reward: 800.0, 804.5262020535542, time: 29.814
steps: 558031, episodes: 599, mean episode reward: 1600.0, 1605.2750077188246, time: 29.799
StopIteration()
steps: 559031, episodes: 600, mean episode reward: 0.0, 3.773109125563938, time: 29.8
steps: 560031, episodes: 601, mean episode reward: 1600.0, 1603.5933620158671, time: 29.825
steps: 560709, episodes: 602, mean episode reward: 0.0, 2.44164461695869, time: 19.323
steps: 561495, episodes: 603, mean episode reward: 0.0, 4.37349943018953, time: 22.514
steps: 562023, episodes: 604, mean episode reward: 0.0, 3.024477158394934, time: 14.719
steps: 563004, episodes: 605, mean episode reward: 2400.0, 2404.239670787321, time: 29.141
steps: 564004, episodes: 606, mean episode reward: 4000.0, 4003.987975456885, time: 29.826
steps: 565004, episodes: 607, mean episode reward: 1600.0, 1603.277050556077, time: 29.775
steps: 566004, episodes: 608, mean episode reward: 0.0, 4.36043676830731, time: 29.78
steps: 566904, episodes: 609, mean episode reward: 0.0, 3.4370489614750626, time: 26.426
steps: 567904, episodes: 610, mean episode reward: 0.0, 5.043879545584401, time: 29.739
steps: 568904, episodes: 611, mean episode reward: 800.0, 803.4569504942266, time: 29.753
steps: 569904, episodes: 612, mean episode reward: 1600.0, 1604.8753714793625, time: 29.863
steps: 570904, episodes: 613, mean episode reward: 0.0, 3.606192950568844, time: 29.782
steps: 571904, episodes: 614, mean episode reward: 0.0, 4.760017495155865, time: 29.707
steps: 572904, episodes: 615, mean episode reward: 2400.0, 2404.7265143299633, time: 29.811
steps: 573904, episodes: 616, mean episode reward: 2400.0, 2403.2693202601, time: 29.754
steps: 574682, episodes: 617, mean episode reward: 1600.0, 1603.8173344973104, time: 22.512
steps: 575682, episodes: 618, mean episode reward: 800.0, 803.7122360563255, time: 29.977
steps: 576662, episodes: 619, mean episode reward: 1600.0, 1605.0207582300884, time: 29.225
steps: 577662, episodes: 620, mean episode reward: 0.0, 5.172102125864696, time: 29.808
steps: 578662, episodes: 621, mean episode reward: 3200.0, 3202.959436224208, time: 29.807
StopIteration()
steps: 579662, episodes: 622, mean episode reward: 0.0, 5.01284164920555, time: 29.81
steps: 580662, episodes: 623, mean episode reward: 0.0, 5.3372901884525605, time: 29.89
steps: 581662, episodes: 624, mean episode reward: 0.0, 5.740538626072095, time: 32.499
StopIteration()
steps: 582662, episodes: 625, mean episode reward: 0.0, 5.277441664134925, time: 34.011
steps: 583662, episodes: 626, mean episode reward: 3200.0, 3205.0344125922343, time: 30.921
steps: 584662, episodes: 627, mean episode reward: 3200.0, 3204.086225000801, time: 34.005
steps: 585453, episodes: 628, mean episode reward: 1600.0, 1604.1567078542946, time: 22.828
steps: 586143, episodes: 629, mean episode reward: 3200.0, 3202.9107642919207, time: 19.664
steps: 586821, episodes: 630, mean episode reward: 0.0, 3.8675635791693823, time: 19.323
steps: 587821, episodes: 631, mean episode reward: 2400.0, 2403.8188563460885, time: 29.733
steps: 588500, episodes: 632, mean episode reward: 1600.0, 1603.5064975406747, time: 19.439
steps: 589176, episodes: 633, mean episode reward: 0.0, 2.7759349491960372, time: 19.208
steps: 590176, episodes: 634, mean episode reward: 3200.0, 3204.7172811224536, time: 29.761
steps: 591176, episodes: 635, mean episode reward: 0.0, 5.410907522192229, time: 30.109
steps: 592176, episodes: 636, mean episode reward: 1600.0, 1603.7935398766851, time: 29.897
steps: 593176, episodes: 637, mean episode reward: 1600.0, 1604.6803842302252, time: 29.901
steps: 594176, episodes: 638, mean episode reward: 0.0, 3.49554864720991, time: 29.963
steps: 595176, episodes: 639, mean episode reward: 1600.0, 1605.243279625853, time: 29.848
steps: 596176, episodes: 640, mean episode reward: 3200.0, 3203.403908308775, time: 29.714
steps: 597176, episodes: 641, mean episode reward: 800.0, 805.4789477945469, time: 29.833
steps: 597723, episodes: 642, mean episode reward: 2400.0, 2402.7011572982374, time: 15.265
steps: 598704, episodes: 643, mean episode reward: 0.0, 5.073170361456371, time: 29.218
StopIteration()
steps: 599704, episodes: 644, mean episode reward: 0.0, 5.187926283103642, time: 29.761
steps: 600704, episodes: 645, mean episode reward: 0.0, 5.389702701054695, time: 29.766
steps: 601655, episodes: 646, mean episode reward: 0.0, 5.047765321538714, time: 28.075
steps: 602655, episodes: 647, mean episode reward: 800.0, 805.1210283339708, time: 29.811
steps: 603449, episodes: 648, mean episode reward: 0.0, 3.290685285567732, time: 23.019
steps: 604449, episodes: 649, mean episode reward: 0.0, 5.28183757991767, time: 29.834
StopIteration()
steps: 605449, episodes: 650, mean episode reward: 4000.0, 4004.0937642499407, time: 29.906
steps: 605942, episodes: 651, mean episode reward: 0.0, 2.2980381523236177, time: 13.646
steps: 606942, episodes: 652, mean episode reward: 0.0, 5.699008308498688, time: 29.786
steps: 607882, episodes: 653, mean episode reward: 0.0, 4.802778129461355, time: 27.692
steps: 608673, episodes: 654, mean episode reward: 0.0, 4.456921468240515, time: 22.835
steps: 609673, episodes: 655, mean episode reward: 0.0, 4.388194041406163, time: 29.772
steps: 610673, episodes: 656, mean episode reward: 2400.0, 2404.9411376363014, time: 29.763
steps: 611360, episodes: 657, mean episode reward: 0.0, 3.5635157315134958, time: 19.582
steps: 612360, episodes: 658, mean episode reward: 1600.0, 1604.8129526328403, time: 29.788
steps: 613128, episodes: 659, mean episode reward: 0.0, 3.8841548801262222, time: 22.165
steps: 614088, episodes: 660, mean episode reward: 0.0, 5.275688684993559, time: 28.313
steps: 615088, episodes: 661, mean episode reward: 0.0, 4.79979568316286, time: 29.755
steps: 616088, episodes: 662, mean episode reward: 0.0, 5.009261204414003, time: 29.885
steps: 617088, episodes: 663, mean episode reward: 3200.0, 3203.8368309692455, time: 29.934
steps: 617906, episodes: 664, mean episode reward: 0.0, 3.1206935118954444, time: 23.902
steps: 618906, episodes: 665, mean episode reward: 0.0, 5.521244625195608, time: 29.765
steps: 619592, episodes: 666, mean episode reward: 0.0, 2.804762889398405, time: 19.462
steps: 620592, episodes: 667, mean episode reward: 0.0, 3.5761954246470533, time: 29.779
steps: 621319, episodes: 668, mean episode reward: 1600.0, 1603.3891444836715, time: 20.82
steps: 622128, episodes: 669, mean episode reward: 1600.0, 1603.4675643605924, time: 23.422
steps: 622816, episodes: 670, mean episode reward: 1600.0, 1602.8970758062503, time: 19.558
steps: 623816, episodes: 671, mean episode reward: 0.0, 5.232969320163457, time: 29.747
steps: 624816, episodes: 672, mean episode reward: 800.0, 804.5105639833085, time: 29.786
steps: 625816, episodes: 673, mean episode reward: 0.0, 5.17151047925821, time: 29.761
steps: 626816, episodes: 674, mean episode reward: 0.0, 5.511523761058362, time: 29.762
steps: 627712, episodes: 675, mean episode reward: 2400.0, 2404.1606173738364, time: 26.397
steps: 628712, episodes: 676, mean episode reward: 0.0, 5.327029228061201, time: 29.8
steps: 629712, episodes: 677, mean episode reward: 0.0, 4.830039426789911, time: 29.755
steps: 630712, episodes: 678, mean episode reward: 0.0, 4.808224036654103, time: 29.771
steps: 631712, episodes: 679, mean episode reward: 0.0, 4.655697711443668, time: 29.973
steps: 632712, episodes: 680, mean episode reward: 0.0, 4.11290047428247, time: 29.825
steps: 633712, episodes: 681, mean episode reward: 0.0, 4.912477214166342, time: 29.912
steps: 634712, episodes: 682, mean episode reward: 0.0, 4.659977169193266, time: 29.892
steps: 635712, episodes: 683, mean episode reward: 800.0, 804.6710503444145, time: 29.944
steps: 636712, episodes: 684, mean episode reward: 0.0, 5.074838032010423, time: 29.777
steps: 637438, episodes: 685, mean episode reward: 0.0, 3.368938495492413, time: 20.756
steps: 638438, episodes: 686, mean episode reward: 0.0, 3.994352647460291, time: 29.823
steps: 639438, episodes: 687, mean episode reward: 1600.0, 1603.8285603274883, time: 29.872
steps: 640438, episodes: 688, mean episode reward: 1600.0, 1603.7965463666576, time: 29.71
steps: 641438, episodes: 689, mean episode reward: 0.0, 4.554810150854984, time: 29.775
steps: 642275, episodes: 690, mean episode reward: 1600.0, 1604.1968027597532, time: 24.394
steps: 643275, episodes: 691, mean episode reward: 1600.0, 1602.9781115554574, time: 29.818
steps: 643960, episodes: 692, mean episode reward: 0.0, 3.0960381134579658, time: 19.429
steps: 644960, episodes: 693, mean episode reward: 0.0, 4.203875131039373, time: 29.774
steps: 645960, episodes: 694, mean episode reward: 3200.0, 3204.355460263562, time: 29.952
steps: 646833, episodes: 695, mean episode reward: 0.0, 3.505415292346973, time: 25.584
StopIteration()
steps: 647833, episodes: 696, mean episode reward: 0.0, 4.025032896631351, time: 29.839
steps: 648662, episodes: 697, mean episode reward: 0.0, 4.036669372590405, time: 24.084
steps: 649288, episodes: 698, mean episode reward: 0.0, 3.263988871928644, time: 17.531
steps: 650288, episodes: 699, mean episode reward: 800.0, 804.2314290741715, time: 29.731
steps: 651288, episodes: 700, mean episode reward: 0.0, 4.595123900737308, time: 29.822
steps: 652288, episodes: 701, mean episode reward: 800.0, 803.315952277711, time: 29.721
steps: 653191, episodes: 702, mean episode reward: 1600.0, 1603.2453429105892, time: 26.534
steps: 654191, episodes: 703, mean episode reward: 2400.0, 2402.813874105669, time: 29.882
steps: 655191, episodes: 704, mean episode reward: 800.0, 803.4777963251966, time: 29.888
StopIteration()
steps: 656191, episodes: 705, mean episode reward: 1600.0, 1603.4771637189574, time: 29.872
steps: 657191, episodes: 706, mean episode reward: 0.0, 4.16113034597538, time: 29.743
steps: 658191, episodes: 707, mean episode reward: 0.0, 3.1972595071963936, time: 29.811
steps: 659191, episodes: 708, mean episode reward: 0.0, 4.893811378269404, time: 29.733
steps: 659582, episodes: 709, mean episode reward: 0.0, 2.1115589813676046, time: 10.664
steps: 660462, episodes: 710, mean episode reward: 0.0, 2.914311271663784, time: 25.813
steps: 661462, episodes: 711, mean episode reward: 0.0, 4.384246258673192, time: 29.687
steps: 662462, episodes: 712, mean episode reward: 800.0, 804.1605685859297, time: 29.748
steps: 663372, episodes: 713, mean episode reward: 1600.0, 1603.66920174883, time: 26.767
steps: 664372, episodes: 714, mean episode reward: 0.0, 4.166148864249297, time: 29.709
steps: 665372, episodes: 715, mean episode reward: 0.0, 4.258147263680339, time: 29.67
steps: 666372, episodes: 716, mean episode reward: 0.0, 3.9680258472339394, time: 29.832
steps: 667372, episodes: 717, mean episode reward: 1600.0, 1603.4622553089312, time: 29.722
steps: 668372, episodes: 718, mean episode reward: 1600.0, 1603.990928316845, time: 29.903
steps: 669372, episodes: 719, mean episode reward: 0.0, 3.8310508629354847, time: 29.73
steps: 670372, episodes: 720, mean episode reward: 0.0, 3.128246273501092, time: 29.724
steps: 671372, episodes: 721, mean episode reward: 1600.0, 1603.432463864929, time: 29.738
steps: 672372, episodes: 722, mean episode reward: 0.0, 3.5215833803329852, time: 29.703
steps: 673372, episodes: 723, mean episode reward: 1600.0, 1603.2534626744725, time: 29.673
steps: 674372, episodes: 724, mean episode reward: 0.0, 3.856497033183326, time: 29.714
steps: 675162, episodes: 725, mean episode reward: 0.0, 3.248428573292922, time: 22.773
steps: 676162, episodes: 726, mean episode reward: 1600.0, 1603.9159324965785, time: 29.773
steps: 677162, episodes: 727, mean episode reward: 800.0, 803.8807934682953, time: 29.825
steps: 677850, episodes: 728, mean episode reward: 1600.0, 1602.746044276992, time: 19.573
steps: 678850, episodes: 729, mean episode reward: 0.0, 4.273729869634096, time: 29.624
steps: 679751, episodes: 730, mean episode reward: 0.0, 4.223564924177301, time: 26.387
steps: 680751, episodes: 731, mean episode reward: 3200.0, 3203.244304104287, time: 29.588
steps: 681751, episodes: 732, mean episode reward: 0.0, 3.838489232677973, time: 29.62
steps: 682751, episodes: 733, mean episode reward: 0.0, 4.606998748877733, time: 29.627
steps: 683751, episodes: 734, mean episode reward: 0.0, 5.187940825292538, time: 29.617
steps: 684751, episodes: 735, mean episode reward: 2400.0, 2403.308173144958, time: 29.577
steps: 685751, episodes: 736, mean episode reward: 0.0, 3.9158095591189093, time: 29.641
steps: 686751, episodes: 737, mean episode reward: 800.0, 803.9378204976103, time: 29.632
steps: 687751, episodes: 738, mean episode reward: 1600.0, 1604.4902416165357, time: 29.541
steps: 688648, episodes: 739, mean episode reward: 0.0, 3.593935693563098, time: 26.191
steps: 689648, episodes: 740, mean episode reward: 0.0, 4.067370834241282, time: 29.695
steps: 690648, episodes: 741, mean episode reward: 800.0, 803.197235916636, time: 29.737
steps: 691597, episodes: 742, mean episode reward: 0.0, 4.157128410570061, time: 28.015
steps: 692597, episodes: 743, mean episode reward: 4000.0, 4004.6463799248104, time: 29.725
steps: 693118, episodes: 744, mean episode reward: 800.0, 802.232760565448, time: 14.432
steps: 693975, episodes: 745, mean episode reward: 0.0, 3.8876205223577256, time: 24.829
steps: 694863, episodes: 746, mean episode reward: 3200.0, 3203.032229369218, time: 26.146
steps: 695863, episodes: 747, mean episode reward: 0.0, 3.8742605462541935, time: 29.683
steps: 696759, episodes: 748, mean episode reward: 1600.0, 1603.5116495340371, time: 26.298
steps: 697759, episodes: 749, mean episode reward: 1600.0, 1604.3400215772754, time: 29.594
steps: 698759, episodes: 750, mean episode reward: 0.0, 3.108596228626874, time: 29.66
StopIteration()
steps: 699759, episodes: 751, mean episode reward: 0.0, 3.9919804374838055, time: 29.636
steps: 700713, episodes: 752, mean episode reward: 0.0, 3.859448580588717, time: 28.234
steps: 701711, episodes: 753, mean episode reward: 800.0, 803.7344090150907, time: 29.607
steps: 702549, episodes: 754, mean episode reward: 0.0, 3.429645610817877, time: 24.343
steps: 703519, episodes: 755, mean episode reward: 0.0, 3.9740129834731692, time: 28.875
steps: 704519, episodes: 756, mean episode reward: 0.0, 4.9137501607277425, time: 29.76
steps: 705519, episodes: 757, mean episode reward: 1600.0, 1604.0576353785843, time: 29.679
steps: 706519, episodes: 758, mean episode reward: 0.0, 3.6803115015469032, time: 29.653
steps: 707519, episodes: 759, mean episode reward: 0.0, 4.339617279199744, time: 29.626
steps: 708519, episodes: 760, mean episode reward: 0.0, 4.143727673153008, time: 29.767
steps: 709519, episodes: 761, mean episode reward: 3200.0, 3204.471998245922, time: 29.723
StopIteration()
steps: 710519, episodes: 762, mean episode reward: 1600.0, 1604.5405982087282, time: 29.695
steps: 711519, episodes: 763, mean episode reward: 800.0, 803.1497501786707, time: 29.757
steps: 712254, episodes: 764, mean episode reward: 0.0, 2.3110875754065083, time: 20.989
steps: 713120, episodes: 765, mean episode reward: 0.0, 3.8444029221050418, time: 25.282
steps: 714120, episodes: 766, mean episode reward: 1600.0, 1604.043172907077, time: 29.632
StopIteration()
steps: 715120, episodes: 767, mean episode reward: 800.0, 803.9997521245356, time: 29.644
StopIteration()
steps: 716120, episodes: 768, mean episode reward: 1600.0, 1604.2025607892858, time: 29.668
steps: 716522, episodes: 769, mean episode reward: 800.0, 801.7706641207802, time: 11.012
steps: 717522, episodes: 770, mean episode reward: 3200.0, 3203.798889659082, time: 29.71
steps: 718522, episodes: 771, mean episode reward: 800.0, 803.1417029194041, time: 29.829
steps: 719510, episodes: 772, mean episode reward: 3200.0, 3203.682486078356, time: 29.301
steps: 720510, episodes: 773, mean episode reward: 0.0, 2.9280359371006206, time: 29.724
steps: 721510, episodes: 774, mean episode reward: 0.0, 3.1890741896049186, time: 29.739
steps: 722459, episodes: 775, mean episode reward: 0.0, 4.292952080145972, time: 27.905
steps: 723459, episodes: 776, mean episode reward: 800.0, 802.7732861624287, time: 29.6
StopIteration()
steps: 724459, episodes: 777, mean episode reward: 1600.0, 1604.3901101525516, time: 29.545
steps: 725459, episodes: 778, mean episode reward: 3200.0, 3205.0241423616835, time: 29.408
steps: 726459, episodes: 779, mean episode reward: 0.0, 4.393629259332229, time: 29.588
steps: 727459, episodes: 780, mean episode reward: 0.0, 4.230220299900641, time: 29.541
steps: 728459, episodes: 781, mean episode reward: 2400.0, 2403.8101046385914, time: 29.599
steps: 729366, episodes: 782, mean episode reward: 0.0, 3.863427953568518, time: 26.547
StopIteration()
steps: 730366, episodes: 783, mean episode reward: 0.0, 3.944042719425373, time: 29.734
steps: 731366, episodes: 784, mean episode reward: 800.0, 804.454609364236, time: 29.644
steps: 732366, episodes: 785, mean episode reward: 1600.0, 1603.4457554863206, time: 29.637
steps: 733366, episodes: 786, mean episode reward: 0.0, 4.225698023477197, time: 29.48
steps: 734366, episodes: 787, mean episode reward: 0.0, 4.298420067597861, time: 29.589
steps: 735366, episodes: 788, mean episode reward: 0.0, 4.174291572708955, time: 29.487
steps: 736225, episodes: 789, mean episode reward: 0.0, 3.6072961234685095, time: 24.901
steps: 737133, episodes: 790, mean episode reward: 0.0, 3.8020767111816416, time: 26.649
steps: 738133, episodes: 791, mean episode reward: 0.0, 4.281537651707379, time: 29.606
steps: 739133, episodes: 792, mean episode reward: 0.0, 3.901840974009679, time: 29.544
steps: 740133, episodes: 793, mean episode reward: 0.0, 4.952155935011072, time: 29.576
steps: 741133, episodes: 794, mean episode reward: 0.0, 4.543564300843621, time: 29.748
steps: 742133, episodes: 795, mean episode reward: 1600.0, 1604.4757315934971, time: 29.846
steps: 742821, episodes: 796, mean episode reward: 0.0, 3.9102962312926386, time: 19.486
StopIteration()
steps: 743821, episodes: 797, mean episode reward: 0.0, 4.620305079898405, time: 29.607
steps: 744821, episodes: 798, mean episode reward: 3200.0, 3204.4480383374976, time: 29.616
steps: 745821, episodes: 799, mean episode reward: 1600.0, 1604.714338685635, time: 29.688
StopIteration()
steps: 746821, episodes: 800, mean episode reward: 800.0, 803.7427051702728, time: 29.655
steps: 747821, episodes: 801, mean episode reward: 800.0, 804.0874034917125, time: 29.593
steps: 748821, episodes: 802, mean episode reward: 0.0, 3.7361624231336963, time: 29.504
StopIteration()
steps: 749821, episodes: 803, mean episode reward: 0.0, 4.710735167201735, time: 29.502
steps: 750477, episodes: 804, mean episode reward: 0.0, 2.9903069612044, time: 18.362
steps: 751477, episodes: 805, mean episode reward: 1600.0, 1603.7341420536936, time: 29.585
steps: 752477, episodes: 806, mean episode reward: 1600.0, 1604.4304294834637, time: 29.529
steps: 753477, episodes: 807, mean episode reward: 0.0, 4.979550129595253, time: 29.565
steps: 754477, episodes: 808, mean episode reward: 1600.0, 1604.188913258817, time: 29.588
steps: 755477, episodes: 809, mean episode reward: 800.0, 804.5110564700033, time: 29.611
steps: 756477, episodes: 810, mean episode reward: 0.0, 5.110715226571969, time: 29.64
steps: 757012, episodes: 811, mean episode reward: 0.0, 1.9074372277847882, time: 14.891
steps: 758012, episodes: 812, mean episode reward: 1600.0, 1604.343590816859, time: 29.535
steps: 759012, episodes: 813, mean episode reward: 0.0, 4.9252828512022395, time: 29.549
steps: 759919, episodes: 814, mean episode reward: 0.0, 3.301541332119501, time: 26.422
steps: 760919, episodes: 815, mean episode reward: 3200.0, 3203.3234193278518, time: 29.518
steps: 761919, episodes: 816, mean episode reward: 0.0, 4.952525763509102, time: 29.485
steps: 762658, episodes: 817, mean episode reward: 800.0, 802.383039888061, time: 20.962
steps: 763658, episodes: 818, mean episode reward: 0.0, 4.691574852364832, time: 29.597
steps: 764593, episodes: 819, mean episode reward: 0.0, 4.7076218081831405, time: 27.303
steps: 765593, episodes: 820, mean episode reward: 1600.0, 1603.2205634925942, time: 29.437
steps: 766593, episodes: 821, mean episode reward: 2400.0, 2402.9631200511676, time: 29.694
steps: 767593, episodes: 822, mean episode reward: 0.0, 3.522394068333276, time: 29.578
steps: 768593, episodes: 823, mean episode reward: 0.0, 3.23166800010938, time: 29.539
steps: 769124, episodes: 824, mean episode reward: 0.0, 2.209049857525766, time: 14.715
steps: 770124, episodes: 825, mean episode reward: 1600.0, 1603.8304904494403, time: 29.547
steps: 771124, episodes: 826, mean episode reward: 0.0, 4.1682011233433665, time: 29.499
steps: 772124, episodes: 827, mean episode reward: 0.0, 4.018762428891458, time: 29.583
steps: 773124, episodes: 828, mean episode reward: 0.0, 3.1686111459089488, time: 29.616
steps: 774124, episodes: 829, mean episode reward: 0.0, 4.0361218631873435, time: 29.505
steps: 775124, episodes: 830, mean episode reward: 1600.0, 1603.5893982029029, time: 29.495
steps: 776124, episodes: 831, mean episode reward: 0.0, 4.2909640188097296, time: 29.5
steps: 776899, episodes: 832, mean episode reward: 0.0, 3.226335908558046, time: 22.171
steps: 777899, episodes: 833, mean episode reward: 0.0, 3.8379130792358565, time: 29.832
steps: 778868, episodes: 834, mean episode reward: 1600.0, 1604.1155020792187, time: 28.561
steps: 779613, episodes: 835, mean episode reward: 0.0, 2.2084956843433305, time: 21.219
steps: 780432, episodes: 836, mean episode reward: 0.0, 3.4678372260683776, time: 23.577
steps: 781432, episodes: 837, mean episode reward: 0.0, 3.7886668322441506, time: 29.599
steps: 782081, episodes: 838, mean episode reward: 0.0, 2.388030061528087, time: 18.2
steps: 782906, episodes: 839, mean episode reward: 0.0, 2.4967175112102717, time: 23.848
steps: 783906, episodes: 840, mean episode reward: 0.0, 4.453774318319843, time: 29.524
steps: 784804, episodes: 841, mean episode reward: 0.0, 4.02699294039769, time: 26.177
steps: 785804, episodes: 842, mean episode reward: 1600.0, 1604.1522348445192, time: 29.636
steps: 786798, episodes: 843, mean episode reward: 0.0, 4.276725451441549, time: 29.15
steps: 787665, episodes: 844, mean episode reward: 0.0, 3.5072035530174905, time: 25.317
steps: 788665, episodes: 845, mean episode reward: 0.0, 4.120315942942919, time: 29.554
steps: 789665, episodes: 846, mean episode reward: 0.0, 4.161902870435574, time: 29.547
steps: 790665, episodes: 847, mean episode reward: 0.0, 4.914711015555093, time: 29.5
steps: 791665, episodes: 848, mean episode reward: 800.0, 804.6738422242756, time: 29.477
steps: 792657, episodes: 849, mean episode reward: 0.0, 4.2018148899968235, time: 29.28
steps: 793497, episodes: 850, mean episode reward: 0.0, 3.7588978774879194, time: 24.252
steps: 794342, episodes: 851, mean episode reward: 0.0, 3.6994089539403134, time: 24.537
steps: 795342, episodes: 852, mean episode reward: 3200.0, 3204.0936624477454, time: 29.64
steps: 796342, episodes: 853, mean episode reward: 3200.0, 3204.509693257981, time: 29.681
steps: 797342, episodes: 854, mean episode reward: 2400.0, 2403.6008568458487, time: 29.654
steps: 798342, episodes: 855, mean episode reward: 1600.0, 1604.0596901620247, time: 29.63
steps: 799144, episodes: 856, mean episode reward: 0.0, 3.336927919976926, time: 22.956
steps: 799869, episodes: 857, mean episode reward: 0.0, 3.6772265816638825, time: 20.505
steps: 800869, episodes: 858, mean episode reward: 2400.0, 2404.088636328116, time: 29.494
steps: 801869, episodes: 859, mean episode reward: 0.0, 3.414661510591381, time: 29.612
steps: 802481, episodes: 860, mean episode reward: 0.0, 2.997252960060281, time: 17.041
steps: 803481, episodes: 861, mean episode reward: 0.0, 5.184645288267906, time: 29.515
steps: 804429, episodes: 862, mean episode reward: 0.0, 4.722151920288508, time: 27.774
steps: 805429, episodes: 863, mean episode reward: 0.0, 3.93293444211206, time: 29.53
steps: 806065, episodes: 864, mean episode reward: 0.0, 3.0329936208706103, time: 17.697
steps: 806848, episodes: 865, mean episode reward: 0.0, 3.0334313283687417, time: 22.353
steps: 807387, episodes: 866, mean episode reward: 0.0, 1.6758177556483775, time: 14.717
steps: 808146, episodes: 867, mean episode reward: 0.0, 3.3723810405255685, time: 21.609
steps: 809114, episodes: 868, mean episode reward: 1600.0, 1603.7677454960085, time: 28.303
steps: 810114, episodes: 869, mean episode reward: 0.0, 3.7376213501235798, time: 29.381
StopIteration()
steps: 811114, episodes: 870, mean episode reward: 0.0, 3.9042170054799525, time: 29.505
steps: 812114, episodes: 871, mean episode reward: 0.0, 4.809881291002643, time: 29.518
steps: 813114, episodes: 872, mean episode reward: 0.0, 4.34038561902462, time: 29.412
steps: 814114, episodes: 873, mean episode reward: 0.0, 4.602346117845567, time: 29.515
steps: 815114, episodes: 874, mean episode reward: 0.0, 3.8751404613893286, time: 29.508
steps: 816114, episodes: 875, mean episode reward: 0.0, 3.959455850707361, time: 29.462
steps: 817114, episodes: 876, mean episode reward: 0.0, 4.054831910482287, time: 29.503
steps: 818114, episodes: 877, mean episode reward: 0.0, 3.898657312240556, time: 29.462
steps: 819114, episodes: 878, mean episode reward: 0.0, 4.363087149937784, time: 29.482
steps: 820114, episodes: 879, mean episode reward: 3200.0, 3203.845495634502, time: 29.45
steps: 821114, episodes: 880, mean episode reward: 800.0, 804.3726513695785, time: 29.451
steps: 822114, episodes: 881, mean episode reward: 0.0, 3.963513572581751, time: 29.538
steps: 823114, episodes: 882, mean episode reward: 1600.0, 1604.0980809231341, time: 29.476
StopIteration()
steps: 824114, episodes: 883, mean episode reward: 0.0, 4.1027639761709205, time: 29.623
steps: 825087, episodes: 884, mean episode reward: 0.0, 2.781145753430438, time: 28.638
steps: 826087, episodes: 885, mean episode reward: 0.0, 4.5020694932683885, time: 29.47
steps: 827087, episodes: 886, mean episode reward: 1600.0, 1604.3926426587232, time: 29.525
steps: 828087, episodes: 887, mean episode reward: 0.0, 3.7693657977236326, time: 29.506
steps: 829087, episodes: 888, mean episode reward: 1600.0, 1604.650490685844, time: 29.514
steps: 830087, episodes: 889, mean episode reward: 800.0, 803.9079789832141, time: 29.478
steps: 831087, episodes: 890, mean episode reward: 0.0, 4.654982589528899, time: 29.468
StopIteration()
steps: 832087, episodes: 891, mean episode reward: 0.0, 3.659043377234435, time: 29.412
steps: 833087, episodes: 892, mean episode reward: 3200.0, 3204.1296246827515, time: 29.375
steps: 834087, episodes: 893, mean episode reward: 1600.0, 1603.9875077690176, time: 29.446
steps: 834622, episodes: 894, mean episode reward: 0.0, 2.6592445303020904, time: 14.965
steps: 835622, episodes: 895, mean episode reward: 1600.0, 1604.5517120726383, time: 29.445
steps: 836537, episodes: 896, mean episode reward: 0.0, 3.8795689977465098, time: 26.651
steps: 837537, episodes: 897, mean episode reward: 1600.0, 1603.4498949414738, time: 29.44
steps: 838537, episodes: 898, mean episode reward: 0.0, 4.225180361022516, time: 29.388
steps: 839537, episodes: 899, mean episode reward: 0.0, 3.987853861580731, time: 29.584
steps: 840466, episodes: 900, mean episode reward: 0.0, 3.495458680969253, time: 27.157
steps: 841466, episodes: 901, mean episode reward: 1600.0, 1603.8543683383875, time: 29.528
steps: 842466, episodes: 902, mean episode reward: 800.0, 803.3743680341775, time: 29.51
steps: 843466, episodes: 903, mean episode reward: 0.0, 3.126101937349156, time: 29.594
steps: 844410, episodes: 904, mean episode reward: 0.0, 3.5314993877592915, time: 27.666
StopIteration()
steps: 845410, episodes: 905, mean episode reward: 0.0, 4.54830102355588, time: 29.528
steps: 846238, episodes: 906, mean episode reward: 0.0, 3.5180299629886504, time: 23.776
steps: 847022, episodes: 907, mean episode reward: 0.0, 3.306367314480978, time: 22.412
steps: 848022, episodes: 908, mean episode reward: 0.0, 4.6704708376758575, time: 29.475
steps: 848742, episodes: 909, mean episode reward: 0.0, 3.4641126514137985, time: 20.285
steps: 849742, episodes: 910, mean episode reward: 0.0, 3.7967892983630147, time: 31.672
steps: 850742, episodes: 911, mean episode reward: 1600.0, 1604.186440787738, time: 29.89
steps: 851425, episodes: 912, mean episode reward: 0.0, 2.801511946050873, time: 19.267
steps: 852425, episodes: 913, mean episode reward: 1600.0, 1604.3426108027752, time: 29.533
steps: 853425, episodes: 914, mean episode reward: 0.0, 3.7952717341364015, time: 29.546
steps: 854425, episodes: 915, mean episode reward: 0.0, 3.7867303139090174, time: 29.549
steps: 855425, episodes: 916, mean episode reward: 800.0, 803.4279855201149, time: 29.531
steps: 855960, episodes: 917, mean episode reward: 0.0, 2.637783623608929, time: 14.685
StopIteration()
steps: 856960, episodes: 918, mean episode reward: 0.0, 3.446710194441847, time: 29.525
steps: 857960, episodes: 919, mean episode reward: 800.0, 803.6558241563165, time: 29.596
steps: 858647, episodes: 920, mean episode reward: 800.0, 802.253848496878, time: 19.366
steps: 859647, episodes: 921, mean episode reward: 800.0, 803.2027229549614, time: 29.637
steps: 860647, episodes: 922, mean episode reward: 0.0, 3.4080021549451733, time: 29.643
steps: 861647, episodes: 923, mean episode reward: 1600.0, 1603.3795687775603, time: 29.566
steps: 862470, episodes: 924, mean episode reward: 0.0, 3.424593612841062, time: 23.636
steps: 863470, episodes: 925, mean episode reward: 1600.0, 1604.0436964904436, time: 29.684
steps: 864470, episodes: 926, mean episode reward: 2400.0, 2402.9792049230896, time: 29.543
steps: 865232, episodes: 927, mean episode reward: 0.0, 2.8236360271509096, time: 21.818
steps: 866232, episodes: 928, mean episode reward: 0.0, 3.9204582296910577, time: 29.59
steps: 867232, episodes: 929, mean episode reward: 800.0, 803.5850675819989, time: 29.635
steps: 868232, episodes: 930, mean episode reward: 2400.0, 2403.6931772181856, time: 29.519
StopIteration()
steps: 869232, episodes: 931, mean episode reward: 0.0, 3.1761502557220567, time: 29.643
steps: 869991, episodes: 932, mean episode reward: 0.0, 2.6736984139931197, time: 21.646
steps: 870991, episodes: 933, mean episode reward: 1600.0, 1603.797863984278, time: 29.518
steps: 871554, episodes: 934, mean episode reward: 0.0, 1.7775062602211245, time: 15.713
steps: 872554, episodes: 935, mean episode reward: 5600.0, 5603.579171672018, time: 29.599
steps: 873554, episodes: 936, mean episode reward: 0.0, 3.8883043415339915, time: 29.521
steps: 874554, episodes: 937, mean episode reward: 4800.0, 4802.867654996795, time: 29.577
steps: 875029, episodes: 938, mean episode reward: 0.0, 1.9869483499337783, time: 13.033
steps: 875822, episodes: 939, mean episode reward: 0.0, 3.2300235414599285, time: 22.718
steps: 876822, episodes: 940, mean episode reward: 0.0, 3.4795170862152887, time: 29.641
steps: 877822, episodes: 941, mean episode reward: 0.0, 3.134710841213355, time: 29.535
StopIteration()
steps: 878822, episodes: 942, mean episode reward: 0.0, 3.3991825993298432, time: 29.598
steps: 879589, episodes: 943, mean episode reward: 0.0, 2.678854886946607, time: 22.07
StopIteration()
steps: 880589, episodes: 944, mean episode reward: 0.0, 3.1072637108668295, time: 29.645
steps: 881589, episodes: 945, mean episode reward: 0.0, 3.528508761438341, time: 29.604
steps: 882589, episodes: 946, mean episode reward: 0.0, 2.7860643454310114, time: 29.57
steps: 883589, episodes: 947, mean episode reward: 1600.0, 1603.5247718367489, time: 29.556
steps: 884589, episodes: 948, mean episode reward: 1600.0, 1603.6011301536291, time: 29.525
steps: 885589, episodes: 949, mean episode reward: 2400.0, 2403.511864313152, time: 29.47
StopIteration()
steps: 886589, episodes: 950, mean episode reward: 0.0, 3.6320510643402084, time: 29.629
steps: 887303, episodes: 951, mean episode reward: 0.0, 3.00023160857708, time: 20.262
steps: 888303, episodes: 952, mean episode reward: 0.0, 4.147171198664712, time: 29.53
steps: 889196, episodes: 953, mean episode reward: 0.0, 2.700810775494359, time: 25.978
steps: 890196, episodes: 954, mean episode reward: 0.0, 4.676902569273002, time: 29.768
steps: 891196, episodes: 955, mean episode reward: 0.0, 3.354039733393345, time: 29.76
steps: 892196, episodes: 956, mean episode reward: 0.0, 4.189652641882578, time: 29.707
steps: 893196, episodes: 957, mean episode reward: 0.0, 4.3687715184667315, time: 29.621
steps: 894196, episodes: 958, mean episode reward: 1600.0, 1604.4507097815058, time: 29.503
steps: 895196, episodes: 959, mean episode reward: 0.0, 4.21226689141893, time: 29.453
steps: 896196, episodes: 960, mean episode reward: 0.0, 4.1968897015744915, time: 29.794
StopIteration()
steps: 897196, episodes: 961, mean episode reward: 0.0, 3.8403528407567444, time: 29.58
steps: 898196, episodes: 962, mean episode reward: 1600.0, 1604.037084334259, time: 29.491
steps: 899196, episodes: 963, mean episode reward: 800.0, 803.7997917930988, time: 29.54
steps: 900196, episodes: 964, mean episode reward: 0.0, 4.584992021820469, time: 29.672
steps: 901196, episodes: 965, mean episode reward: 1600.0, 1604.2603029443303, time: 29.546
steps: 902196, episodes: 966, mean episode reward: 0.0, 4.675915428556033, time: 29.497
steps: 903196, episodes: 967, mean episode reward: 0.0, 4.570929910597444, time: 29.438
steps: 904196, episodes: 968, mean episode reward: 0.0, 3.9607636252174676, time: 29.512
steps: 905196, episodes: 969, mean episode reward: 0.0, 4.794629469583793, time: 29.549
steps: 906196, episodes: 970, mean episode reward: 0.0, 4.052044200445293, time: 29.537
steps: 907196, episodes: 971, mean episode reward: 1600.0, 1603.8517473195461, time: 29.685
steps: 908196, episodes: 972, mean episode reward: 0.0, 3.8600533095561693, time: 29.638
steps: 909196, episodes: 973, mean episode reward: 0.0, 3.9347599803798308, time: 29.637
steps: 910196, episodes: 974, mean episode reward: 0.0, 3.4396170434064386, time: 29.689
steps: 911138, episodes: 975, mean episode reward: 0.0, 3.8521321445878693, time: 27.833
steps: 912138, episodes: 976, mean episode reward: 1600.0, 1603.8791753134026, time: 29.6
steps: 913138, episodes: 977, mean episode reward: 0.0, 3.325527547777492, time: 29.629
steps: 914138, episodes: 978, mean episode reward: 1600.0, 1604.4532760373083, time: 29.543
steps: 915138, episodes: 979, mean episode reward: 0.0, 4.01974378525433, time: 29.553
steps: 916138, episodes: 980, mean episode reward: 0.0, 4.127959049303842, time: 29.486
steps: 917065, episodes: 981, mean episode reward: 0.0, 4.049515781480052, time: 27.461
steps: 918065, episodes: 982, mean episode reward: 0.0, 3.894490592495675, time: 29.623
steps: 918892, episodes: 983, mean episode reward: 0.0, 3.6148567912778127, time: 23.874
StopIteration()
steps: 919892, episodes: 984, mean episode reward: 0.0, 3.9548969368464872, time: 29.588
steps: 920892, episodes: 985, mean episode reward: 0.0, 3.786294398153446, time: 29.6
steps: 921892, episodes: 986, mean episode reward: 0.0, 4.47540495306698, time: 29.622
steps: 922892, episodes: 987, mean episode reward: 0.0, 3.733068301998189, time: 29.595
steps: 923892, episodes: 988, mean episode reward: 0.0, 3.8727003709098593, time: 29.651
steps: 924892, episodes: 989, mean episode reward: 0.0, 4.425454629543138, time: 29.626
steps: 925892, episodes: 990, mean episode reward: 1600.0, 1604.531788116724, time: 29.574
steps: 926892, episodes: 991, mean episode reward: 800.0, 804.3758265734202, time: 29.62
steps: 927789, episodes: 992, mean episode reward: 0.0, 2.6484935284366875, time: 26.178
steps: 928789, episodes: 993, mean episode reward: 0.0, 4.539906051462275, time: 29.523
steps: 929755, episodes: 994, mean episode reward: 0.0, 3.833085847426163, time: 28.443
steps: 930755, episodes: 995, mean episode reward: 1600.0, 1604.2289269787502, time: 29.551
steps: 931755, episodes: 996, mean episode reward: 0.0, 4.035807535188221, time: 29.623
steps: 932755, episodes: 997, mean episode reward: 1600.0, 1604.1424552319963, time: 29.514
steps: 933755, episodes: 998, mean episode reward: 0.0, 4.287722697800639, time: 29.708
steps: 934755, episodes: 999, mean episode reward: 0.0, 4.217523005805862, time: 29.603
steps: 935755, episodes: 1000, mean episode reward: 1600.0, 1604.3342298633802, time: 29.626
steps: 936755, episodes: 1001, mean episode reward: 0.0, 4.719033376029184, time: 29.564
steps: 937755, episodes: 1002, mean episode reward: 0.0, 4.854329122906301, time: 29.636
StopIteration()
steps: 938755, episodes: 1003, mean episode reward: 0.0, 4.377259871595111, time: 29.616
steps: 939755, episodes: 1004, mean episode reward: 0.0, 4.394279644649635, time: 29.585
steps: 940755, episodes: 1005, mean episode reward: 0.0, 4.7286741300769215, time: 29.568
steps: 941755, episodes: 1006, mean episode reward: 0.0, 4.089806036992287, time: 29.666
steps: 942755, episodes: 1007, mean episode reward: 0.0, 4.610102468070901, time: 29.631
steps: 943755, episodes: 1008, mean episode reward: 2400.0, 2404.3871091614506, time: 29.565
steps: 944755, episodes: 1009, mean episode reward: 0.0, 2.8929036108797908, time: 29.729
steps: 945755, episodes: 1010, mean episode reward: 0.0, 4.168105390447693, time: 29.635
steps: 946755, episodes: 1011, mean episode reward: 0.0, 3.1035094796817146, time: 29.737
steps: 947755, episodes: 1012, mean episode reward: 1600.0, 1604.6905286129604, time: 29.629
steps: 948755, episodes: 1013, mean episode reward: 0.0, 4.06993501423443, time: 29.656
steps: 949550, episodes: 1014, mean episode reward: 0.0, 3.9192516812547327, time: 22.904
steps: 950550, episodes: 1015, mean episode reward: 0.0, 3.2305889144794957, time: 29.679
steps: 951550, episodes: 1016, mean episode reward: 0.0, 4.192730199963411, time: 29.803
steps: 952550, episodes: 1017, mean episode reward: 0.0, 4.117160812052871, time: 29.622
steps: 953550, episodes: 1018, mean episode reward: 0.0, 4.569299156102631, time: 29.646
steps: 954513, episodes: 1019, mean episode reward: 0.0, 4.261847458315042, time: 28.436
steps: 955513, episodes: 1020, mean episode reward: 0.0, 2.8532212117353626, time: 29.677
steps: 956513, episodes: 1021, mean episode reward: 0.0, 3.7493055950623773, time: 29.848
steps: 957513, episodes: 1022, mean episode reward: 0.0, 4.117839255013914, time: 29.749
steps: 958513, episodes: 1023, mean episode reward: 1600.0, 1604.2380045881955, time: 29.656
steps: 959414, episodes: 1024, mean episode reward: 0.0, 4.560714217353817, time: 26.638
steps: 960414, episodes: 1025, mean episode reward: 0.0, 5.012566617401482, time: 29.722
steps: 961414, episodes: 1026, mean episode reward: 1600.0, 1604.3739417065085, time: 29.72
steps: 962414, episodes: 1027, mean episode reward: 0.0, 5.067679573300612, time: 29.664
steps: 963414, episodes: 1028, mean episode reward: 0.0, 4.677735998688808, time: 29.633
steps: 964414, episodes: 1029, mean episode reward: 0.0, 4.498841914544253, time: 29.634
StopIteration()
steps: 965414, episodes: 1030, mean episode reward: 0.0, 3.328603202793109, time: 29.657
steps: 966414, episodes: 1031, mean episode reward: 0.0, 4.005987847718414, time: 29.682
steps: 967414, episodes: 1032, mean episode reward: 0.0, 5.0239910878789376, time: 29.646
steps: 968414, episodes: 1033, mean episode reward: 0.0, 4.199237227176429, time: 29.708
steps: 969414, episodes: 1034, mean episode reward: 0.0, 3.4655457830744916, time: 29.637
steps: 970414, episodes: 1035, mean episode reward: 1600.0, 1604.5257165462194, time: 29.778
StopIteration()
steps: 971414, episodes: 1036, mean episode reward: 0.0, 3.6490515267713173, time: 29.618
steps: 972414, episodes: 1037, mean episode reward: 1600.0, 1604.6877665381744, time: 29.682
steps: 973414, episodes: 1038, mean episode reward: 1600.0, 1604.1628689404974, time: 29.621
steps: 974414, episodes: 1039, mean episode reward: 0.0, 5.626183276185305, time: 29.565
steps: 975414, episodes: 1040, mean episode reward: 0.0, 3.6640327020771, time: 29.6
steps: 976414, episodes: 1041, mean episode reward: 1600.0, 1604.4425582597382, time: 29.638
steps: 977414, episodes: 1042, mean episode reward: 0.0, 4.0743691507374855, time: 29.632
steps: 978414, episodes: 1043, mean episode reward: 0.0, 4.560879901651657, time: 29.712
StopIteration()
steps: 979414, episodes: 1044, mean episode reward: 800.0, 804.086696523886, time: 29.735
steps: 980414, episodes: 1045, mean episode reward: 1600.0, 1605.07653191312, time: 29.619
steps: 981414, episodes: 1046, mean episode reward: 0.0, 3.8945783106255005, time: 29.647
steps: 982250, episodes: 1047, mean episode reward: 0.0, 4.089811056848528, time: 24.193
steps: 983250, episodes: 1048, mean episode reward: 0.0, 3.4677754851463996, time: 29.725
steps: 984250, episodes: 1049, mean episode reward: 1600.0, 1604.536624341185, time: 29.742
steps: 985250, episodes: 1050, mean episode reward: 0.0, 4.378893534247911, time: 29.713
steps: 986153, episodes: 1051, mean episode reward: 0.0, 4.556145488264915, time: 26.321
steps: 987153, episodes: 1052, mean episode reward: 0.0, 5.16353352027418, time: 29.531
steps: 987979, episodes: 1053, mean episode reward: 0.0, 3.6546544702899673, time: 23.839
steps: 988878, episodes: 1054, mean episode reward: 0.0, 4.308972273438109, time: 26.256
steps: 989878, episodes: 1055, mean episode reward: 0.0, 3.9139025739581665, time: 29.689
steps: 990878, episodes: 1056, mean episode reward: 0.0, 3.832176756828371, time: 29.68
steps: 991878, episodes: 1057, mean episode reward: 0.0, 4.71255457447293, time: 29.845
steps: 992878, episodes: 1058, mean episode reward: 1600.0, 1603.9345278520307, time: 29.64
steps: 993878, episodes: 1059, mean episode reward: 0.0, 3.9968476825381583, time: 29.715
steps: 994878, episodes: 1060, mean episode reward: 0.0, 3.912076170027202, time: 29.543
steps: 995878, episodes: 1061, mean episode reward: 0.0, 4.632140851198663, time: 29.68
steps: 996878, episodes: 1062, mean episode reward: 800.0, 804.7303974459569, time: 29.703
steps: 997878, episodes: 1063, mean episode reward: 0.0, 3.813929648315357, time: 29.726
steps: 998878, episodes: 1064, mean episode reward: 0.0, 4.642729611014073, time: 29.731
steps: 999878, episodes: 1065, mean episode reward: 0.0, 4.786893494821037, time: 29.802
steps: 1000878, episodes: 1066, mean episode reward: 0.0, 4.109953887150223, time: 29.86
steps: 1001878, episodes: 1067, mean episode reward: 0.0, 3.17084960212977, time: 29.777
steps: 1002878, episodes: 1068, mean episode reward: 1600.0, 1604.6380327318911, time: 29.813
StopIteration()
steps: 1003878, episodes: 1069, mean episode reward: 0.0, 3.98583578669568, time: 29.796
steps: 1004878, episodes: 1070, mean episode reward: 0.0, 4.321602041704692, time: 29.848
steps: 1005878, episodes: 1071, mean episode reward: 0.0, 3.7726284815170263, time: 29.8
steps: 1006878, episodes: 1072, mean episode reward: 0.0, 4.810938006781247, time: 29.762
steps: 1007878, episodes: 1073, mean episode reward: 0.0, 3.937101864727805, time: 29.732
steps: 1008878, episodes: 1074, mean episode reward: 800.0, 803.7756647922706, time: 29.74
steps: 1009878, episodes: 1075, mean episode reward: 800.0, 805.4487875415037, time: 29.845
steps: 1010878, episodes: 1076, mean episode reward: 0.0, 4.668597177317223, time: 29.969
steps: 1011677, episodes: 1077, mean episode reward: 0.0, 2.8117945778794464, time: 23.107
steps: 1012677, episodes: 1078, mean episode reward: 0.0, 4.302982946887742, time: 30.138
steps: 1013677, episodes: 1079, mean episode reward: 0.0, 4.479680720794591, time: 30.009
steps: 1014677, episodes: 1080, mean episode reward: 0.0, 3.659635774917987, time: 29.942
steps: 1015677, episodes: 1081, mean episode reward: 3200.0, 3203.834041329431, time: 29.948
steps: 1016677, episodes: 1082, mean episode reward: 0.0, 3.7968509200575484, time: 29.841
steps: 1017677, episodes: 1083, mean episode reward: 0.0, 3.9783346385877607, time: 30.089
steps: 1018677, episodes: 1084, mean episode reward: 0.0, 4.839323171365932, time: 30.052
steps: 1019677, episodes: 1085, mean episode reward: 0.0, 4.198273303929976, time: 29.972
steps: 1020677, episodes: 1086, mean episode reward: 0.0, 4.660539635314366, time: 29.976
steps: 1021657, episodes: 1087, mean episode reward: 0.0, 3.947304080423871, time: 29.546
steps: 1022657, episodes: 1088, mean episode reward: 2400.0, 2402.930630664502, time: 30.195
steps: 1023657, episodes: 1089, mean episode reward: 0.0, 4.713566118617084, time: 30.16
steps: 1024657, episodes: 1090, mean episode reward: 0.0, 4.477493890397657, time: 30.029
steps: 1025657, episodes: 1091, mean episode reward: 0.0, 4.125993089762281, time: 30.207
steps: 1026657, episodes: 1092, mean episode reward: 0.0, 3.633399507670732, time: 30.137
steps: 1027657, episodes: 1093, mean episode reward: 1600.0, 1603.673270235693, time: 30.159
steps: 1028493, episodes: 1094, mean episode reward: 0.0, 3.1761717535221177, time: 24.525
steps: 1029493, episodes: 1095, mean episode reward: 0.0, 4.23224676468375, time: 30.177
StopIteration()
steps: 1030493, episodes: 1096, mean episode reward: 1600.0, 1603.6143973514259, time: 30.216
steps: 1031493, episodes: 1097, mean episode reward: 1600.0, 1604.1395393133116, time: 30.25
steps: 1032493, episodes: 1098, mean episode reward: 0.0, 4.577981609274925, time: 30.23
steps: 1033493, episodes: 1099, mean episode reward: 0.0, 3.9399491023568043, time: 30.312
steps: 1034493, episodes: 1100, mean episode reward: 0.0, 4.071822015861358, time: 30.309
steps: 1035493, episodes: 1101, mean episode reward: 0.0, 4.356358584947167, time: 30.292
steps: 1036493, episodes: 1102, mean episode reward: 0.0, 4.0080920116156316, time: 30.363
steps: 1037493, episodes: 1103, mean episode reward: 0.0, 4.825796241448055, time: 30.288
steps: 1038493, episodes: 1104, mean episode reward: 1600.0, 1604.2447052185323, time: 30.311
steps: 1039493, episodes: 1105, mean episode reward: 0.0, 4.846527082542129, time: 30.314
steps: 1040493, episodes: 1106, mean episode reward: 0.0, 4.6472175995016345, time: 30.295
steps: 1041493, episodes: 1107, mean episode reward: 0.0, 4.296413492541151, time: 30.314
steps: 1042493, episodes: 1108, mean episode reward: 800.0, 804.502452552451, time: 30.379
steps: 1043493, episodes: 1109, mean episode reward: 1600.0, 1604.6370728194454, time: 30.491
steps: 1044493, episodes: 1110, mean episode reward: 0.0, 5.452520842248374, time: 30.473
StopIteration()
steps: 1045493, episodes: 1111, mean episode reward: 0.0, 4.0529946226689235, time: 30.492
steps: 1046493, episodes: 1112, mean episode reward: 1600.0, 1604.487898078134, time: 30.344
steps: 1047493, episodes: 1113, mean episode reward: 0.0, 4.073686244830099, time: 30.432
steps: 1048493, episodes: 1114, mean episode reward: 1600.0, 1604.2261774995739, time: 30.405
steps: 1049493, episodes: 1115, mean episode reward: 0.0, 4.000422033315875, time: 30.469
steps: 1050493, episodes: 1116, mean episode reward: 0.0, 4.234668394958373, time: 30.426
steps: 1051493, episodes: 1117, mean episode reward: 1600.0, 1604.2444004856977, time: 30.427
steps: 1052493, episodes: 1118, mean episode reward: 0.0, 5.481490676398171, time: 30.475
steps: 1053493, episodes: 1119, mean episode reward: 0.0, 5.362976404786812, time: 30.485
StopIteration()
steps: 1054493, episodes: 1120, mean episode reward: 0.0, 3.020498577767906, time: 30.604
steps: 1055493, episodes: 1121, mean episode reward: 0.0, 4.111572150617114, time: 30.517
steps: 1056493, episodes: 1122, mean episode reward: 0.0, 3.017148031567733, time: 30.521
steps: 1057493, episodes: 1123, mean episode reward: 0.0, 4.208940552906986, time: 30.512
steps: 1058493, episodes: 1124, mean episode reward: 3200.0, 3204.7572749910864, time: 30.664
steps: 1059493, episodes: 1125, mean episode reward: 1600.0, 1604.668809342667, time: 30.633
steps: 1060493, episodes: 1126, mean episode reward: 1600.0, 1603.9556751030057, time: 30.566
steps: 1061493, episodes: 1127, mean episode reward: 0.0, 2.9396005929524285, time: 30.696
steps: 1062493, episodes: 1128, mean episode reward: 0.0, 4.250471127165794, time: 30.636
steps: 1063493, episodes: 1129, mean episode reward: 1600.0, 1604.5321256624825, time: 30.675
steps: 1064493, episodes: 1130, mean episode reward: 0.0, 3.597715262924365, time: 30.682
steps: 1065178, episodes: 1131, mean episode reward: 0.0, 3.0559120637040076, time: 20.226
StopIteration()
steps: 1066178, episodes: 1132, mean episode reward: 0.0, 3.133530612848801, time: 30.781
steps: 1067178, episodes: 1133, mean episode reward: 0.0, 4.391706802562591, time: 30.803
steps: 1068178, episodes: 1134, mean episode reward: 0.0, 4.170931627628419, time: 30.72
steps: 1069178, episodes: 1135, mean episode reward: 0.0, 3.9009145627412867, time: 30.839
steps: 1070178, episodes: 1136, mean episode reward: 0.0, 3.080131456653157, time: 30.731
steps: 1071178, episodes: 1137, mean episode reward: 0.0, 3.7822355268937513, time: 30.78
steps: 1072178, episodes: 1138, mean episode reward: 0.0, 4.026965257704357, time: 30.728
steps: 1073157, episodes: 1139, mean episode reward: 0.0, 4.440672668293961, time: 30.063
steps: 1074157, episodes: 1140, mean episode reward: 0.0, 3.430681448529268, time: 30.67
steps: 1075157, episodes: 1141, mean episode reward: 0.0, 4.217225314135131, time: 30.729
steps: 1076157, episodes: 1142, mean episode reward: 1600.0, 1604.661532462028, time: 30.805
steps: 1076933, episodes: 1143, mean episode reward: 0.0, 2.9097656496501045, time: 23.276
steps: 1077933, episodes: 1144, mean episode reward: 0.0, 3.559126121397428, time: 30.765
steps: 1078933, episodes: 1145, mean episode reward: 0.0, 3.6529004845294497, time: 30.798
steps: 1079857, episodes: 1146, mean episode reward: 0.0, 3.4120167931570644, time: 28.158
steps: 1080857, episodes: 1147, mean episode reward: 800.0, 803.559167059814, time: 30.872
steps: 1081263, episodes: 1148, mean episode reward: 0.0, 1.338071383888109, time: 11.555
steps: 1082263, episodes: 1149, mean episode reward: 0.0, 3.360220245937012, time: 30.85
steps: 1083263, episodes: 1150, mean episode reward: 3200.0, 3203.269821894537, time: 30.936
steps: 1084053, episodes: 1151, mean episode reward: 0.0, 2.6215235019406666, time: 23.639
StopIteration()
steps: 1085053, episodes: 1152, mean episode reward: 0.0, 3.8357250390189312, time: 30.822
steps: 1086002, episodes: 1153, mean episode reward: 0.0, 3.637729779570683, time: 29.086
steps: 1086832, episodes: 1154, mean episode reward: 0.0, 3.339078869948088, time: 25.09
steps: 1087617, episodes: 1155, mean episode reward: 0.0, 3.485673897238835, time: 23.527
steps: 1088617, episodes: 1156, mean episode reward: 0.0, 3.984865655906839, time: 30.895
steps: 1089617, episodes: 1157, mean episode reward: 0.0, 3.891285978121218, time: 30.959
steps: 1090617, episodes: 1158, mean episode reward: 0.0, 4.33533960114601, time: 30.954
steps: 1091617, episodes: 1159, mean episode reward: 1600.0, 1603.8732063666212, time: 30.89
steps: 1092203, episodes: 1160, mean episode reward: 0.0, 2.6965894048044046, time: 17.168
steps: 1093203, episodes: 1161, mean episode reward: 0.0, 3.475685608616573, time: 30.905
steps: 1094203, episodes: 1162, mean episode reward: 0.0, 4.342108180619792, time: 30.845
steps: 1095203, episodes: 1163, mean episode reward: 0.0, 3.800633547996638, time: 30.859
steps: 1096203, episodes: 1164, mean episode reward: 1600.0, 1604.484088524172, time: 30.926
steps: 1097203, episodes: 1165, mean episode reward: 0.0, 4.650941325421314, time: 30.86
steps: 1097891, episodes: 1166, mean episode reward: 0.0, 2.17466246779435, time: 20.271
steps: 1098891, episodes: 1167, mean episode reward: 1600.0, 1603.951688646208, time: 30.854
steps: 1099891, episodes: 1168, mean episode reward: 800.0, 803.7136847713555, time: 30.908
steps: 1100891, episodes: 1169, mean episode reward: 0.0, 3.659129887933849, time: 30.936
steps: 1101891, episodes: 1170, mean episode reward: 0.0, 4.759243861800112, time: 30.993
steps: 1102891, episodes: 1171, mean episode reward: 0.0, 2.7546724090688914, time: 31.081
steps: 1103891, episodes: 1172, mean episode reward: 0.0, 4.601702442399588, time: 30.958
steps: 1104836, episodes: 1173, mean episode reward: 0.0, 4.075747950736585, time: 29.093
steps: 1105836, episodes: 1174, mean episode reward: 0.0, 4.2213730518365775, time: 31.009
steps: 1106836, episodes: 1175, mean episode reward: 0.0, 4.0765269003386155, time: 30.96
steps: 1107836, episodes: 1176, mean episode reward: 1600.0, 1605.0535196189592, time: 31.057
steps: 1108836, episodes: 1177, mean episode reward: 0.0, 3.581086548567587, time: 31.009
steps: 1109740, episodes: 1178, mean episode reward: 0.0, 4.026613802776113, time: 27.658
steps: 1110686, episodes: 1179, mean episode reward: 0.0, 4.559009669134819, time: 29.031
steps: 1111686, episodes: 1180, mean episode reward: 0.0, 3.959140919649055, time: 30.961
steps: 1112686, episodes: 1181, mean episode reward: 0.0, 4.510898594959685, time: 30.949
steps: 1113686, episodes: 1182, mean episode reward: 0.0, 4.202978127078121, time: 30.926
steps: 1114686, episodes: 1183, mean episode reward: 0.0, 4.066644694307414, time: 31.011
steps: 1115686, episodes: 1184, mean episode reward: 1600.0, 1604.5723062442994, time: 30.899
steps: 1116686, episodes: 1185, mean episode reward: 0.0, 3.73225492389602, time: 30.947
steps: 1117686, episodes: 1186, mean episode reward: 1600.0, 1604.0061469608108, time: 30.876
steps: 1118590, episodes: 1187, mean episode reward: 0.0, 3.6798437234450807, time: 27.582
steps: 1119590, episodes: 1188, mean episode reward: 0.0, 4.082045210710792, time: 31.011
steps: 1120590, episodes: 1189, mean episode reward: 0.0, 3.410921518108653, time: 30.975
steps: 1121590, episodes: 1190, mean episode reward: 0.0, 3.8485067916065914, time: 30.974
steps: 1122590, episodes: 1191, mean episode reward: 0.0, 4.0427103446305015, time: 30.829
steps: 1123590, episodes: 1192, mean episode reward: 0.0, 3.5427497047390815, time: 30.827
steps: 1124590, episodes: 1193, mean episode reward: 1600.0, 1604.3098566367332, time: 30.817
steps: 1125261, episodes: 1194, mean episode reward: 0.0, 2.1677492905871203, time: 19.914
steps: 1126261, episodes: 1195, mean episode reward: 0.0, 4.640590042082087, time: 30.823
steps: 1127261, episodes: 1196, mean episode reward: 0.0, 3.368413722017325, time: 30.848
steps: 1128261, episodes: 1197, mean episode reward: 0.0, 4.065336717778764, time: 30.821
steps: 1129261, episodes: 1198, mean episode reward: 0.0, 3.545636868253942, time: 30.842
steps: 1130261, episodes: 1199, mean episode reward: 0.0, 4.1578134834763665, time: 30.803
steps: 1131261, episodes: 1200, mean episode reward: 0.0, 3.6609835202657037, time: 30.808
steps: 1132261, episodes: 1201, mean episode reward: 0.0, 3.3402633427474693, time: 30.78
steps: 1133261, episodes: 1202, mean episode reward: 0.0, 4.670342558226652, time: 30.744
steps: 1134261, episodes: 1203, mean episode reward: 0.0, 3.5198682127874026, time: 30.788
steps: 1135261, episodes: 1204, mean episode reward: 0.0, 3.721811570705914, time: 30.748
steps: 1136261, episodes: 1205, mean episode reward: 800.0, 804.2816754325647, time: 30.995
steps: 1137261, episodes: 1206, mean episode reward: 0.0, 4.207177134260858, time: 30.745
steps: 1138261, episodes: 1207, mean episode reward: 0.0, 3.956138319909858, time: 30.825
steps: 1139261, episodes: 1208, mean episode reward: 1600.0, 1604.1692616386977, time: 30.778
steps: 1140261, episodes: 1209, mean episode reward: 1600.0, 1603.8609720231523, time: 30.758
steps: 1141261, episodes: 1210, mean episode reward: 0.0, 4.952911950952777, time: 30.758
steps: 1142261, episodes: 1211, mean episode reward: 0.0, 3.633839162139893, time: 30.731
steps: 1143261, episodes: 1212, mean episode reward: 0.0, 3.7295825971473286, time: 30.685
steps: 1144261, episodes: 1213, mean episode reward: 0.0, 2.9591409233580004, time: 30.69
steps: 1145261, episodes: 1214, mean episode reward: 0.0, 3.8116994627221614, time: 30.764
steps: 1146261, episodes: 1215, mean episode reward: 1600.0, 1603.5705573481564, time: 30.662
steps: 1147261, episodes: 1216, mean episode reward: 0.0, 4.198686913660361, time: 30.746
steps: 1148261, episodes: 1217, mean episode reward: 800.0, 804.2164009983405, time: 30.747
steps: 1149261, episodes: 1218, mean episode reward: 0.0, 4.330783521466459, time: 30.671
steps: 1150261, episodes: 1219, mean episode reward: 0.0, 3.847712371710783, time: 30.678
steps: 1151261, episodes: 1220, mean episode reward: 0.0, 3.7053693701750614, time: 30.774
steps: 1152261, episodes: 1221, mean episode reward: 0.0, 4.068681901029406, time: 30.666
steps: 1153261, episodes: 1222, mean episode reward: 0.0, 4.503938917749868, time: 30.679
steps: 1154261, episodes: 1223, mean episode reward: 0.0, 3.904179877017565, time: 30.673
steps: 1155261, episodes: 1224, mean episode reward: 0.0, 3.8560984768890205, time: 30.788
steps: 1156261, episodes: 1225, mean episode reward: 0.0, 4.265486124595321, time: 30.706
steps: 1157261, episodes: 1226, mean episode reward: 0.0, 3.955368350669515, time: 30.685
steps: 1158261, episodes: 1227, mean episode reward: 2400.0, 2402.7833546257066, time: 30.693
steps: 1159261, episodes: 1228, mean episode reward: 0.0, 3.996362352153829, time: 30.713
steps: 1160261, episodes: 1229, mean episode reward: 1600.0, 1603.9386826260159, time: 30.723
steps: 1161261, episodes: 1230, mean episode reward: 0.0, 4.838624932546888, time: 30.596
steps: 1162261, episodes: 1231, mean episode reward: 0.0, 2.9731970202071074, time: 30.623
steps: 1163261, episodes: 1232, mean episode reward: 1600.0, 1604.0696528384399, time: 30.619
steps: 1164261, episodes: 1233, mean episode reward: 0.0, 3.5244650470937584, time: 30.684
steps: 1165261, episodes: 1234, mean episode reward: 0.0, 4.195671399500232, time: 30.687
steps: 1166261, episodes: 1235, mean episode reward: 0.0, 4.23940077258095, time: 30.665
steps: 1167261, episodes: 1236, mean episode reward: 0.0, 3.579153516098573, time: 30.588
steps: 1168261, episodes: 1237, mean episode reward: 0.0, 4.020206214224655, time: 30.617
steps: 1169261, episodes: 1238, mean episode reward: 0.0, 3.8051171726140893, time: 30.541
steps: 1170261, episodes: 1239, mean episode reward: 0.0, 4.208334897817101, time: 30.527
steps: 1171261, episodes: 1240, mean episode reward: 0.0, 3.3826422755798644, time: 30.662
steps: 1172097, episodes: 1241, mean episode reward: 0.0, 3.3326963217209298, time: 24.97
steps: 1173097, episodes: 1242, mean episode reward: 0.0, 5.2042859639956625, time: 30.538
StopIteration()
steps: 1174097, episodes: 1243, mean episode reward: 1600.0, 1604.700009268873, time: 30.535
steps: 1175097, episodes: 1244, mean episode reward: 0.0, 3.962696924441464, time: 30.488
steps: 1176097, episodes: 1245, mean episode reward: 1600.0, 1604.8317302474666, time: 30.514
steps: 1177097, episodes: 1246, mean episode reward: 0.0, 4.268324883977264, time: 30.518
steps: 1178097, episodes: 1247, mean episode reward: 0.0, 4.6897905850591455, time: 30.479
steps: 1179097, episodes: 1248, mean episode reward: 800.0, 803.9138850296476, time: 30.544
steps: 1180097, episodes: 1249, mean episode reward: 0.0, 4.428311272574279, time: 30.743
steps: 1181097, episodes: 1250, mean episode reward: 0.0, 4.0464193533373365, time: 30.505
steps: 1182097, episodes: 1251, mean episode reward: 0.0, 3.583636596908581, time: 30.494
steps: 1182936, episodes: 1252, mean episode reward: 0.0, 3.979790949405042, time: 25.176
steps: 1183936, episodes: 1253, mean episode reward: 1600.0, 1604.8458441649775, time: 30.503
steps: 1184794, episodes: 1254, mean episode reward: 800.0, 803.8742806931026, time: 25.768
steps: 1185794, episodes: 1255, mean episode reward: 0.0, 3.9237600166127944, time: 30.66
steps: 1186794, episodes: 1256, mean episode reward: 0.0, 3.4300289828800743, time: 30.641
steps: 1187794, episodes: 1257, mean episode reward: 0.0, 4.038087077924773, time: 30.545
steps: 1188794, episodes: 1258, mean episode reward: 0.0, 4.532096279765064, time: 30.512
steps: 1189794, episodes: 1259, mean episode reward: 0.0, 3.7434413675386726, time: 30.502
steps: 1190794, episodes: 1260, mean episode reward: 0.0, 4.5295838556587436, time: 30.441
steps: 1191794, episodes: 1261, mean episode reward: 0.0, 3.9056876895497403, time: 30.443
steps: 1192794, episodes: 1262, mean episode reward: 0.0, 3.735351867683214, time: 30.651
steps: 1193794, episodes: 1263, mean episode reward: 0.0, 4.242439894408699, time: 30.364
StopIteration()
steps: 1194794, episodes: 1264, mean episode reward: 0.0, 4.26642130351491, time: 30.526
steps: 1195794, episodes: 1265, mean episode reward: 0.0, 4.067509990783899, time: 30.431
steps: 1196794, episodes: 1266, mean episode reward: 0.0, 3.550740839057555, time: 30.486
steps: 1197794, episodes: 1267, mean episode reward: 0.0, 4.081163307903757, time: 30.413
steps: 1198794, episodes: 1268, mean episode reward: 800.0, 804.4673349637386, time: 30.327
steps: 1199678, episodes: 1269, mean episode reward: 0.0, 3.6227457611540768, time: 26.591
steps: 1200678, episodes: 1270, mean episode reward: 0.0, 3.598737310187107, time: 30.51
steps: 1201676, episodes: 1271, mean episode reward: 0.0, 4.085406586547236, time: 30.324
steps: 1202676, episodes: 1272, mean episode reward: 2400.0, 2402.9127929823453, time: 30.515
steps: 1203676, episodes: 1273, mean episode reward: 0.0, 4.941836516914319, time: 30.501
steps: 1204676, episodes: 1274, mean episode reward: 0.0, 4.496030236979552, time: 30.492
steps: 1205676, episodes: 1275, mean episode reward: 0.0, 3.9800160552409762, time: 30.341
steps: 1206676, episodes: 1276, mean episode reward: 1600.0, 1604.2123861348086, time: 30.396
steps: 1207676, episodes: 1277, mean episode reward: 0.0, 4.060941769618322, time: 30.386
steps: 1208676, episodes: 1278, mean episode reward: 0.0, 2.686030564952387, time: 30.753
steps: 1209676, episodes: 1279, mean episode reward: 0.0, 4.050332568847329, time: 30.543
steps: 1210676, episodes: 1280, mean episode reward: 0.0, 4.209748892423152, time: 30.487
steps: 1211676, episodes: 1281, mean episode reward: 0.0, 4.07958257250094, time: 30.433
steps: 1212676, episodes: 1282, mean episode reward: 0.0, 3.9654370690893828, time: 30.45
steps: 1213616, episodes: 1283, mean episode reward: 0.0, 3.1800646297885558, time: 28.543
steps: 1214419, episodes: 1284, mean episode reward: 1600.0, 1603.0159698629686, time: 23.905
steps: 1215419, episodes: 1285, mean episode reward: 0.0, 3.7917250645512928, time: 30.521
steps: 1216419, episodes: 1286, mean episode reward: 1600.0, 1603.7788822781374, time: 30.59
steps: 1217419, episodes: 1287, mean episode reward: 0.0, 3.723790838900465, time: 30.702
steps: 1218419, episodes: 1288, mean episode reward: 0.0, 2.707094984681099, time: 30.654
steps: 1219419, episodes: 1289, mean episode reward: 1600.0, 1604.3814694212701, time: 30.634
steps: 1220419, episodes: 1290, mean episode reward: 0.0, 3.7555006115692304, time: 30.502
StopIteration()
steps: 1221419, episodes: 1291, mean episode reward: 0.0, 3.898372138835149, time: 30.644
steps: 1222419, episodes: 1292, mean episode reward: 0.0, 4.345068896402307, time: 30.599
steps: 1223419, episodes: 1293, mean episode reward: 0.0, 3.110749176276322, time: 30.591
steps: 1224317, episodes: 1294, mean episode reward: 0.0, 3.7005080113843865, time: 27.159
steps: 1225317, episodes: 1295, mean episode reward: 3200.0, 3203.524440612378, time: 30.653
steps: 1226317, episodes: 1296, mean episode reward: 1600.0, 1603.426942482712, time: 30.547
steps: 1227148, episodes: 1297, mean episode reward: 0.0, 3.0880008743249965, time: 24.891
steps: 1228148, episodes: 1298, mean episode reward: 1600.0, 1604.3464248217565, time: 30.636
steps: 1229148, episodes: 1299, mean episode reward: 1600.0, 1604.3930251133372, time: 30.589
StopIteration()
steps: 1230148, episodes: 1300, mean episode reward: 0.0, 3.8160252854858543, time: 30.664
steps: 1231148, episodes: 1301, mean episode reward: 1600.0, 1603.6453494252014, time: 30.564
steps: 1232148, episodes: 1302, mean episode reward: 1600.0, 1604.0823631495703, time: 30.686
steps: 1233148, episodes: 1303, mean episode reward: 1600.0, 1603.9565314552342, time: 30.639
steps: 1234148, episodes: 1304, mean episode reward: 0.0, 4.031873254917699, time: 30.679
steps: 1235148, episodes: 1305, mean episode reward: 1600.0, 1603.9544410345297, time: 30.639
steps: 1236076, episodes: 1306, mean episode reward: 800.0, 803.525944446779, time: 28.308
steps: 1237076, episodes: 1307, mean episode reward: 0.0, 3.8119578755925634, time: 30.534
steps: 1238076, episodes: 1308, mean episode reward: 800.0, 804.5914513903663, time: 30.646
steps: 1239076, episodes: 1309, mean episode reward: 0.0, 3.4467068951593025, time: 30.784
steps: 1240076, episodes: 1310, mean episode reward: 0.0, 4.0101502124383055, time: 30.557
steps: 1241076, episodes: 1311, mean episode reward: 0.0, 3.0481030692168005, time: 30.55
steps: 1242076, episodes: 1312, mean episode reward: 0.0, 3.837169826681737, time: 30.561
steps: 1243076, episodes: 1313, mean episode reward: 0.0, 4.239554913963238, time: 30.551
steps: 1243994, episodes: 1314, mean episode reward: 0.0, 4.116997802527603, time: 27.721
steps: 1244994, episodes: 1315, mean episode reward: 0.0, 4.073549580139171, time: 30.513
steps: 1245994, episodes: 1316, mean episode reward: 0.0, 3.928505873623542, time: 30.471
steps: 1246994, episodes: 1317, mean episode reward: 0.0, 4.523320053825332, time: 30.484
steps: 1247994, episodes: 1318, mean episode reward: 0.0, 3.6392429745270007, time: 30.396
steps: 1248656, episodes: 1319, mean episode reward: 0.0, 3.118414290775422, time: 19.31
steps: 1249656, episodes: 1320, mean episode reward: 1600.0, 1603.6677664882409, time: 30.443
steps: 1250656, episodes: 1321, mean episode reward: 1600.0, 1604.3251728470336, time: 30.399
steps: 1251498, episodes: 1322, mean episode reward: 1600.0, 1603.2660077581756, time: 25.087
steps: 1252498, episodes: 1323, mean episode reward: 3200.0, 3203.471810926065, time: 30.482
steps: 1253498, episodes: 1324, mean episode reward: 1600.0, 1604.2093169318014, time: 30.651
steps: 1254426, episodes: 1325, mean episode reward: 0.0, 3.575338458610343, time: 28.033
steps: 1255426, episodes: 1326, mean episode reward: 0.0, 2.7306115054416193, time: 30.588
StopIteration()
steps: 1256426, episodes: 1327, mean episode reward: 0.0, 3.272060125645474, time: 30.631
steps: 1257426, episodes: 1328, mean episode reward: 0.0, 3.414435529942991, time: 30.661
steps: 1258426, episodes: 1329, mean episode reward: 1600.0, 1603.8777096828032, time: 30.504
steps: 1259315, episodes: 1330, mean episode reward: 0.0, 4.193172163430692, time: 26.779
steps: 1260315, episodes: 1331, mean episode reward: 0.0, 4.475806551719112, time: 30.502
steps: 1261315, episodes: 1332, mean episode reward: 0.0, 3.9105483591492485, time: 30.475
steps: 1262315, episodes: 1333, mean episode reward: 0.0, 4.278427184813562, time: 30.527
steps: 1263315, episodes: 1334, mean episode reward: 0.0, 4.047493008058573, time: 30.497
StopIteration()
steps: 1264315, episodes: 1335, mean episode reward: 0.0, 4.671554403860664, time: 30.524
StopIteration()
steps: 1265315, episodes: 1336, mean episode reward: 800.0, 804.0154498651183, time: 30.601
steps: 1266315, episodes: 1337, mean episode reward: 0.0, 3.950377534842791, time: 30.582
steps: 1267315, episodes: 1338, mean episode reward: 1600.0, 1604.1731710693984, time: 30.662
steps: 1268315, episodes: 1339, mean episode reward: 0.0, 3.2787205269607322, time: 30.663
steps: 1269275, episodes: 1340, mean episode reward: 0.0, 3.9359283251751886, time: 29.285
steps: 1270275, episodes: 1341, mean episode reward: 0.0, 3.932674875523568, time: 30.565
steps: 1271275, episodes: 1342, mean episode reward: 0.0, 4.392046825926293, time: 30.529
steps: 1272169, episodes: 1343, mean episode reward: 0.0, 3.366745187509664, time: 26.897
steps: 1273113, episodes: 1344, mean episode reward: 0.0, 3.4289192662512766, time: 28.686
steps: 1274113, episodes: 1345, mean episode reward: 0.0, 4.211646262678024, time: 30.557
StopIteration()
steps: 1275113, episodes: 1346, mean episode reward: 1600.0, 1603.9634342881882, time: 30.56
steps: 1276113, episodes: 1347, mean episode reward: 3200.0, 3203.792877165503, time: 30.754
steps: 1277113, episodes: 1348, mean episode reward: 0.0, 4.419235979015416, time: 30.562
steps: 1278113, episodes: 1349, mean episode reward: 0.0, 3.5518521269268857, time: 30.531
steps: 1279113, episodes: 1350, mean episode reward: 1600.0, 1603.6783218501057, time: 30.54
StopIteration()
steps: 1280113, episodes: 1351, mean episode reward: 1600.0, 1603.3433094426837, time: 30.503
steps: 1281113, episodes: 1352, mean episode reward: 0.0, 4.052064425115315, time: 30.535
steps: 1282113, episodes: 1353, mean episode reward: 3200.0, 3203.7436064297076, time: 30.5
steps: 1283113, episodes: 1354, mean episode reward: 800.0, 803.5155502782076, time: 30.569
steps: 1283922, episodes: 1355, mean episode reward: 0.0, 3.3610187662965156, time: 24.091
steps: 1284719, episodes: 1356, mean episode reward: 0.0, 2.9573297694718446, time: 23.667
steps: 1285719, episodes: 1357, mean episode reward: 0.0, 3.3081953109748357, time: 30.516
steps: 1286719, episodes: 1358, mean episode reward: 0.0, 3.9034921947628733, time: 30.572
steps: 1287719, episodes: 1359, mean episode reward: 800.0, 803.9043348863871, time: 30.52
steps: 1288719, episodes: 1360, mean episode reward: 0.0, 4.014481543552061, time: 30.501
StopIteration()
steps: 1289719, episodes: 1361, mean episode reward: 0.0, 4.25119918751601, time: 30.564
steps: 1290719, episodes: 1362, mean episode reward: 0.0, 4.428208902680799, time: 30.617
steps: 1291719, episodes: 1363, mean episode reward: 0.0, 3.9404851728045056, time: 30.538
steps: 1292719, episodes: 1364, mean episode reward: 0.0, 3.7067675065378474, time: 30.582
steps: 1293199, episodes: 1365, mean episode reward: 0.0, 1.8670583596310113, time: 13.677
steps: 1294199, episodes: 1366, mean episode reward: 2400.0, 2403.7667642453116, time: 30.429
StopIteration()
steps: 1295199, episodes: 1367, mean episode reward: 0.0, 2.7378434352527607, time: 30.744
steps: 1296199, episodes: 1368, mean episode reward: 2400.0, 2403.5895769206527, time: 30.587
steps: 1297199, episodes: 1369, mean episode reward: 0.0, 4.150750193723726, time: 30.667
steps: 1297911, episodes: 1370, mean episode reward: 0.0, 2.2336788561094694, time: 21.166
steps: 1298911, episodes: 1371, mean episode reward: 0.0, 4.254809874885991, time: 30.673
steps: 1299667, episodes: 1372, mean episode reward: 0.0, 3.48869571260631, time: 22.256
steps: 1300667, episodes: 1373, mean episode reward: 0.0, 3.69717754387285, time: 30.511
steps: 1301615, episodes: 1374, mean episode reward: 1600.0, 1603.6406986949605, time: 28.745
steps: 1302541, episodes: 1375, mean episode reward: 0.0, 2.6641457921092933, time: 28.058
steps: 1303541, episodes: 1376, mean episode reward: 0.0, 3.8889936545186776, time: 30.523
StopIteration()
steps: 1304541, episodes: 1377, mean episode reward: 1600.0, 1603.7787533128603, time: 30.626
steps: 1305541, episodes: 1378, mean episode reward: 0.0, 3.7861793199678875, time: 30.505
steps: 1306143, episodes: 1379, mean episode reward: 0.0, 2.344429630255864, time: 17.436
steps: 1307143, episodes: 1380, mean episode reward: 0.0, 4.242129303966849, time: 30.558
steps: 1308143, episodes: 1381, mean episode reward: 0.0, 3.6533287343235323, time: 30.456
steps: 1309079, episodes: 1382, mean episode reward: 0.0, 3.868402925995427, time: 28.308
steps: 1310079, episodes: 1383, mean episode reward: 1600.0, 1603.8407579754044, time: 30.546
steps: 1311079, episodes: 1384, mean episode reward: 0.0, 3.473380733901217, time: 30.516
steps: 1312039, episodes: 1385, mean episode reward: 0.0, 3.8439200551095825, time: 29.267
steps: 1313039, episodes: 1386, mean episode reward: 0.0, 3.536162140539679, time: 30.604
steps: 1313954, episodes: 1387, mean episode reward: 0.0, 3.720708445513243, time: 27.551
steps: 1314954, episodes: 1388, mean episode reward: 0.0, 3.7455716979633884, time: 30.563
steps: 1315954, episodes: 1389, mean episode reward: 1600.0, 1603.4847792322296, time: 30.463
StopIteration()
steps: 1316954, episodes: 1390, mean episode reward: 2400.0, 2403.3936633416347, time: 30.398
steps: 1317725, episodes: 1391, mean episode reward: 2400.0, 2402.3730781261584, time: 22.763
steps: 1318352, episodes: 1392, mean episode reward: 1600.0, 1602.286355077208, time: 18.208
steps: 1319352, episodes: 1393, mean episode reward: 800.0, 803.315438598604, time: 30.404
steps: 1320200, episodes: 1394, mean episode reward: 1600.0, 1602.8418319554999, time: 25.281
steps: 1321200, episodes: 1395, mean episode reward: 1600.0, 1603.2588718069742, time: 30.662
steps: 1322200, episodes: 1396, mean episode reward: 1600.0, 1603.6488799443473, time: 30.587
steps: 1323186, episodes: 1397, mean episode reward: 3200.0, 3203.2679768426774, time: 29.953
steps: 1323906, episodes: 1398, mean episode reward: 0.0, 2.4433879274899932, time: 21.2
steps: 1324906, episodes: 1399, mean episode reward: 4000.0, 4003.191739852481, time: 30.61
steps: 1325681, episodes: 1400, mean episode reward: 800.0, 802.5662659695791, time: 22.961
StopIteration()
steps: 1326681, episodes: 1401, mean episode reward: 3200.0, 3203.4279298830006, time: 30.632
StopIteration()
steps: 1327681, episodes: 1402, mean episode reward: 2400.0, 2403.549255592291, time: 30.514
StopIteration()
steps: 1328681, episodes: 1403, mean episode reward: 0.0, 3.240303103763938, time: 30.572
steps: 1329525, episodes: 1404, mean episode reward: 0.0, 3.399106719682929, time: 25.28
steps: 1330426, episodes: 1405, mean episode reward: 0.0, 2.8076701655686236, time: 27.112
steps: 1331426, episodes: 1406, mean episode reward: 4000.0, 4003.0235625944624, time: 30.465
steps: 1332426, episodes: 1407, mean episode reward: 3200.0, 3203.339084994208, time: 30.414
steps: 1333199, episodes: 1408, mean episode reward: 0.0, 3.243568591826762, time: 22.789
steps: 1334199, episodes: 1409, mean episode reward: 1600.0, 1603.1232783333344, time: 30.442
steps: 1334808, episodes: 1410, mean episode reward: 4000.0, 4002.039702848838, time: 17.711
steps: 1335808, episodes: 1411, mean episode reward: 3200.0, 3203.545631012861, time: 30.314
steps: 1336808, episodes: 1412, mean episode reward: 1600.0, 1602.6918520268828, time: 30.51
StopIteration()
steps: 1337808, episodes: 1413, mean episode reward: 800.0, 803.1594878464081, time: 30.549
steps: 1338808, episodes: 1414, mean episode reward: 3200.0, 3203.182224090314, time: 30.638
steps: 1339740, episodes: 1415, mean episode reward: 0.0, 2.5376558291614035, time: 28.106
steps: 1340740, episodes: 1416, mean episode reward: 3200.0, 3202.7793159577172, time: 30.394
steps: 1341740, episodes: 1417, mean episode reward: 1600.0, 1602.9483810238132, time: 30.205
steps: 1342740, episodes: 1418, mean episode reward: 1600.0, 1602.9042411087903, time: 30.363
steps: 1343740, episodes: 1419, mean episode reward: 0.0, 2.7675454054033, time: 30.433
steps: 1344740, episodes: 1420, mean episode reward: 1600.0, 1602.736620189267, time: 30.515
StopIteration()
steps: 1345740, episodes: 1421, mean episode reward: 1600.0, 1603.1642696933186, time: 30.484
steps: 1346574, episodes: 1422, mean episode reward: 0.0, 2.5221767599997023, time: 24.795
steps: 1347574, episodes: 1423, mean episode reward: 1600.0, 1603.132983096636, time: 30.368
steps: 1348492, episodes: 1424, mean episode reward: 0.0, 3.1401767309368678, time: 27.609
steps: 1349041, episodes: 1425, mean episode reward: 0.0, 1.9478139371947263, time: 15.859
steps: 1349982, episodes: 1426, mean episode reward: 0.0, 3.0288095469903014, time: 28.322
steps: 1350982, episodes: 1427, mean episode reward: 0.0, 3.1516561917763517, time: 30.256
steps: 1351717, episodes: 1428, mean episode reward: 0.0, 2.509538142928225, time: 21.533
steps: 1352717, episodes: 1429, mean episode reward: 3200.0, 3203.310430920412, time: 30.502
steps: 1353717, episodes: 1430, mean episode reward: 1600.0, 1603.3638403821778, time: 30.308
steps: 1354690, episodes: 1431, mean episode reward: 1600.0, 1602.7213742784295, time: 29.397
steps: 1355484, episodes: 1432, mean episode reward: 1600.0, 1602.6409475088624, time: 23.685
steps: 1356361, episodes: 1433, mean episode reward: 0.0, 3.110574791971961, time: 26.3
StopIteration()
steps: 1357361, episodes: 1434, mean episode reward: 0.0, 3.106279234090329, time: 30.211
steps: 1358361, episodes: 1435, mean episode reward: 0.0, 3.2909686851560016, time: 30.288
steps: 1359361, episodes: 1436, mean episode reward: 0.0, 3.641819276985099, time: 30.216
steps: 1360361, episodes: 1437, mean episode reward: 3200.0, 3202.8173962804544, time: 30.521
steps: 1361249, episodes: 1438, mean episode reward: 0.0, 3.1805303399213285, time: 26.629
steps: 1362249, episodes: 1439, mean episode reward: 0.0, 3.634266212842574, time: 30.375
steps: 1362985, episodes: 1440, mean episode reward: 0.0, 3.221955886269022, time: 21.582
steps: 1363985, episodes: 1441, mean episode reward: 0.0, 3.666514466352166, time: 30.396
steps: 1364985, episodes: 1442, mean episode reward: 0.0, 3.466625230200731, time: 30.279
steps: 1365985, episodes: 1443, mean episode reward: 0.0, 3.766081690914818, time: 30.389
steps: 1366985, episodes: 1444, mean episode reward: 1600.0, 1603.3015558891482, time: 30.248
steps: 1367786, episodes: 1445, mean episode reward: 0.0, 2.350578293717567, time: 23.791
steps: 1368786, episodes: 1446, mean episode reward: 800.0, 803.993360228148, time: 30.377
steps: 1369786, episodes: 1447, mean episode reward: 0.0, 3.7593482627111783, time: 30.317
steps: 1370786, episodes: 1448, mean episode reward: 0.0, 3.4673715429571352, time: 30.368
steps: 1371786, episodes: 1449, mean episode reward: 0.0, 2.9392070982007, time: 30.714
steps: 1372786, episodes: 1450, mean episode reward: 0.0, 3.693022295527154, time: 30.396
steps: 1373786, episodes: 1451, mean episode reward: 800.0, 803.3593625872886, time: 30.418
steps: 1374786, episodes: 1452, mean episode reward: 0.0, 4.129417945384294, time: 30.346
steps: 1375619, episodes: 1453, mean episode reward: 800.0, 803.1319216850535, time: 24.902
steps: 1376406, episodes: 1454, mean episode reward: 0.0, 2.9547455900068744, time: 23.364
steps: 1377260, episodes: 1455, mean episode reward: 0.0, 3.2042342503376977, time: 25.432
steps: 1378142, episodes: 1456, mean episode reward: 0.0, 3.3213360803033356, time: 26.36
steps: 1379142, episodes: 1457, mean episode reward: 1600.0, 1603.256475922934, time: 30.439
steps: 1380142, episodes: 1458, mean episode reward: 0.0, 3.971414696396829, time: 30.478
steps: 1381142, episodes: 1459, mean episode reward: 0.0, 3.806512914608318, time: 30.44
steps: 1382142, episodes: 1460, mean episode reward: 0.0, 3.167869181373531, time: 30.414
steps: 1383142, episodes: 1461, mean episode reward: 1600.0, 1604.1343331163223, time: 30.259
steps: 1384142, episodes: 1462, mean episode reward: 1600.0, 1604.0760379183394, time: 30.375
steps: 1385142, episodes: 1463, mean episode reward: 0.0, 3.961232468066725, time: 30.383
steps: 1386142, episodes: 1464, mean episode reward: 0.0, 3.0449358363563195, time: 30.46
steps: 1387142, episodes: 1465, mean episode reward: 0.0, 4.05460001652146, time: 30.196
steps: 1388142, episodes: 1466, mean episode reward: 0.0, 4.064597488425569, time: 30.376
steps: 1389142, episodes: 1467, mean episode reward: 0.0, 3.9466072397118794, time: 30.351
steps: 1390142, episodes: 1468, mean episode reward: 0.0, 3.062344231051232, time: 30.404
steps: 1391121, episodes: 1469, mean episode reward: 0.0, 3.74077250411223, time: 29.488
steps: 1392121, episodes: 1470, mean episode reward: 0.0, 3.752904248163486, time: 30.156
steps: 1393121, episodes: 1471, mean episode reward: 0.0, 4.031183237231374, time: 30.339
steps: 1394121, episodes: 1472, mean episode reward: 0.0, 4.374892583826069, time: 30.178
steps: 1395121, episodes: 1473, mean episode reward: 0.0, 4.11439879062883, time: 30.504
steps: 1396121, episodes: 1474, mean episode reward: 0.0, 3.7641989346915903, time: 30.332
steps: 1397121, episodes: 1475, mean episode reward: 0.0, 4.440515208084154, time: 30.377
steps: 1398121, episodes: 1476, mean episode reward: 0.0, 3.4680979709151356, time: 30.301
steps: 1399121, episodes: 1477, mean episode reward: 800.0, 804.0363283832704, time: 30.251
steps: 1400121, episodes: 1478, mean episode reward: 1600.0, 1604.0839488858055, time: 30.327
steps: 1401121, episodes: 1479, mean episode reward: 0.0, 3.6689485731302587, time: 30.465
steps: 1402121, episodes: 1480, mean episode reward: 0.0, 4.322622339119701, time: 30.342
steps: 1403121, episodes: 1481, mean episode reward: 1600.0, 1604.06347784537, time: 30.294
steps: 1404121, episodes: 1482, mean episode reward: 0.0, 3.747133878915988, time: 30.218
steps: 1405121, episodes: 1483, mean episode reward: 0.0, 4.747091958917665, time: 30.25
steps: 1405808, episodes: 1484, mean episode reward: 0.0, 3.0341396076627243, time: 19.922
steps: 1406808, episodes: 1485, mean episode reward: 0.0, 4.604302211070908, time: 30.291
steps: 1407808, episodes: 1486, mean episode reward: 800.0, 803.9626797381802, time: 30.382
steps: 1408808, episodes: 1487, mean episode reward: 0.0, 4.706283459283353, time: 30.277
steps: 1409808, episodes: 1488, mean episode reward: 0.0, 3.4158556820575185, time: 30.441
steps: 1410808, episodes: 1489, mean episode reward: 0.0, 4.048505639037258, time: 30.346
steps: 1411808, episodes: 1490, mean episode reward: 0.0, 5.058300967366308, time: 30.335
steps: 1412808, episodes: 1491, mean episode reward: 1600.0, 1603.7912017675856, time: 30.264
steps: 1413808, episodes: 1492, mean episode reward: 0.0, 4.243640582854951, time: 30.273
steps: 1414808, episodes: 1493, mean episode reward: 0.0, 4.522981380020205, time: 30.294
steps: 1415808, episodes: 1494, mean episode reward: 0.0, 4.169335037576356, time: 30.469
steps: 1416808, episodes: 1495, mean episode reward: 0.0, 3.781707754232127, time: 30.342
steps: 1417808, episodes: 1496, mean episode reward: 0.0, 4.020977982121136, time: 30.462
steps: 1418808, episodes: 1497, mean episode reward: 0.0, 4.049790969806593, time: 30.195
steps: 1419808, episodes: 1498, mean episode reward: 0.0, 4.408089795019114, time: 30.167
steps: 1420808, episodes: 1499, mean episode reward: 0.0, 4.276788196318543, time: 30.12
steps: 1421808, episodes: 1500, mean episode reward: 0.0, 3.386577314720789, time: 30.289
steps: 1422808, episodes: 1501, mean episode reward: 800.0, 803.5649623911095, time: 30.298
steps: 1423808, episodes: 1502, mean episode reward: 0.0, 4.278812635838781, time: 30.174
steps: 1424734, episodes: 1503, mean episode reward: 0.0, 3.557454719521221, time: 27.76
steps: 1425734, episodes: 1504, mean episode reward: 0.0, 3.9844942094970284, time: 30.286
steps: 1426734, episodes: 1505, mean episode reward: 0.0, 4.934775758015893, time: 30.205
steps: 1427734, episodes: 1506, mean episode reward: 0.0, 4.082118353729525, time: 30.376
steps: 1428734, episodes: 1507, mean episode reward: 800.0, 804.0169503451943, time: 30.511
steps: 1429734, episodes: 1508, mean episode reward: 0.0, 3.7245649939032006, time: 30.37
steps: 1430734, episodes: 1509, mean episode reward: 0.0, 3.8813450558932527, time: 30.236
steps: 1431734, episodes: 1510, mean episode reward: 800.0, 803.8725853851696, time: 30.471
steps: 1432629, episodes: 1511, mean episode reward: 800.0, 803.8064100732472, time: 26.673
steps: 1433629, episodes: 1512, mean episode reward: 0.0, 3.7194133961750415, time: 30.28
steps: 1434629, episodes: 1513, mean episode reward: 0.0, 3.3231843098700797, time: 30.426
steps: 1435629, episodes: 1514, mean episode reward: 1600.0, 1603.7608204435176, time: 30.258
steps: 1436629, episodes: 1515, mean episode reward: 0.0, 4.575271485526648, time: 30.216
steps: 1437629, episodes: 1516, mean episode reward: 0.0, 4.033804759127445, time: 30.278
steps: 1438629, episodes: 1517, mean episode reward: 0.0, 3.9250189001830327, time: 30.21
steps: 1439629, episodes: 1518, mean episode reward: 0.0, 4.122458156466568, time: 30.346
steps: 1440629, episodes: 1519, mean episode reward: 0.0, 5.177858098513338, time: 30.354
steps: 1441629, episodes: 1520, mean episode reward: 0.0, 3.9292271284989675, time: 30.201
steps: 1442629, episodes: 1521, mean episode reward: 0.0, 4.009724579577592, time: 30.209
steps: 1443629, episodes: 1522, mean episode reward: 0.0, 3.7743993033952092, time: 30.255
steps: 1444629, episodes: 1523, mean episode reward: 800.0, 804.0798146322419, time: 30.32
steps: 1445629, episodes: 1524, mean episode reward: 0.0, 3.170852786853466, time: 30.621
steps: 1446629, episodes: 1525, mean episode reward: 0.0, 4.080521038313504, time: 30.315
steps: 1447629, episodes: 1526, mean episode reward: 0.0, 3.3509478531478067, time: 30.349
steps: 1448629, episodes: 1527, mean episode reward: 0.0, 4.1135812107182215, time: 30.329
steps: 1449629, episodes: 1528, mean episode reward: 1600.0, 1603.7724990159732, time: 30.324
steps: 1450629, episodes: 1529, mean episode reward: 1600.0, 1603.1706833539376, time: 30.305
steps: 1451629, episodes: 1530, mean episode reward: 0.0, 2.8993220913191284, time: 30.394
steps: 1452629, episodes: 1531, mean episode reward: 0.0, 4.361749607894811, time: 30.252
steps: 1453629, episodes: 1532, mean episode reward: 0.0, 4.246661085094856, time: 30.277
steps: 1454629, episodes: 1533, mean episode reward: 0.0, 4.706407875299983, time: 30.21
steps: 1455629, episodes: 1534, mean episode reward: 0.0, 4.012412879411678, time: 30.418
steps: 1456629, episodes: 1535, mean episode reward: 0.0, 3.758266429740936, time: 30.189
steps: 1457629, episodes: 1536, mean episode reward: 0.0, 4.276946328358471, time: 30.219
steps: 1458629, episodes: 1537, mean episode reward: 0.0, 3.1789456328979893, time: 30.361
steps: 1459629, episodes: 1538, mean episode reward: 0.0, 4.093942685629269, time: 30.265
steps: 1460629, episodes: 1539, mean episode reward: 0.0, 3.668845115430993, time: 30.397
steps: 1461629, episodes: 1540, mean episode reward: 0.0, 3.6178857404406566, time: 30.332
steps: 1462629, episodes: 1541, mean episode reward: 0.0, 3.9797970698471254, time: 30.221
steps: 1463629, episodes: 1542, mean episode reward: 0.0, 3.6158750000471116, time: 30.198
steps: 1464629, episodes: 1543, mean episode reward: 0.0, 4.11385060782905, time: 30.193
steps: 1465629, episodes: 1544, mean episode reward: 0.0, 3.575744295991669, time: 30.464
steps: 1466629, episodes: 1545, mean episode reward: 0.0, 4.259536365673822, time: 30.242
steps: 1467629, episodes: 1546, mean episode reward: 0.0, 4.748510599965219, time: 31.962
steps: 1468629, episodes: 1547, mean episode reward: 0.0, 4.609913478533843, time: 31.302
steps: 1469629, episodes: 1548, mean episode reward: 0.0, 4.179720472086023, time: 35.656
steps: 1470629, episodes: 1549, mean episode reward: 0.0, 3.558451204930405, time: 30.976
steps: 1471533, episodes: 1550, mean episode reward: 0.0, 3.8510760346924227, time: 29.013
steps: 1472533, episodes: 1551, mean episode reward: 1600.0, 1604.0408486314707, time: 32.059
steps: 1473533, episodes: 1552, mean episode reward: 0.0, 4.3049742989038196, time: 30.232
steps: 1474533, episodes: 1553, mean episode reward: 0.0, 3.816944145685112, time: 30.881
steps: 1475533, episodes: 1554, mean episode reward: 0.0, 4.16175768129765, time: 30.29
steps: 1476533, episodes: 1555, mean episode reward: 0.0, 3.374250001145615, time: 30.287
steps: 1477533, episodes: 1556, mean episode reward: 0.0, 4.03592202930422, time: 31.697
steps: 1478427, episodes: 1557, mean episode reward: 0.0, 2.9931650255523765, time: 26.836
steps: 1479427, episodes: 1558, mean episode reward: 0.0, 3.5803186589771037, time: 30.398
steps: 1480427, episodes: 1559, mean episode reward: 0.0, 3.870919421551477, time: 32.34
steps: 1481427, episodes: 1560, mean episode reward: 0.0, 3.7315778753026083, time: 34.431
steps: 1482427, episodes: 1561, mean episode reward: 0.0, 3.979770091578639, time: 32.896
StopIteration()
steps: 1483427, episodes: 1562, mean episode reward: 0.0, 4.71727777252896, time: 33.741
steps: 1484427, episodes: 1563, mean episode reward: 0.0, 4.430826327699104, time: 30.318
steps: 1485427, episodes: 1564, mean episode reward: 0.0, 2.8728646907581568, time: 30.651
steps: 1486427, episodes: 1565, mean episode reward: 0.0, 4.296751368858368, time: 37.356
steps: 1487427, episodes: 1566, mean episode reward: 800.0, 803.6760825532817, time: 31.333
steps: 1488427, episodes: 1567, mean episode reward: 0.0, 3.893937580157045, time: 31.68
steps: 1489427, episodes: 1568, mean episode reward: 0.0, 3.758697403679392, time: 31.616
steps: 1490427, episodes: 1569, mean episode reward: 0.0, 3.3593354708759464, time: 31.868
steps: 1491427, episodes: 1570, mean episode reward: 0.0, 3.974117470863871, time: 32.126
steps: 1492427, episodes: 1571, mean episode reward: 0.0, 4.00511695897549, time: 31.637
steps: 1493427, episodes: 1572, mean episode reward: 0.0, 3.1759498296745248, time: 31.702
steps: 1494427, episodes: 1573, mean episode reward: 0.0, 4.137445037804875, time: 31.607
steps: 1495427, episodes: 1574, mean episode reward: 0.0, 3.864321854435656, time: 31.598
steps: 1496427, episodes: 1575, mean episode reward: 0.0, 3.3901207664291357, time: 31.594
steps: 1497427, episodes: 1576, mean episode reward: 0.0, 4.335330563437532, time: 31.451
steps: 1498427, episodes: 1577, mean episode reward: 1600.0, 1603.757752032517, time: 31.601
steps: 1499427, episodes: 1578, mean episode reward: 0.0, 4.214525067150591, time: 31.559
steps: 1500427, episodes: 1579, mean episode reward: 0.0, 3.578442361431911, time: 31.59
steps: 1501427, episodes: 1580, mean episode reward: 0.0, 3.7065921322001145, time: 31.598
steps: 1502427, episodes: 1581, mean episode reward: 0.0, 4.241596737763222, time: 31.622
steps: 1503427, episodes: 1582, mean episode reward: 0.0, 4.659984905474416, time: 31.602
steps: 1504427, episodes: 1583, mean episode reward: 0.0, 4.509338120037796, time: 31.736
steps: 1505427, episodes: 1584, mean episode reward: 0.0, 4.1741086347609135, time: 31.626
steps: 1506328, episodes: 1585, mean episode reward: 1600.0, 1603.3235574787172, time: 28.197
steps: 1507328, episodes: 1586, mean episode reward: 0.0, 4.112454827562493, time: 31.511
steps: 1508328, episodes: 1587, mean episode reward: 0.0, 3.1359719371517016, time: 31.658
steps: 1509328, episodes: 1588, mean episode reward: 0.0, 4.100628851782954, time: 31.573
steps: 1510328, episodes: 1589, mean episode reward: 0.0, 4.22890520739324, time: 31.49
steps: 1511328, episodes: 1590, mean episode reward: 0.0, 4.486659564298095, time: 31.65
steps: 1512328, episodes: 1591, mean episode reward: 0.0, 3.8044659065368367, time: 31.712
steps: 1513328, episodes: 1592, mean episode reward: 0.0, 4.211835142268509, time: 31.473
steps: 1514328, episodes: 1593, mean episode reward: 0.0, 4.126806931517022, time: 31.78
steps: 1515328, episodes: 1594, mean episode reward: 1600.0, 1603.681912022951, time: 31.688
steps: 1516328, episodes: 1595, mean episode reward: 0.0, 3.988923414858068, time: 31.714
steps: 1517154, episodes: 1596, mean episode reward: 0.0, 3.793702602033359, time: 25.658
steps: 1518154, episodes: 1597, mean episode reward: 1600.0, 1603.9186430240718, time: 31.808
steps: 1519048, episodes: 1598, mean episode reward: 0.0, 3.523141380305835, time: 28.062
steps: 1520048, episodes: 1599, mean episode reward: 0.0, 4.063546064863616, time: 31.716
steps: 1521048, episodes: 1600, mean episode reward: 0.0, 3.950332870777802, time: 31.577
steps: 1522048, episodes: 1601, mean episode reward: 0.0, 3.9979026487531213, time: 31.681
steps: 1523048, episodes: 1602, mean episode reward: 0.0, 3.4693972531628083, time: 31.748
steps: 1524048, episodes: 1603, mean episode reward: 0.0, 4.160806900096815, time: 32.226
steps: 1525048, episodes: 1604, mean episode reward: 0.0, 3.378209005365939, time: 32.504
steps: 1526048, episodes: 1605, mean episode reward: 0.0, 4.1575822725022835, time: 30.926
steps: 1527048, episodes: 1606, mean episode reward: 0.0, 4.190026594703532, time: 30.851
steps: 1528048, episodes: 1607, mean episode reward: 1600.0, 1603.6170461577474, time: 30.932
steps: 1529048, episodes: 1608, mean episode reward: 0.0, 3.8997673541932563, time: 33.492
steps: 1530048, episodes: 1609, mean episode reward: 0.0, 4.24577014725453, time: 33.944
steps: 1531048, episodes: 1610, mean episode reward: 0.0, 3.619558880985835, time: 31.02
steps: 1532048, episodes: 1611, mean episode reward: 0.0, 4.636908691783042, time: 30.985
steps: 1533048, episodes: 1612, mean episode reward: 1600.0, 1604.1583440794877, time: 30.915
steps: 1534048, episodes: 1613, mean episode reward: 0.0, 4.450127134827239, time: 33.486
steps: 1535048, episodes: 1614, mean episode reward: 0.0, 4.233919326568024, time: 33.321
steps: 1536048, episodes: 1615, mean episode reward: 0.0, 4.072185684150678, time: 31.278
steps: 1537048, episodes: 1616, mean episode reward: 0.0, 3.6873651697903274, time: 30.923
steps: 1538048, episodes: 1617, mean episode reward: 0.0, 4.506172910773899, time: 30.911
steps: 1539048, episodes: 1618, mean episode reward: 0.0, 4.372216637472332, time: 30.98
steps: 1540048, episodes: 1619, mean episode reward: 0.0, 4.0104694495543995, time: 31.229
steps: 1541048, episodes: 1620, mean episode reward: 0.0, 4.839341040579157, time: 30.996
steps: 1542048, episodes: 1621, mean episode reward: 0.0, 3.8192949503902773, time: 30.891
steps: 1543048, episodes: 1622, mean episode reward: 0.0, 4.290517998499402, time: 30.998
steps: 1544048, episodes: 1623, mean episode reward: 1600.0, 1603.4608694429278, time: 30.953
steps: 1545048, episodes: 1624, mean episode reward: 0.0, 3.448494797911961, time: 30.86
steps: 1546048, episodes: 1625, mean episode reward: 1600.0, 1603.9696334189662, time: 30.745
steps: 1547048, episodes: 1626, mean episode reward: 0.0, 4.2045559730250295, time: 31.056
steps: 1548048, episodes: 1627, mean episode reward: 0.0, 4.281429272919537, time: 30.796
steps: 1549048, episodes: 1628, mean episode reward: 0.0, 3.3001095503882736, time: 30.896
steps: 1550048, episodes: 1629, mean episode reward: 0.0, 4.425612592672156, time: 30.916
steps: 1551048, episodes: 1630, mean episode reward: 0.0, 3.754530328299457, time: 31.029
steps: 1552048, episodes: 1631, mean episode reward: 0.0, 3.8244442194684973, time: 30.909
steps: 1553048, episodes: 1632, mean episode reward: 0.0, 3.91124378250399, time: 30.933
steps: 1554048, episodes: 1633, mean episode reward: 0.0, 3.683106229769485, time: 30.945
steps: 1555048, episodes: 1634, mean episode reward: 0.0, 3.9924216860104083, time: 30.89
steps: 1556048, episodes: 1635, mean episode reward: 0.0, 3.92391429429944, time: 30.885
steps: 1557048, episodes: 1636, mean episode reward: 0.0, 3.795802519184174, time: 30.897
steps: 1558048, episodes: 1637, mean episode reward: 0.0, 3.745481328668428, time: 30.872
steps: 1559048, episodes: 1638, mean episode reward: 0.0, 3.2946825564075772, time: 31.042
steps: 1560048, episodes: 1639, mean episode reward: 0.0, 3.2985404362507627, time: 31.1
steps: 1561048, episodes: 1640, mean episode reward: 0.0, 4.045948402024664, time: 30.917
steps: 1562048, episodes: 1641, mean episode reward: 0.0, 3.4452382377011186, time: 30.998
steps: 1563048, episodes: 1642, mean episode reward: 0.0, 3.836834028405376, time: 31.027
steps: 1564048, episodes: 1643, mean episode reward: 0.0, 3.75017006581494, time: 30.931
steps: 1565048, episodes: 1644, mean episode reward: 0.0, 3.8330381668418863, time: 31.013
steps: 1566048, episodes: 1645, mean episode reward: 0.0, 4.112804574437438, time: 30.945
steps: 1567048, episodes: 1646, mean episode reward: 0.0, 3.2527486255851383, time: 30.957
steps: 1568048, episodes: 1647, mean episode reward: 0.0, 4.5873308451344865, time: 30.91
steps: 1569048, episodes: 1648, mean episode reward: 0.0, 3.840715835173101, time: 31.018
steps: 1570048, episodes: 1649, mean episode reward: 0.0, 3.9878846584657444, time: 30.956
steps: 1571048, episodes: 1650, mean episode reward: 1600.0, 1604.0614122753618, time: 30.885
steps: 1572048, episodes: 1651, mean episode reward: 0.0, 4.250963145378853, time: 31.02
steps: 1573048, episodes: 1652, mean episode reward: 0.0, 3.7180667511389407, time: 30.873
steps: 1573877, episodes: 1653, mean episode reward: 0.0, 2.7598546100144463, time: 25.093
steps: 1574877, episodes: 1654, mean episode reward: 0.0, 3.926296565888323, time: 31.035
steps: 1575877, episodes: 1655, mean episode reward: 0.0, 3.853279962792082, time: 30.909
steps: 1576877, episodes: 1656, mean episode reward: 0.0, 3.6010318189102657, time: 30.912
steps: 1577877, episodes: 1657, mean episode reward: 0.0, 3.7054464556453315, time: 34.656
steps: 1578877, episodes: 1658, mean episode reward: 0.0, 3.9943218432134433, time: 40.627
steps: 1579703, episodes: 1659, mean episode reward: 0.0, 3.431799581671649, time: 33.963
StopIteration()
steps: 1580703, episodes: 1660, mean episode reward: 0.0, 3.0247609603217924, time: 37.17
steps: 1581703, episodes: 1661, mean episode reward: 0.0, 4.2780607700973095, time: 34.27
steps: 1582703, episodes: 1662, mean episode reward: 0.0, 3.624604994425656, time: 41.574
steps: 1583703, episodes: 1663, mean episode reward: 1600.0, 1603.8032270204808, time: 33.219
steps: 1584703, episodes: 1664, mean episode reward: 0.0, 3.987531186420327, time: 32.052
steps: 1585703, episodes: 1665, mean episode reward: 0.0, 3.261076008316511, time: 30.809
steps: 1586703, episodes: 1666, mean episode reward: 0.0, 3.5871462966963508, time: 30.666
steps: 1587703, episodes: 1667, mean episode reward: 0.0, 3.252464728722177, time: 30.693
steps: 1588703, episodes: 1668, mean episode reward: 0.0, 3.915363136249751, time: 30.602
StopIteration()
steps: 1589703, episodes: 1669, mean episode reward: 0.0, 3.727847176994468, time: 30.726
steps: 1590703, episodes: 1670, mean episode reward: 0.0, 3.4310079065373684, time: 30.788
steps: 1591703, episodes: 1671, mean episode reward: 0.0, 3.4398181757570168, time: 30.607
steps: 1592703, episodes: 1672, mean episode reward: 0.0, 4.350172038420442, time: 30.776
steps: 1593703, episodes: 1673, mean episode reward: 0.0, 4.303867957287736, time: 30.678
steps: 1594703, episodes: 1674, mean episode reward: 1600.0, 1603.650515357712, time: 30.671
steps: 1595703, episodes: 1675, mean episode reward: 0.0, 3.7767812673310566, time: 30.737
steps: 1596703, episodes: 1676, mean episode reward: 0.0, 3.7865146051228793, time: 30.765
steps: 1597703, episodes: 1677, mean episode reward: 0.0, 3.8259050113292377, time: 30.798
steps: 1598703, episodes: 1678, mean episode reward: 0.0, 3.2714307518426056, time: 30.813
steps: 1599703, episodes: 1679, mean episode reward: 0.0, 3.7625955242535336, time: 30.724
steps: 1600703, episodes: 1680, mean episode reward: 0.0, 2.9660532358764375, time: 30.807
steps: 1601703, episodes: 1681, mean episode reward: 0.0, 3.6830126665010448, time: 30.589
steps: 1602703, episodes: 1682, mean episode reward: 0.0, 4.075498006862549, time: 30.634
steps: 1603703, episodes: 1683, mean episode reward: 0.0, 3.881610314237618, time: 31.36
steps: 1604703, episodes: 1684, mean episode reward: 0.0, 4.0658357469575055, time: 30.608
steps: 1605703, episodes: 1685, mean episode reward: 0.0, 4.4594816836833395, time: 30.578
steps: 1606703, episodes: 1686, mean episode reward: 0.0, 3.870852033703061, time: 30.653
steps: 1607703, episodes: 1687, mean episode reward: 0.0, 3.4625867956896172, time: 30.483
steps: 1608703, episodes: 1688, mean episode reward: 0.0, 3.8080638123382755, time: 30.682
steps: 1609703, episodes: 1689, mean episode reward: 0.0, 3.6249887741998537, time: 30.626
steps: 1610703, episodes: 1690, mean episode reward: 0.0, 4.054141794029557, time: 30.548
steps: 1611703, episodes: 1691, mean episode reward: 0.0, 3.8601350291238328, time: 30.579
steps: 1612703, episodes: 1692, mean episode reward: 0.0, 3.7619346837049763, time: 30.493
steps: 1613703, episodes: 1693, mean episode reward: 0.0, 3.338265862129149, time: 30.546
steps: 1614703, episodes: 1694, mean episode reward: 0.0, 3.2122608636797385, time: 30.616
steps: 1615703, episodes: 1695, mean episode reward: 0.0, 3.5765671881775103, time: 30.526
steps: 1616703, episodes: 1696, mean episode reward: 0.0, 3.192551541894093, time: 30.716
steps: 1617703, episodes: 1697, mean episode reward: 0.0, 3.5944967379690396, time: 30.68
steps: 1618703, episodes: 1698, mean episode reward: 0.0, 3.982809425767659, time: 30.56
steps: 1619703, episodes: 1699, mean episode reward: 800.0, 803.8700010649757, time: 30.645
steps: 1620703, episodes: 1700, mean episode reward: 0.0, 3.1161679425898163, time: 30.615
steps: 1621703, episodes: 1701, mean episode reward: 0.0, 3.689173241927587, time: 30.629
steps: 1622703, episodes: 1702, mean episode reward: 0.0, 3.6922572601192067, time: 30.673
steps: 1623703, episodes: 1703, mean episode reward: 0.0, 4.258366740575499, time: 30.521
steps: 1624703, episodes: 1704, mean episode reward: 0.0, 3.918845443564977, time: 30.503
steps: 1625703, episodes: 1705, mean episode reward: 0.0, 4.7178599369539445, time: 30.537
steps: 1626703, episodes: 1706, mean episode reward: 0.0, 3.191130514176588, time: 30.584
steps: 1627703, episodes: 1707, mean episode reward: 0.0, 3.09407006192004, time: 30.604
steps: 1628703, episodes: 1708, mean episode reward: 0.0, 3.0453376959524157, time: 30.58
steps: 1629703, episodes: 1709, mean episode reward: 0.0, 3.1004490188095586, time: 30.66
steps: 1630703, episodes: 1710, mean episode reward: 1600.0, 1603.334979887557, time: 30.512
steps: 1631703, episodes: 1711, mean episode reward: 0.0, 4.341537635349671, time: 30.536
steps: 1632535, episodes: 1712, mean episode reward: 0.0, 2.894388843823825, time: 24.884
steps: 1633535, episodes: 1713, mean episode reward: 0.0, 3.287872070942198, time: 30.521
steps: 1634535, episodes: 1714, mean episode reward: 0.0, 3.7880176407115203, time: 30.526
steps: 1635535, episodes: 1715, mean episode reward: 0.0, 3.482541915241714, time: 30.498
steps: 1636535, episodes: 1716, mean episode reward: 0.0, 3.824546485533381, time: 30.506
steps: 1637535, episodes: 1717, mean episode reward: 0.0, 3.8532494332116936, time: 30.601
steps: 1638535, episodes: 1718, mean episode reward: 0.0, 4.538904825402198, time: 30.509
steps: 1639535, episodes: 1719, mean episode reward: 0.0, 3.4914780993928836, time: 30.553
steps: 1640535, episodes: 1720, mean episode reward: 0.0, 3.671930275373649, time: 30.495
steps: 1641535, episodes: 1721, mean episode reward: 0.0, 3.992171477573927, time: 30.456
steps: 1642535, episodes: 1722, mean episode reward: 0.0, 3.685725130496692, time: 30.517
steps: 1643535, episodes: 1723, mean episode reward: 0.0, 4.393237695738877, time: 30.429
steps: 1644535, episodes: 1724, mean episode reward: 0.0, 3.673624644265704, time: 30.47
steps: 1645535, episodes: 1725, mean episode reward: 0.0, 4.308709359195913, time: 30.497
steps: 1646535, episodes: 1726, mean episode reward: 0.0, 3.509641706683759, time: 30.612
steps: 1647535, episodes: 1727, mean episode reward: 0.0, 3.2856337767598793, time: 30.531
steps: 1648535, episodes: 1728, mean episode reward: 0.0, 3.5717889821380897, time: 30.464
steps: 1649535, episodes: 1729, mean episode reward: 0.0, 4.416489713693329, time: 30.633
steps: 1650535, episodes: 1730, mean episode reward: 1600.0, 1602.7894490225306, time: 30.644
steps: 1651461, episodes: 1731, mean episode reward: 0.0, 3.041063225438677, time: 28.137
steps: 1652461, episodes: 1732, mean episode reward: 0.0, 3.9108540481049143, time: 30.719
steps: 1653461, episodes: 1733, mean episode reward: 0.0, 4.01339528003292, time: 30.619
steps: 1654461, episodes: 1734, mean episode reward: 0.0, 4.924753816245875, time: 30.534
steps: 1655461, episodes: 1735, mean episode reward: 0.0, 3.6115907651028136, time: 30.612
steps: 1656461, episodes: 1736, mean episode reward: 0.0, 3.7785675698292644, time: 30.578
steps: 1657461, episodes: 1737, mean episode reward: 0.0, 3.3044718185577593, time: 30.478
steps: 1658461, episodes: 1738, mean episode reward: 0.0, 3.4544964648712138, time: 30.487
steps: 1659461, episodes: 1739, mean episode reward: 0.0, 4.422959444609812, time: 30.59
StopIteration()
steps: 1660461, episodes: 1740, mean episode reward: 1600.0, 1604.177551354471, time: 30.654
steps: 1661461, episodes: 1741, mean episode reward: 0.0, 3.939249791563266, time: 30.568
steps: 1662461, episodes: 1742, mean episode reward: 0.0, 2.6216117326450314, time: 30.718
steps: 1663461, episodes: 1743, mean episode reward: 0.0, 3.4203674120713146, time: 30.752
steps: 1664461, episodes: 1744, mean episode reward: 0.0, 4.588450318626004, time: 30.623
steps: 1665461, episodes: 1745, mean episode reward: 0.0, 4.162201922193772, time: 30.781
steps: 1666461, episodes: 1746, mean episode reward: 0.0, 3.6889035387570326, time: 30.713
steps: 1667461, episodes: 1747, mean episode reward: 0.0, 3.5849343410848045, time: 30.59
steps: 1668461, episodes: 1748, mean episode reward: 0.0, 4.065267736698565, time: 30.629
steps: 1669461, episodes: 1749, mean episode reward: 0.0, 3.7327757823236625, time: 30.602
steps: 1670461, episodes: 1750, mean episode reward: 0.0, 3.611808636332202, time: 30.367
steps: 1671461, episodes: 1751, mean episode reward: 1600.0, 1603.5198800212781, time: 30.547
steps: 1672461, episodes: 1752, mean episode reward: 0.0, 4.435701101886973, time: 30.562
steps: 1673461, episodes: 1753, mean episode reward: 800.0, 803.4729794390497, time: 30.478
steps: 1674461, episodes: 1754, mean episode reward: 0.0, 3.3630028695299545, time: 30.627
steps: 1675461, episodes: 1755, mean episode reward: 0.0, 3.681526001670593, time: 30.468
steps: 1676461, episodes: 1756, mean episode reward: 0.0, 3.364040694328929, time: 30.559
steps: 1677461, episodes: 1757, mean episode reward: 1600.0, 1603.655316315839, time: 30.536
steps: 1678461, episodes: 1758, mean episode reward: 0.0, 3.2406296542320185, time: 30.629
StopIteration()
steps: 1679461, episodes: 1759, mean episode reward: 0.0, 3.5637186533869407, time: 30.584
steps: 1680461, episodes: 1760, mean episode reward: 0.0, 3.718185813081997, time: 30.693
steps: 1681461, episodes: 1761, mean episode reward: 1600.0, 1604.0172134311138, time: 30.562
steps: 1682461, episodes: 1762, mean episode reward: 0.0, 3.5753740618387564, time: 30.607
steps: 1683461, episodes: 1763, mean episode reward: 0.0, 3.316369149469902, time: 30.574
steps: 1684346, episodes: 1764, mean episode reward: 3200.0, 3203.3275614429926, time: 26.722
steps: 1685346, episodes: 1765, mean episode reward: 0.0, 4.096873295896811, time: 30.628
steps: 1686346, episodes: 1766, mean episode reward: 0.0, 3.8757633481293174, time: 30.533
steps: 1687346, episodes: 1767, mean episode reward: 0.0, 3.9312519183852803, time: 30.54
steps: 1688346, episodes: 1768, mean episode reward: 1600.0, 1603.195958571671, time: 30.7
steps: 1689346, episodes: 1769, mean episode reward: 2400.0, 2403.1101867670986, time: 30.693
steps: 1690346, episodes: 1770, mean episode reward: 1600.0, 1603.4044731221131, time: 30.539
steps: 1691346, episodes: 1771, mean episode reward: 0.0, 3.9696912737159424, time: 30.457
steps: 1692346, episodes: 1772, mean episode reward: 0.0, 3.1632227480038537, time: 30.608
steps: 1693346, episodes: 1773, mean episode reward: 1600.0, 1603.747138654012, time: 30.559
steps: 1694346, episodes: 1774, mean episode reward: 0.0, 3.3129244244272957, time: 30.651
steps: 1695346, episodes: 1775, mean episode reward: 0.0, 3.0029999582541125, time: 30.626
steps: 1696346, episodes: 1776, mean episode reward: 0.0, 4.199646917260261, time: 30.586
steps: 1697346, episodes: 1777, mean episode reward: 800.0, 804.1995959551952, time: 32.245
steps: 1698346, episodes: 1778, mean episode reward: 0.0, 3.4830419643982036, time: 32.921
steps: 1699346, episodes: 1779, mean episode reward: 0.0, 3.773056879023317, time: 33.035
steps: 1700165, episodes: 1780, mean episode reward: 0.0, 2.7119476306223733, time: 31.976
steps: 1701165, episodes: 1781, mean episode reward: 0.0, 3.2805307738151495, time: 33.335
steps: 1702165, episodes: 1782, mean episode reward: 1600.0, 1603.5346705600457, time: 30.475
steps: 1703165, episodes: 1783, mean episode reward: 0.0, 3.7098374366789244, time: 30.586
steps: 1704165, episodes: 1784, mean episode reward: 0.0, 3.7473817571919144, time: 30.538
steps: 1705159, episodes: 1785, mean episode reward: 0.0, 2.8384066961159653, time: 30.631
steps: 1706159, episodes: 1786, mean episode reward: 0.0, 3.7952292613723384, time: 30.584
steps: 1707159, episodes: 1787, mean episode reward: 0.0, 3.6883240972732816, time: 30.61
steps: 1708159, episodes: 1788, mean episode reward: 0.0, 3.7350042814418174, time: 30.531
steps: 1709159, episodes: 1789, mean episode reward: 1600.0, 1603.2338109362663, time: 30.612
steps: 1709926, episodes: 1790, mean episode reward: 1600.0, 1602.8615031782056, time: 22.833
steps: 1710752, episodes: 1791, mean episode reward: 0.0, 2.7739377205259834, time: 27.936
steps: 1711752, episodes: 1792, mean episode reward: 0.0, 3.1942473437910124, time: 33.218
steps: 1712752, episodes: 1793, mean episode reward: 0.0, 3.3601386538345466, time: 39.112
steps: 1713752, episodes: 1794, mean episode reward: 0.0, 2.99048409809245, time: 33.208
steps: 1714752, episodes: 1795, mean episode reward: 0.0, 3.555877438930981, time: 33.0
steps: 1715752, episodes: 1796, mean episode reward: 800.0, 802.9584577605063, time: 35.966
steps: 1716752, episodes: 1797, mean episode reward: 800.0, 804.23966753964, time: 48.258
steps: 1717752, episodes: 1798, mean episode reward: 0.0, 3.6153653079720485, time: 37.934
steps: 1718752, episodes: 1799, mean episode reward: 0.0, 3.2147982643902124, time: 37.94
steps: 1719752, episodes: 1800, mean episode reward: 0.0, 3.080467306922714, time: 37.913
steps: 1720752, episodes: 1801, mean episode reward: 0.0, 3.265145877061496, time: 38.408
steps: 1721752, episodes: 1802, mean episode reward: 1600.0, 1603.4202176797771, time: 34.853
StopIteration()
steps: 1722752, episodes: 1803, mean episode reward: 0.0, 3.0060740052573665, time: 31.845
steps: 1723752, episodes: 1804, mean episode reward: 0.0, 4.170837745432245, time: 31.857
steps: 1724752, episodes: 1805, mean episode reward: 0.0, 4.256065465919454, time: 31.825
steps: 1725752, episodes: 1806, mean episode reward: 0.0, 4.006474692142996, time: 31.764
steps: 1726752, episodes: 1807, mean episode reward: 0.0, 3.4935495513581434, time: 31.866
steps: 1727752, episodes: 1808, mean episode reward: 1600.0, 1603.2361332323655, time: 31.872
steps: 1728752, episodes: 1809, mean episode reward: 0.0, 3.6058613183715957, time: 33.72
steps: 1729752, episodes: 1810, mean episode reward: 0.0, 3.59079093193471, time: 30.444
steps: 1730752, episodes: 1811, mean episode reward: 0.0, 3.647586002913237, time: 30.375
steps: 1731752, episodes: 1812, mean episode reward: 0.0, 2.97572989342806, time: 30.632
steps: 1732752, episodes: 1813, mean episode reward: 0.0, 3.4508638183415288, time: 30.399
steps: 1733752, episodes: 1814, mean episode reward: 800.0, 802.93322129304, time: 30.605
steps: 1734752, episodes: 1815, mean episode reward: 0.0, 3.274626072716721, time: 30.53
steps: 1735752, episodes: 1816, mean episode reward: 0.0, 4.068567147448631, time: 30.361
steps: 1736752, episodes: 1817, mean episode reward: 1600.0, 1603.701996507284, time: 30.413
steps: 1737752, episodes: 1818, mean episode reward: 0.0, 3.6666179523252405, time: 30.529
steps: 1738752, episodes: 1819, mean episode reward: 0.0, 3.496543543867793, time: 30.22
steps: 1739752, episodes: 1820, mean episode reward: 0.0, 3.8687478469500567, time: 30.407
steps: 1740578, episodes: 1821, mean episode reward: 0.0, 2.2249191863776767, time: 24.556
steps: 1741578, episodes: 1822, mean episode reward: 800.0, 803.8203364316194, time: 30.557
steps: 1742578, episodes: 1823, mean episode reward: 0.0, 3.7869731676864076, time: 41.301
steps: 1743578, episodes: 1824, mean episode reward: 0.0, 3.53202477475297, time: 36.395
steps: 1744578, episodes: 1825, mean episode reward: 0.0, 3.8697837843494547, time: 40.153
steps: 1745578, episodes: 1826, mean episode reward: 0.0, 3.104144183723737, time: 32.09
steps: 1746578, episodes: 1827, mean episode reward: 1600.0, 1603.367832348712, time: 30.412
steps: 1747578, episodes: 1828, mean episode reward: 2400.0, 2403.452870935851, time: 38.642
steps: 1748578, episodes: 1829, mean episode reward: 2400.0, 2403.7264163008263, time: 37.428
steps: 1749578, episodes: 1830, mean episode reward: 0.0, 3.5242265752476083, time: 35.695
steps: 1750538, episodes: 1831, mean episode reward: 0.0, 3.75686035981433, time: 30.705
steps: 1751538, episodes: 1832, mean episode reward: 0.0, 3.7826740101063887, time: 39.74
steps: 1752538, episodes: 1833, mean episode reward: 0.0, 3.2689714899916136, time: 34.535
steps: 1753421, episodes: 1834, mean episode reward: 3200.0, 3202.7437482059604, time: 31.357
steps: 1754421, episodes: 1835, mean episode reward: 0.0, 3.487131045618769, time: 41.649
steps: 1755421, episodes: 1836, mean episode reward: 0.0, 3.0787018159160637, time: 33.706
steps: 1756421, episodes: 1837, mean episode reward: 0.0, 2.9856721448220602, time: 34.415
steps: 1757421, episodes: 1838, mean episode reward: 0.0, 3.4769049581004365, time: 36.566
steps: 1758421, episodes: 1839, mean episode reward: 0.0, 3.63499117966036, time: 38.575
steps: 1759421, episodes: 1840, mean episode reward: 1600.0, 1603.1265210940091, time: 31.736
steps: 1760421, episodes: 1841, mean episode reward: 0.0, 3.858312431516315, time: 30.558
StopIteration()
steps: 1761421, episodes: 1842, mean episode reward: 0.0, 3.426497426316154, time: 30.561
steps: 1762421, episodes: 1843, mean episode reward: 0.0, 2.869050405759838, time: 30.502
steps: 1763421, episodes: 1844, mean episode reward: 2400.0, 2403.8687174170964, time: 30.442
steps: 1764421, episodes: 1845, mean episode reward: 3200.0, 3202.7595879388273, time: 30.54
steps: 1765421, episodes: 1846, mean episode reward: 800.0, 803.5682404386724, time: 30.296
StopIteration()
steps: 1766421, episodes: 1847, mean episode reward: 0.0, 3.004461163293733, time: 30.808
steps: 1767361, episodes: 1848, mean episode reward: 0.0, 2.8670887301212775, time: 28.393
steps: 1768361, episodes: 1849, mean episode reward: 800.0, 803.9630146547971, time: 30.262
steps: 1769360, episodes: 1850, mean episode reward: 0.0, 3.170755650234772, time: 30.607
steps: 1770207, episodes: 1851, mean episode reward: 0.0, 2.505723589223841, time: 32.438
steps: 1771207, episodes: 1852, mean episode reward: 0.0, 3.6288348652538627, time: 33.951
steps: 1772143, episodes: 1853, mean episode reward: 1600.0, 1603.435252455343, time: 33.571
steps: 1773143, episodes: 1854, mean episode reward: 0.0, 3.4174581159330284, time: 35.02
steps: 1774143, episodes: 1855, mean episode reward: 0.0, 3.10610901842554, time: 31.986
steps: 1775143, episodes: 1856, mean episode reward: 1600.0, 1603.511043971996, time: 32.873
steps: 1776143, episodes: 1857, mean episode reward: 0.0, 3.4531276637444472, time: 32.524
steps: 1777143, episodes: 1858, mean episode reward: 1600.0, 1603.039050993967, time: 32.094
steps: 1778143, episodes: 1859, mean episode reward: 0.0, 3.5921381989344665, time: 36.499
steps: 1779143, episodes: 1860, mean episode reward: 0.0, 3.3228159535315513, time: 41.866
steps: 1780143, episodes: 1861, mean episode reward: 2400.0, 2403.1446789873703, time: 38.666
steps: 1781143, episodes: 1862, mean episode reward: 0.0, 3.15881019777388, time: 38.505
steps: 1782143, episodes: 1863, mean episode reward: 0.0, 4.226283641825034, time: 38.491
steps: 1783143, episodes: 1864, mean episode reward: 800.0, 803.5863798864526, time: 38.42
steps: 1784143, episodes: 1865, mean episode reward: 1600.0, 1603.7341292306699, time: 36.409
steps: 1785143, episodes: 1866, mean episode reward: 0.0, 3.6260650526838405, time: 35.0
steps: 1786143, episodes: 1867, mean episode reward: 1600.0, 1604.0261405741587, time: 30.271
steps: 1787143, episodes: 1868, mean episode reward: 0.0, 3.1212775071518917, time: 33.923
steps: 1788143, episodes: 1869, mean episode reward: 0.0, 3.8479189240463265, time: 35.746
steps: 1789143, episodes: 1870, mean episode reward: 0.0, 3.750640029507378, time: 34.344
steps: 1790143, episodes: 1871, mean episode reward: 0.0, 3.7473330498651842, time: 34.398
steps: 1791028, episodes: 1872, mean episode reward: 0.0, 2.750772130416114, time: 30.358
steps: 1792028, episodes: 1873, mean episode reward: 0.0, 3.906343015059203, time: 39.27
steps: 1793028, episodes: 1874, mean episode reward: 1600.0, 1603.7191930610993, time: 35.552
steps: 1794028, episodes: 1875, mean episode reward: 0.0, 4.2547871308363945, time: 33.165
steps: 1795028, episodes: 1876, mean episode reward: 1600.0, 1603.6742488323414, time: 34.262
steps: 1796028, episodes: 1877, mean episode reward: 1600.0, 1603.3048976263863, time: 36.103
steps: 1797028, episodes: 1878, mean episode reward: 1600.0, 1603.327389150275, time: 36.748
steps: 1798028, episodes: 1879, mean episode reward: 0.0, 3.602470864362341, time: 38.675
steps: 1799028, episodes: 1880, mean episode reward: 0.0, 3.8153494946488267, time: 36.897
steps: 1800028, episodes: 1881, mean episode reward: 800.0, 803.6403186425314, time: 31.878
steps: 1801028, episodes: 1882, mean episode reward: 1600.0, 1603.4193285012911, time: 30.337
steps: 1802028, episodes: 1883, mean episode reward: 1600.0, 1603.3853365495625, time: 30.316
steps: 1803028, episodes: 1884, mean episode reward: 1600.0, 1604.2952444179807, time: 30.369
steps: 1804028, episodes: 1885, mean episode reward: 0.0, 2.9109000694241263, time: 30.46
steps: 1805028, episodes: 1886, mean episode reward: 0.0, 2.9118486237562746, time: 36.255
steps: 1806028, episodes: 1887, mean episode reward: 0.0, 4.107485938286233, time: 32.802
steps: 1807028, episodes: 1888, mean episode reward: 0.0, 4.1733330929874635, time: 31.282
steps: 1808028, episodes: 1889, mean episode reward: 0.0, 3.7275597017061792, time: 32.103
steps: 1809028, episodes: 1890, mean episode reward: 0.0, 3.550400895997003, time: 33.594
steps: 1810028, episodes: 1891, mean episode reward: 0.0, 3.0670228100318924, time: 32.784
steps: 1811028, episodes: 1892, mean episode reward: 0.0, 3.895808580323763, time: 33.544
steps: 1812028, episodes: 1893, mean episode reward: 0.0, 2.987129291796338, time: 33.183
steps: 1813028, episodes: 1894, mean episode reward: 1600.0, 1603.30846601621, time: 33.072
steps: 1814028, episodes: 1895, mean episode reward: 0.0, 3.4712664538040157, time: 45.387
steps: 1814851, episodes: 1896, mean episode reward: 0.0, 2.640030122657564, time: 30.287
steps: 1815851, episodes: 1897, mean episode reward: 0.0, 4.290192590332487, time: 32.599
steps: 1816851, episodes: 1898, mean episode reward: 0.0, 3.437811374461132, time: 36.258
steps: 1817851, episodes: 1899, mean episode reward: 1600.0, 1603.4738314357212, time: 32.724
steps: 1818851, episodes: 1900, mean episode reward: 0.0, 3.258602347894279, time: 31.554
steps: 1819851, episodes: 1901, mean episode reward: 800.0, 803.1286153929786, time: 30.464
steps: 1820851, episodes: 1902, mean episode reward: 0.0, 3.289251936463305, time: 30.371
steps: 1821851, episodes: 1903, mean episode reward: 0.0, 3.5578520819678485, time: 30.336
steps: 1822851, episodes: 1904, mean episode reward: 0.0, 3.812163389409938, time: 30.181
steps: 1823818, episodes: 1905, mean episode reward: 0.0, 2.519659368310868, time: 29.325
steps: 1824818, episodes: 1906, mean episode reward: 0.0, 3.9429392823552565, time: 30.249
steps: 1825818, episodes: 1907, mean episode reward: 800.0, 802.6309471933588, time: 30.751
steps: 1826818, episodes: 1908, mean episode reward: 0.0, 4.1225727687150515, time: 30.338
steps: 1827777, episodes: 1909, mean episode reward: 0.0, 3.4328178826644464, time: 28.893
steps: 1828777, episodes: 1910, mean episode reward: 0.0, 3.5067525789508975, time: 30.292
steps: 1829777, episodes: 1911, mean episode reward: 0.0, 3.8103316229324578, time: 30.186
steps: 1830777, episodes: 1912, mean episode reward: 0.0, 3.6200196812342096, time: 30.282
steps: 1831777, episodes: 1913, mean episode reward: 1600.0, 1602.8608884246853, time: 30.403
steps: 1832777, episodes: 1914, mean episode reward: 0.0, 3.7966047052948255, time: 30.292
steps: 1833777, episodes: 1915, mean episode reward: 0.0, 3.2370335273734736, time: 30.478
steps: 1834607, episodes: 1916, mean episode reward: 2400.0, 2402.784705401856, time: 24.802
steps: 1835607, episodes: 1917, mean episode reward: 0.0, 3.766618335965465, time: 30.302
steps: 1836607, episodes: 1918, mean episode reward: 0.0, 3.71224421213444, time: 30.279
steps: 1837607, episodes: 1919, mean episode reward: 0.0, 3.6870894606346365, time: 30.416
StopIteration()
steps: 1838607, episodes: 1920, mean episode reward: 0.0, 3.3300534984762944, time: 30.432
steps: 1839607, episodes: 1921, mean episode reward: 0.0, 3.33014192882046, time: 30.52
steps: 1840607, episodes: 1922, mean episode reward: 0.0, 3.8360196356348846, time: 30.415
steps: 1841607, episodes: 1923, mean episode reward: 0.0, 2.974332504714684, time: 30.493
steps: 1842525, episodes: 1924, mean episode reward: 0.0, 3.6198871258605894, time: 27.6
steps: 1843525, episodes: 1925, mean episode reward: 0.0, 2.857204884616419, time: 31.058
steps: 1844525, episodes: 1926, mean episode reward: 0.0, 3.2980105602707526, time: 36.381
steps: 1845525, episodes: 1927, mean episode reward: 2400.0, 2403.62234214926, time: 37.514
steps: 1846525, episodes: 1928, mean episode reward: 1600.0, 1603.2436942985078, time: 32.874
steps: 1847525, episodes: 1929, mean episode reward: 0.0, 3.7136716096933338, time: 30.427
steps: 1848316, episodes: 1930, mean episode reward: 0.0, 2.76094608849371, time: 23.323
steps: 1849316, episodes: 1931, mean episode reward: 0.0, 3.839400837507428, time: 30.434
steps: 1850316, episodes: 1932, mean episode reward: 1600.0, 1602.9576096206945, time: 31.505
steps: 1851316, episodes: 1933, mean episode reward: 0.0, 3.399175874884953, time: 35.93
steps: 1852316, episodes: 1934, mean episode reward: 0.0, 3.1239641264356557, time: 32.865
steps: 1853316, episodes: 1935, mean episode reward: 0.0, 2.6270868728188375, time: 30.392
steps: 1854316, episodes: 1936, mean episode reward: 0.0, 3.0244104918777457, time: 33.873
steps: 1855139, episodes: 1937, mean episode reward: 0.0, 3.9275762109823624, time: 28.516
steps: 1856110, episodes: 1938, mean episode reward: 0.0, 3.711781295063715, time: 35.739
steps: 1857110, episodes: 1939, mean episode reward: 0.0, 3.577307171433084, time: 39.539
steps: 1858110, episodes: 1940, mean episode reward: 0.0, 3.6170722485533533, time: 38.615
steps: 1859110, episodes: 1941, mean episode reward: 0.0, 3.336097392684626, time: 30.638
steps: 1860110, episodes: 1942, mean episode reward: 0.0, 3.409269674268862, time: 30.938
steps: 1861110, episodes: 1943, mean episode reward: 1600.0, 1603.5151798534378, time: 30.631
StopIteration()
steps: 1862110, episodes: 1944, mean episode reward: 800.0, 803.8743975935502, time: 30.55
steps: 1863008, episodes: 1945, mean episode reward: 0.0, 2.6511121132132907, time: 27.945
steps: 1864008, episodes: 1946, mean episode reward: 0.0, 3.6990079911243674, time: 35.217
steps: 1865008, episodes: 1947, mean episode reward: 0.0, 2.9124152188027574, time: 38.224
steps: 1866008, episodes: 1948, mean episode reward: 0.0, 3.8014949032725944, time: 35.659
steps: 1867008, episodes: 1949, mean episode reward: 1600.0, 1603.6341955915914, time: 33.829
steps: 1868008, episodes: 1950, mean episode reward: 1600.0, 1602.9852639521189, time: 30.446
steps: 1869008, episodes: 1951, mean episode reward: 0.0, 3.6891947444146846, time: 30.381
steps: 1869884, episodes: 1952, mean episode reward: 0.0, 3.7360935735558454, time: 26.3
StopIteration()
steps: 1870884, episodes: 1953, mean episode reward: 2400.0, 2403.866240508158, time: 30.467
steps: 1871884, episodes: 1954, mean episode reward: 0.0, 4.008095740203264, time: 30.335
steps: 1872791, episodes: 1955, mean episode reward: 0.0, 2.320869312004913, time: 27.173
steps: 1873791, episodes: 1956, mean episode reward: 1600.0, 1603.4158003673183, time: 30.205
steps: 1874791, episodes: 1957, mean episode reward: 0.0, 3.619244423158231, time: 30.309
steps: 1875791, episodes: 1958, mean episode reward: 0.0, 3.3784204334796266, time: 30.245
steps: 1876791, episodes: 1959, mean episode reward: 1600.0, 1602.8319564766578, time: 30.623
steps: 1877791, episodes: 1960, mean episode reward: 1600.0, 1603.542189800955, time: 30.173
steps: 1878791, episodes: 1961, mean episode reward: 3200.0, 3203.4182947481563, time: 30.18
steps: 1879791, episodes: 1962, mean episode reward: 0.0, 3.7370572176705865, time: 30.299
steps: 1880791, episodes: 1963, mean episode reward: 800.0, 803.5413890273533, time: 30.377
steps: 1881791, episodes: 1964, mean episode reward: 0.0, 3.865511486231494, time: 30.306
StopIteration()
steps: 1882791, episodes: 1965, mean episode reward: 0.0, 3.471600246096083, time: 30.623
steps: 1883741, episodes: 1966, mean episode reward: 0.0, 2.6068725379318103, time: 28.704
steps: 1884741, episodes: 1967, mean episode reward: 0.0, 3.575226875924902, time: 30.351
steps: 1885508, episodes: 1968, mean episode reward: 0.0, 3.037102047765638, time: 22.534
steps: 1886508, episodes: 1969, mean episode reward: 0.0, 3.6157684075302496, time: 30.26
StopIteration()
steps: 1887508, episodes: 1970, mean episode reward: 3200.0, 3203.630713208792, time: 32.724
StopIteration()
steps: 1888508, episodes: 1971, mean episode reward: 0.0, 3.567773893855797, time: 30.346
steps: 1889508, episodes: 1972, mean episode reward: 0.0, 3.751810370306978, time: 30.312
steps: 1890128, episodes: 1973, mean episode reward: 0.0, 2.1073811977421224, time: 17.878
steps: 1891128, episodes: 1974, mean episode reward: 0.0, 3.5508262076437767, time: 30.201
steps: 1892043, episodes: 1975, mean episode reward: 1600.0, 1603.104817790682, time: 27.305
steps: 1893043, episodes: 1976, mean episode reward: 1600.0, 1603.1897794436845, time: 30.237
steps: 1894007, episodes: 1977, mean episode reward: 0.0, 3.4576640142849504, time: 30.421
steps: 1895007, episodes: 1978, mean episode reward: 0.0, 3.284193288496451, time: 32.605
steps: 1896007, episodes: 1979, mean episode reward: 0.0, 3.626376878779078, time: 30.773
steps: 1897007, episodes: 1980, mean episode reward: 0.0, 3.8404154437611386, time: 32.528
steps: 1898007, episodes: 1981, mean episode reward: 0.0, 3.497788371193496, time: 32.246
steps: 1898939, episodes: 1982, mean episode reward: 0.0, 3.4466623926368936, time: 28.281
steps: 1899939, episodes: 1983, mean episode reward: 800.0, 803.7312276496214, time: 30.521
steps: 1900939, episodes: 1984, mean episode reward: 0.0, 3.7932112360475334, time: 32.128
steps: 1901939, episodes: 1985, mean episode reward: 0.0, 2.6826268961820627, time: 32.251